[2024-12-14T05:32:40.953+0530] {processor.py:186} INFO - Started process (PID=7250) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:32:40.954+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T05:32:40.955+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:32:40.955+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:32:40.968+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:32:41.098+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:32:41.098+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T05:32:41.122+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:32:41.122+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T05:32:41.145+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.196 seconds
[2024-12-14T05:35:31.185+0530] {processor.py:186} INFO - Started process (PID=7578) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:35:31.186+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T05:35:31.187+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:35:31.187+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:35:31.199+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:35:31.326+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:35:31.326+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T05:35:31.349+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:35:31.348+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T05:35:31.372+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.190 seconds
[2024-12-14T05:38:21.204+0530] {processor.py:186} INFO - Started process (PID=7916) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:38:21.205+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T05:38:21.206+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:38:21.206+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:38:21.216+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:38:21.349+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:38:21.349+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T05:38:21.371+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:38:21.371+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T05:38:21.393+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.193 seconds
[2024-12-14T05:41:11.419+0530] {processor.py:186} INFO - Started process (PID=8245) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:41:11.421+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T05:41:11.423+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:41:11.423+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:41:11.435+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:41:11.556+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:41:11.556+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T05:41:11.578+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:41:11.578+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T05:41:11.599+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.183 seconds
[2024-12-14T05:44:02.027+0530] {processor.py:186} INFO - Started process (PID=8584) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:44:02.028+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T05:44:02.030+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:44:02.029+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:44:02.039+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:44:02.170+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:44:02.169+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T05:44:02.194+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:44:02.194+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T05:44:02.215+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.192 seconds
[2024-12-14T05:46:51.661+0530] {processor.py:186} INFO - Started process (PID=8909) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:46:51.663+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T05:46:51.664+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:46:51.664+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:46:51.673+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:46:51.798+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:46:51.797+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T05:46:51.819+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:46:51.819+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T05:46:51.844+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.187 seconds
[2024-12-14T05:49:41.060+0530] {processor.py:186} INFO - Started process (PID=9265) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:49:41.062+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T05:49:41.063+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:49:41.062+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:49:41.073+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:49:41.202+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:49:41.202+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T05:49:41.223+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:49:41.223+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T05:49:41.244+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.187 seconds
[2024-12-14T05:52:35.810+0530] {processor.py:186} INFO - Started process (PID=9623) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:52:35.813+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T05:52:35.814+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:52:35.814+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:52:35.825+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:52:35.953+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:52:35.953+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T05:52:35.979+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:52:35.979+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T05:52:36.004+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.198 seconds
[2024-12-14T05:55:26.387+0530] {processor.py:186} INFO - Started process (PID=9950) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:55:26.388+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T05:55:26.390+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:55:26.389+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:55:26.399+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:55:26.530+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:55:26.530+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T05:55:26.552+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:55:26.552+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T05:55:26.575+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.192 seconds
[2024-12-14T05:58:16.508+0530] {processor.py:186} INFO - Started process (PID=10290) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:58:16.509+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T05:58:16.511+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:58:16.511+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:58:16.521+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T05:58:16.641+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:58:16.640+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T05:58:16.664+0530] {logging_mixin.py:190} INFO - [2024-12-14T05:58:16.664+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T05:58:16.686+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.181 seconds
[2024-12-14T06:01:08.158+0530] {processor.py:186} INFO - Started process (PID=10625) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:01:08.161+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T06:01:08.163+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:01:08.162+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:01:08.174+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:01:08.305+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:01:08.305+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T06:01:08.327+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:01:08.327+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T06:01:08.349+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.194 seconds
[2024-12-14T06:03:57.823+0530] {processor.py:186} INFO - Started process (PID=10972) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:03:57.825+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T06:03:57.827+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:03:57.826+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:03:57.839+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:03:57.963+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:03:57.963+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T06:03:57.986+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:03:57.986+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T06:03:58.007+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.189 seconds
[2024-12-14T06:06:47.031+0530] {processor.py:186} INFO - Started process (PID=11318) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:06:47.034+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T06:06:47.036+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:06:47.036+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:06:47.047+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:06:47.176+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:06:47.176+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T06:06:47.199+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:06:47.198+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T06:06:47.220+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.192 seconds
[2024-12-14T06:09:38.415+0530] {processor.py:186} INFO - Started process (PID=11760) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:09:38.418+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T06:09:38.419+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:09:38.419+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:09:38.430+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:09:38.555+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:09:38.555+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T06:09:38.578+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:09:38.577+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T06:09:38.599+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.188 seconds
[2024-12-14T06:12:29.393+0530] {processor.py:186} INFO - Started process (PID=12151) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:12:29.395+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T06:12:29.397+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:12:29.396+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:12:29.409+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:12:29.532+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:12:29.532+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T06:12:29.554+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:12:29.554+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T06:12:29.578+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.189 seconds
[2024-12-14T06:15:19.738+0530] {processor.py:186} INFO - Started process (PID=12480) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:15:19.739+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T06:15:19.741+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:15:19.740+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:15:19.750+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:15:19.884+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:15:19.884+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T06:15:19.907+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:15:19.907+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T06:15:19.929+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.195 seconds
[2024-12-14T06:18:09.684+0530] {processor.py:186} INFO - Started process (PID=12820) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:18:09.686+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T06:18:09.687+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:18:09.687+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:18:09.696+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:18:09.837+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:18:09.837+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T06:18:09.859+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:18:09.859+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T06:18:09.885+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.204 seconds
[2024-12-14T06:20:59.623+0530] {processor.py:186} INFO - Started process (PID=13162) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:20:59.624+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T06:20:59.626+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:20:59.625+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:20:59.635+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:20:59.758+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:20:59.758+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T06:20:59.779+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:20:59.779+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T06:20:59.801+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.182 seconds
[2024-12-14T06:23:50.768+0530] {processor.py:186} INFO - Started process (PID=13498) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:23:50.769+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T06:23:50.770+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:23:50.770+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:23:50.781+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:23:50.911+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:23:50.911+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T06:23:50.933+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:23:50.932+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T06:23:50.955+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.190 seconds
[2024-12-14T06:26:39.824+0530] {processor.py:186} INFO - Started process (PID=13823) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:26:39.825+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T06:26:39.826+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:26:39.826+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:26:39.839+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:26:39.961+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:26:39.960+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T06:26:39.983+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:26:39.983+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T06:26:40.005+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.186 seconds
[2024-12-14T06:29:29.624+0530] {processor.py:186} INFO - Started process (PID=14154) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:29:29.625+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T06:29:29.627+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:29:29.627+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:29:29.638+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:29:29.800+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:29:29.800+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T06:29:29.825+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:29:29.825+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T06:29:29.854+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.234 seconds
[2024-12-14T06:32:19.495+0530] {processor.py:186} INFO - Started process (PID=14493) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:32:19.497+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T06:32:19.499+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:32:19.499+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:32:19.510+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:32:19.641+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:32:19.640+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T06:32:19.664+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:32:19.664+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T06:32:19.687+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.196 seconds
[2024-12-14T06:35:10.029+0530] {processor.py:186} INFO - Started process (PID=14820) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:35:10.030+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T06:35:10.032+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:35:10.032+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:35:10.044+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:35:10.170+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:35:10.169+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T06:35:10.192+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:35:10.191+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T06:35:10.214+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.192 seconds
[2024-12-14T06:38:02.610+0530] {processor.py:186} INFO - Started process (PID=15159) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:38:02.613+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T06:38:02.614+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:38:02.614+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:38:02.625+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:38:02.749+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:38:02.749+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T06:38:02.774+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:38:02.773+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T06:38:02.796+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.189 seconds
[2024-12-14T06:40:56.703+0530] {processor.py:186} INFO - Started process (PID=15509) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:40:56.704+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T06:40:56.705+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:40:56.705+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:40:56.715+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:40:56.838+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:40:56.838+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T06:40:56.860+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:40:56.860+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T06:40:56.881+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.182 seconds
[2024-12-14T06:43:47.041+0530] {processor.py:186} INFO - Started process (PID=15846) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:43:47.043+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T06:43:47.044+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:43:47.044+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:43:47.055+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:43:47.202+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:43:47.202+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T06:43:47.226+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:43:47.225+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T06:43:47.248+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.211 seconds
[2024-12-14T06:46:37.059+0530] {processor.py:186} INFO - Started process (PID=16177) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:46:37.062+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T06:46:37.063+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:46:37.063+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:46:37.072+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:46:37.202+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:46:37.202+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T06:46:37.224+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:46:37.223+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T06:46:37.248+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.192 seconds
[2024-12-14T06:49:29.146+0530] {processor.py:186} INFO - Started process (PID=16514) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:49:29.147+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T06:49:29.149+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:49:29.148+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:49:29.160+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:49:29.285+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:49:29.285+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T06:49:29.307+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:49:29.307+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T06:49:29.329+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.187 seconds
[2024-12-14T06:52:20.403+0530] {processor.py:186} INFO - Started process (PID=16867) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:52:20.406+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T06:52:20.408+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:52:20.408+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:52:20.420+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:52:20.551+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:52:20.550+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T06:52:20.575+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:52:20.575+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T06:52:20.597+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.197 seconds
[2024-12-14T06:55:13.025+0530] {processor.py:186} INFO - Started process (PID=17196) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:55:13.026+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T06:55:13.027+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:55:13.027+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:55:13.039+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:55:13.166+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:55:13.166+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T06:55:13.189+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:55:13.188+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T06:55:13.211+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.189 seconds
[2024-12-14T06:58:04.220+0530] {processor.py:186} INFO - Started process (PID=17540) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:58:04.223+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T06:58:04.225+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:58:04.225+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:58:04.249+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T06:58:04.371+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:58:04.371+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T06:58:04.395+0530] {logging_mixin.py:190} INFO - [2024-12-14T06:58:04.394+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T06:58:04.418+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.201 seconds
[2024-12-14T07:00:55.826+0530] {processor.py:186} INFO - Started process (PID=17875) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:00:55.828+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T07:00:55.830+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:00:55.830+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:00:55.840+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:00:55.970+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:00:55.970+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T07:00:55.996+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:00:55.996+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T07:00:56.020+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.198 seconds
[2024-12-14T07:03:48.065+0530] {processor.py:186} INFO - Started process (PID=18227) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:03:48.068+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T07:03:48.069+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:03:48.069+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:03:48.080+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:03:48.207+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:03:48.207+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T07:03:48.230+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:03:48.229+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T07:03:48.251+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.190 seconds
[2024-12-14T07:06:40.918+0530] {processor.py:186} INFO - Started process (PID=18576) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:06:40.920+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T07:06:40.923+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:06:40.922+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:06:40.937+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:06:41.072+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:06:41.072+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T07:06:41.094+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:06:41.094+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T07:06:41.117+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.203 seconds
[2024-12-14T07:09:29.595+0530] {processor.py:186} INFO - Started process (PID=18905) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:09:29.596+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T07:09:29.598+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:09:29.597+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:09:29.609+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:09:29.736+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:09:29.736+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T07:09:29.759+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:09:29.759+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T07:09:29.780+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.189 seconds
[2024-12-14T07:12:37.684+0530] {processor.py:186} INFO - Started process (PID=19273) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:12:37.686+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T07:12:37.688+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:12:37.687+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:12:37.694+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:12:37.691+0530] {dagbag.py:387} ERROR - Failed to import: /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py", line 2
    from airflow.
                 ^
SyntaxError: invalid syntax
[2024-12-14T07:12:37.695+0530] {processor.py:927} WARNING - No viable dags retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:12:37.836+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:12:37.835+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T07:12:37.870+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.190 seconds
[2024-12-14T07:16:15.609+0530] {processor.py:186} INFO - Started process (PID=19663) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:16:15.612+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T07:16:15.613+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:16:15.613+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:16:15.629+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:16:15.620+0530] {dagbag.py:387} ERROR - Failed to import: /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3722, in validate_schedule_and_params
    self.params.validate()
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/param.py", line 284, in validate
    raise ParamValidationError(f"Invalid input for param {k}: {ve}") from None
airflow.exceptions.ParamValidationError: Invalid input for param run_date: No value passed and Param has no default value

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py", line 7, in <module>
    with DAG(
         ^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 776, in __init__
    self.validate_schedule_and_params()
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3724, in validate_schedule_and_params
    raise AirflowException(
airflow.exceptions.AirflowException: DAG is not allowed to define a Schedule, if there are any required params without default values or default values are not valid.
[2024-12-14T07:16:15.630+0530] {processor.py:927} WARNING - No viable dags retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:16:15.769+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:16:15.768+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T07:16:15.803+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.197 seconds
[2024-12-14T07:19:49.312+0530] {processor.py:186} INFO - Started process (PID=20068) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:19:49.315+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T07:19:49.317+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:19:49.317+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:19:49.329+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:19:49.323+0530] {dagbag.py:387} ERROR - Failed to import: /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3722, in validate_schedule_and_params
    self.params.validate()
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/param.py", line 284, in validate
    raise ParamValidationError(f"Invalid input for param {k}: {ve}") from None
airflow.exceptions.ParamValidationError: Invalid input for param run_date: No value passed and Param has no default value

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py", line 7, in <module>
    with DAG(
         ^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 776, in __init__
    self.validate_schedule_and_params()
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3724, in validate_schedule_and_params
    raise AirflowException(
airflow.exceptions.AirflowException: DAG is not allowed to define a Schedule, if there are any required params without default values or default values are not valid.
[2024-12-14T07:19:49.330+0530] {processor.py:927} WARNING - No viable dags retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:19:49.481+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:19:49.480+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T07:19:49.510+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.202 seconds
[2024-12-14T07:23:18.020+0530] {processor.py:186} INFO - Started process (PID=20469) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:23:18.022+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T07:23:18.023+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:23:18.023+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:23:18.073+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:23:18.069+0530] {dagbag.py:387} ERROR - Failed to import: /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3722, in validate_schedule_and_params
    self.params.validate()
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/param.py", line 284, in validate
    raise ParamValidationError(f"Invalid input for param {k}: {ve}") from None
airflow.exceptions.ParamValidationError: Invalid input for param some-date: No value passed and Param has no default value

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py", line 8, in <module>
    with DAG(
         ^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 776, in __init__
    self.validate_schedule_and_params()
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3724, in validate_schedule_and_params
    raise AirflowException(
airflow.exceptions.AirflowException: DAG is not allowed to define a Schedule, if there are any required params without default values or default values are not valid.
[2024-12-14T07:23:18.074+0530] {processor.py:927} WARNING - No viable dags retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:23:18.214+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:23:18.214+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T07:23:18.257+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.241 seconds
[2024-12-14T07:26:43.367+0530] {processor.py:186} INFO - Started process (PID=20897) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:26:43.370+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T07:26:43.371+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:26:43.371+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:26:43.433+0530] {processor.py:925} INFO - DAG(s) 'the_dag' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:26:44.088+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:26:44.086+0530] {override.py:1911} INFO - Created Permission View: can read on DAG:the_dag
[2024-12-14T07:26:44.108+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:26:44.108+0530] {override.py:1911} INFO - Created Permission View: can edit on DAG:the_dag
[2024-12-14T07:26:44.127+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:26:44.126+0530] {override.py:1911} INFO - Created Permission View: can delete on DAG:the_dag
[2024-12-14T07:26:44.141+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:26:44.140+0530] {override.py:1911} INFO - Created Permission View: can read on DAG Run:the_dag
[2024-12-14T07:26:44.151+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:26:44.151+0530] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:the_dag
[2024-12-14T07:26:44.162+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:26:44.162+0530] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:the_dag
[2024-12-14T07:26:44.172+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:26:44.171+0530] {override.py:1911} INFO - Created Permission View: can create on DAG Run:the_dag
[2024-12-14T07:26:44.172+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:26:44.172+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T07:26:44.196+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:26:44.196+0530] {dag.py:3262} INFO - Creating ORM DAG for the_dag
[2024-12-14T07:26:44.208+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:26:44.208+0530] {dag.py:4180} INFO - Setting next_dagrun for the_dag to None, run_after=None
[2024-12-14T07:26:44.240+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.877 seconds
[2024-12-14T07:30:14.242+0530] {processor.py:186} INFO - Started process (PID=21274) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:30:14.244+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T07:30:14.245+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:30:14.245+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:30:14.300+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:30:14.292+0530] {dagbag.py:387} ERROR - Failed to import: /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3722, in validate_schedule_and_params
    self.params.validate()
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/param.py", line 284, in validate
    raise ParamValidationError(f"Invalid input for param {k}: {ve}") from None
airflow.exceptions.ParamValidationError: Invalid input for param some-date: No value passed and Param has no default value

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py", line 8, in <module>
    with DAG(
         ^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 776, in __init__
    self.validate_schedule_and_params()
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3724, in validate_schedule_and_params
    raise AirflowException(
airflow.exceptions.AirflowException: DAG is not allowed to define a Schedule, if there are any required params without default values or default values are not valid.
[2024-12-14T07:30:14.301+0530] {processor.py:927} WARNING - No viable dags retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:30:14.431+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:30:14.431+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T07:30:14.461+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.223 seconds
[2024-12-14T07:33:23.453+0530] {processor.py:186} INFO - Started process (PID=21675) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:33:23.456+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T07:33:23.457+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:33:23.457+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:33:23.507+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:33:23.501+0530] {dagbag.py:387} ERROR - Failed to import: /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3722, in validate_schedule_and_params
    self.params.validate()
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/param.py", line 284, in validate
    raise ParamValidationError(f"Invalid input for param {k}: {ve}") from None
airflow.exceptions.ParamValidationError: Invalid input for param some-date: No value passed and Param has no default value

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py", line 8, in <module>
    with DAG(
         ^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 776, in __init__
    self.validate_schedule_and_params()
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3724, in validate_schedule_and_params
    raise AirflowException(
airflow.exceptions.AirflowException: DAG is not allowed to define a Schedule, if there are any required params without default values or default values are not valid.
[2024-12-14T07:33:23.509+0530] {processor.py:927} WARNING - No viable dags retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:33:23.651+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:33:23.651+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T07:33:23.678+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.228 seconds
[2024-12-14T07:36:47.888+0530] {processor.py:186} INFO - Started process (PID=22090) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:36:47.890+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T07:36:47.892+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:36:47.892+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:36:48.158+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:36:48.158+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T07:36:48.183+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:36:48.182+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 02:06:47.939206+00:00: manual__2024-12-14T02:06:47.939206+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T07:36:48.221+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:36:48.221+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=task1 map_index=-1
[2024-12-14T07:36:48.222+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:36:48.221+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.task1 manual__2024-12-14T02:06:47.939206+00:00 [scheduled]>
[2024-12-14T07:36:53.322+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:36:53.322+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T07:36:53.391+0530] {logging_mixin.py:190} INFO - [2024-12-14 07:36:53,391] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:06:47.939206+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:06:47.939206+00:00'
[2024-12-14T07:36:53.391+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:36:53.391+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:06:47.939206+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:06:47.939206+00:00'
[2024-12-14T07:36:53.404+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T07:36:53.405+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T07:36:53.406+0530] {logging_mixin.py:190} INFO - Current task name:task1 state:scheduled start_date:None
[2024-12-14T07:36:53.406+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T07:36:53.407+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:36:53.407+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T07:36:53.410+0530] {logging_mixin.py:190} INFO - 2024-12-14
[2024-12-14T07:36:53.411+0530] {logging_mixin.py:190} INFO - [2024-12-14 07:36:53,410] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T07:36:53.411+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:36:53.410+0530] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T07:36:53.419+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:36:53.418+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T07:36:53.421+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:36:53.419+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=task1, run_id=manual__2024-12-14T02:06:47.939206+00:00, execution_date=20241214T020647, start_date=, end_date=20241214T020653
[2024-12-14T07:36:53.430+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T07:36:53.431+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T07:36:53.431+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T07:36:53.433+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:_PythonDecoratedOperator
[2024-12-14T07:36:53.434+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:36:53.433+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=task1 map_index=-1
[2024-12-14T07:36:53.439+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:36:53.439+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 02:06:47.939206+00:00: manual__2024-12-14T02:06:47.939206+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T07:36:53.440+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T07:36:53.441+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 02:06:47.939206+00:00 end:2024-12-14 02:06:53.440298+00:00
[2024-12-14T07:36:53.448+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:36:53.441+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 02:06:47.939206+00:00, run_id=manual__2024-12-14T02:06:47.939206+00:00, run_start_date=2024-12-14 02:06:47.939206+00:00, run_end_date=2024-12-14 02:06:53.440298+00:00, run_duration=5.501092, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 02:06:47.939206+00:00, data_interval_end=2024-12-14 02:06:47.939206+00:00, dag_hash=None
[2024-12-14T07:36:53.461+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:36:53.626+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:36:53.626+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T07:36:53.643+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:36:53.643+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T07:36:53.671+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.787 seconds
[2024-12-14T07:39:59.520+0530] {processor.py:186} INFO - Started process (PID=22482) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:39:59.522+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T07:39:59.523+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:39:59.523+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:39:59.772+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:39:59.772+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T07:39:59.792+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:39:59.792+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 02:09:59.597906+00:00: manual__2024-12-14T02:09:59.597906+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T07:39:59.830+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:39:59.829+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=task1 map_index=-1
[2024-12-14T07:39:59.830+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:39:59.830+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.task1 manual__2024-12-14T02:09:59.597906+00:00 [scheduled]>
[2024-12-14T07:40:04.938+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:40:04.938+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T07:40:05.016+0530] {logging_mixin.py:190} INFO - [2024-12-14 07:40:05,016] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:09:59.597906+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:09:59.597906+00:00'
[2024-12-14T07:40:05.017+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:40:05.016+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:09:59.597906+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:09:59.597906+00:00'
[2024-12-14T07:40:05.029+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T07:40:05.030+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T07:40:05.030+0530] {logging_mixin.py:190} INFO - Current task name:task1 state:scheduled start_date:None
[2024-12-14T07:40:05.030+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T07:40:05.031+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:40:05.031+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T07:40:05.034+0530] {logging_mixin.py:190} INFO - 2024-12-14
[2024-12-14T07:40:05.035+0530] {logging_mixin.py:190} INFO - [2024-12-14 07:40:05,035] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T07:40:05.035+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:40:05.035+0530] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T07:40:05.040+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:40:05.040+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T07:40:05.041+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:40:05.040+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=task1, run_id=manual__2024-12-14T02:09:59.597906+00:00, execution_date=20241214T020959, start_date=, end_date=20241214T021005
[2024-12-14T07:40:05.050+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T07:40:05.051+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T07:40:05.051+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T07:40:05.051+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:_PythonDecoratedOperator
[2024-12-14T07:40:05.051+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:40:05.051+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=task1 map_index=-1
[2024-12-14T07:40:05.055+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:40:05.055+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 02:09:59.597906+00:00: manual__2024-12-14T02:09:59.597906+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T07:40:05.055+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T07:40:05.056+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 02:09:59.597906+00:00 end:2024-12-14 02:10:05.055777+00:00
[2024-12-14T07:40:05.056+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:40:05.056+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 02:09:59.597906+00:00, run_id=manual__2024-12-14T02:09:59.597906+00:00, run_start_date=2024-12-14 02:09:59.597906+00:00, run_end_date=2024-12-14 02:10:05.055777+00:00, run_duration=5.457871, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 02:09:59.597906+00:00, data_interval_end=2024-12-14 02:09:59.597906+00:00, dag_hash=None
[2024-12-14T07:40:05.065+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:40:05.087+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:40:05.087+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T07:40:05.105+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:40:05.104+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T07:40:05.124+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.608 seconds
[2024-12-14T07:43:54.659+0530] {processor.py:186} INFO - Started process (PID=22995) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:43:54.662+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T07:43:54.665+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:43:54.664+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:43:54.915+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:43:54.915+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T07:43:54.940+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:43:54.940+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 02:13:54.725555+00:00: manual__2024-12-14T02:13:54.725555+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T07:43:54.979+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:43:54.979+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=task1 map_index=-1
[2024-12-14T07:43:54.982+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:43:54.982+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.task1 manual__2024-12-14T02:13:54.725555+00:00 [scheduled]>
[2024-12-14T07:44:00.119+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:44:00.119+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T07:44:00.209+0530] {logging_mixin.py:190} INFO - [2024-12-14 07:44:00,209] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:13:54.725555+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:13:54.725555+00:00'
[2024-12-14T07:44:00.210+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:44:00.209+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:13:54.725555+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:13:54.725555+00:00'
[2024-12-14T07:44:00.213+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T07:44:00.213+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T07:44:00.213+0530] {logging_mixin.py:190} INFO - Current task name:task1 state:scheduled start_date:None
[2024-12-14T07:44:00.214+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T07:44:00.215+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:44:00.215+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T07:44:00.218+0530] {logging_mixin.py:190} INFO - 2024-12-10
[2024-12-14T07:44:00.220+0530] {logging_mixin.py:190} INFO - [2024-12-14 07:44:00,219] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T07:44:00.220+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:44:00.219+0530] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T07:44:00.229+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:44:00.228+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T07:44:00.229+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:44:00.229+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=task1, run_id=manual__2024-12-14T02:13:54.725555+00:00, execution_date=20241214T021354, start_date=, end_date=20241214T021400
[2024-12-14T07:44:00.246+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T07:44:00.247+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T07:44:00.248+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T07:44:00.249+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:_PythonDecoratedOperator
[2024-12-14T07:44:00.252+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:44:00.251+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=task1 map_index=-1
[2024-12-14T07:44:00.257+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:44:00.257+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 02:13:54.725555+00:00: manual__2024-12-14T02:13:54.725555+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T07:44:00.258+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T07:44:00.258+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 02:13:54.725555+00:00 end:2024-12-14 02:14:00.258083+00:00
[2024-12-14T07:44:00.259+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:44:00.259+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 02:13:54.725555+00:00, run_id=manual__2024-12-14T02:13:54.725555+00:00, run_start_date=2024-12-14 02:13:54.725555+00:00, run_end_date=2024-12-14 02:14:00.258083+00:00, run_duration=5.532528, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 02:13:54.725555+00:00, data_interval_end=2024-12-14 02:13:54.725555+00:00, dag_hash=None
[2024-12-14T07:44:00.271+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:44:00.605+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:44:00.605+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T07:44:00.624+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:44:00.624+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T07:44:00.647+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.992 seconds
[2024-12-14T07:47:50.873+0530] {processor.py:186} INFO - Started process (PID=23457) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:47:50.875+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T07:47:50.877+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:47:50.877+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:47:51.056+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:47:51.055+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T07:47:51.071+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:47:51.071+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 02:17:50.920771+00:00: manual__2024-12-14T02:17:50.920771+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T07:47:51.096+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:47:51.096+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=task1 map_index=-1
[2024-12-14T07:47:51.097+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:47:51.096+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.task1 manual__2024-12-14T02:17:50.920771+00:00 [scheduled]>
[2024-12-14T07:47:56.201+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:47:56.200+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T07:47:56.273+0530] {logging_mixin.py:190} INFO - [2024-12-14 07:47:56,273] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:17:50.920771+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:17:50.920771+00:00'
[2024-12-14T07:47:56.273+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:47:56.273+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:17:50.920771+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:17:50.920771+00:00'
[2024-12-14T07:47:56.276+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T07:47:56.276+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T07:47:56.277+0530] {logging_mixin.py:190} INFO - Current task name:task1 state:scheduled start_date:None
[2024-12-14T07:47:56.277+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T07:47:56.277+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:47:56.277+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T07:47:56.279+0530] {logging_mixin.py:190} INFO - 2024-12-10
[2024-12-14T07:47:56.285+0530] {logging_mixin.py:190} INFO - 2024-12-14 02:17:50.920771+00:00
[2024-12-14T07:47:56.286+0530] {logging_mixin.py:190} INFO - [2024-12-14 07:47:56,285] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T07:47:56.287+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:47:56.285+0530] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T07:47:56.294+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:47:56.293+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T07:47:56.294+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:47:56.294+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=task1, run_id=manual__2024-12-14T02:17:50.920771+00:00, execution_date=20241214T021750, start_date=, end_date=20241214T021756
[2024-12-14T07:47:56.305+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T07:47:56.306+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T07:47:56.306+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T07:47:56.306+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:_PythonDecoratedOperator
[2024-12-14T07:47:56.307+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:47:56.306+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=task1 map_index=-1
[2024-12-14T07:47:56.311+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:47:56.311+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 02:17:50.920771+00:00: manual__2024-12-14T02:17:50.920771+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T07:47:56.311+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T07:47:56.311+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 02:17:50.920771+00:00 end:2024-12-14 02:17:56.311560+00:00
[2024-12-14T07:47:56.312+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:47:56.312+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 02:17:50.920771+00:00, run_id=manual__2024-12-14T02:17:50.920771+00:00, run_start_date=2024-12-14 02:17:50.920771+00:00, run_end_date=2024-12-14 02:17:56.311560+00:00, run_duration=5.390789, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 02:17:50.920771+00:00, data_interval_end=2024-12-14 02:17:50.920771+00:00, dag_hash=None
[2024-12-14T07:47:56.322+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:47:56.338+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:47:56.338+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T07:47:56.354+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:47:56.354+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T07:47:56.374+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.505 seconds
[2024-12-14T07:52:29.283+0530] {processor.py:186} INFO - Started process (PID=24035) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:52:29.286+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T07:52:29.287+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:52:29.287+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:52:29.479+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:52:29.479+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T07:52:29.497+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:52:29.496+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 02:22:29.341047+00:00: manual__2024-12-14T02:22:29.341047+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T07:52:29.528+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:52:29.528+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=task1 map_index=-1
[2024-12-14T07:52:29.528+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:52:29.528+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.task1 manual__2024-12-14T02:22:29.341047+00:00 [scheduled]>
[2024-12-14T07:52:34.643+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:52:34.642+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T07:52:34.721+0530] {logging_mixin.py:190} INFO - [2024-12-14 07:52:34,721] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:22:29.341047+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:22:29.341047+00:00'
[2024-12-14T07:52:34.725+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:52:34.721+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:22:29.341047+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:22:29.341047+00:00'
[2024-12-14T07:52:34.739+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T07:52:34.740+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T07:52:34.740+0530] {logging_mixin.py:190} INFO - Current task name:task1 state:scheduled start_date:None
[2024-12-14T07:52:34.740+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T07:52:34.741+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:52:34.741+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T07:52:34.745+0530] {logging_mixin.py:190} INFO - 2024-12-10
[2024-12-14T07:52:34.750+0530] {logging_mixin.py:190} INFO - 2024-12-14 07:52:29.341047+05:30
[2024-12-14T07:52:34.750+0530] {logging_mixin.py:190} INFO - [2024-12-14 07:52:34,750] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T07:52:34.751+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:52:34.750+0530] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T07:52:34.756+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:52:34.755+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T07:52:34.756+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:52:34.756+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=task1, run_id=manual__2024-12-14T02:22:29.341047+00:00, execution_date=20241214T022229, start_date=, end_date=20241214T022234
[2024-12-14T07:52:34.766+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T07:52:34.766+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T07:52:34.766+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T07:52:34.767+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:_PythonDecoratedOperator
[2024-12-14T07:52:34.767+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:52:34.767+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=task1 map_index=-1
[2024-12-14T07:52:34.771+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:52:34.771+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 02:22:29.341047+00:00: manual__2024-12-14T02:22:29.341047+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T07:52:34.771+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T07:52:34.771+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 02:22:29.341047+00:00 end:2024-12-14 02:22:34.771695+00:00
[2024-12-14T07:52:34.772+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:52:34.772+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 02:22:29.341047+00:00, run_id=manual__2024-12-14T02:22:29.341047+00:00, run_start_date=2024-12-14 02:22:29.341047+00:00, run_end_date=2024-12-14 02:22:34.771695+00:00, run_duration=5.430648, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 02:22:29.341047+00:00, data_interval_end=2024-12-14 02:22:29.341047+00:00, dag_hash=None
[2024-12-14T07:52:34.782+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:52:34.797+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:52:34.796+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T07:52:34.814+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:52:34.813+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T07:52:34.835+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.556 seconds
[2024-12-14T07:55:37.903+0530] {processor.py:186} INFO - Started process (PID=24409) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:55:37.905+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T07:55:37.907+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:55:37.907+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:55:38.094+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:55:38.093+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T07:55:38.114+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:55:38.114+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 02:25:37.951560+00:00: manual__2024-12-14T02:25:37.951560+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T07:55:38.143+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:55:38.143+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=task1 map_index=-1
[2024-12-14T07:55:38.144+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:55:38.143+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.task1 manual__2024-12-14T02:25:37.951560+00:00 [scheduled]>
[2024-12-14T07:55:43.243+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:55:43.243+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T07:55:43.309+0530] {logging_mixin.py:190} INFO - [2024-12-14 07:55:43,309] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:25:37.951560+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:25:37.951560+00:00'
[2024-12-14T07:55:43.310+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:55:43.309+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:25:37.951560+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:25:37.951560+00:00'
[2024-12-14T07:55:43.323+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T07:55:43.323+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T07:55:43.323+0530] {logging_mixin.py:190} INFO - Current task name:task1 state:scheduled start_date:None
[2024-12-14T07:55:43.324+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T07:55:43.324+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:55:43.324+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T07:55:43.326+0530] {logging_mixin.py:190} INFO - 2024-12-10
[2024-12-14T07:55:43.332+0530] {logging_mixin.py:190} INFO - 2024-12-14 07:55:37.951560+05:30
[2024-12-14T07:55:43.333+0530] {logging_mixin.py:190} INFO - [2024-12-14 07:55:43,333] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T07:55:43.333+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:55:43.333+0530] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T07:55:43.339+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:55:43.339+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T07:55:43.339+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:55:43.339+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=task1, run_id=manual__2024-12-14T02:25:37.951560+00:00, execution_date=20241214T022537, start_date=, end_date=20241214T022543
[2024-12-14T07:55:43.350+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T07:55:43.350+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T07:55:43.350+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T07:55:43.351+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:_PythonDecoratedOperator
[2024-12-14T07:55:43.351+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:55:43.351+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=task1 map_index=-1
[2024-12-14T07:55:43.355+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:55:43.354+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 02:25:37.951560+00:00: manual__2024-12-14T02:25:37.951560+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T07:55:43.355+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T07:55:43.355+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 02:25:37.951560+00:00 end:2024-12-14 02:25:43.355243+00:00
[2024-12-14T07:55:43.356+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:55:43.355+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 02:25:37.951560+00:00, run_id=manual__2024-12-14T02:25:37.951560+00:00, run_start_date=2024-12-14 02:25:37.951560+00:00, run_end_date=2024-12-14 02:25:43.355243+00:00, run_duration=5.403683, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 02:25:37.951560+00:00, data_interval_end=2024-12-14 02:25:37.951560+00:00, dag_hash=None
[2024-12-14T07:55:43.365+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:55:43.376+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:55:43.376+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T07:55:43.394+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:55:43.393+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T07:55:43.415+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.517 seconds
[2024-12-14T07:59:53.729+0530] {processor.py:186} INFO - Started process (PID=24744) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:59:53.745+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T07:59:53.750+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:59:53.747+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:59:54.043+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:59:54.042+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T07:59:54.060+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:59:54.060+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 02:29:53.863829+00:00: manual__2024-12-14T02:29:53.863829+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T07:59:54.092+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:59:54.092+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=task1 map_index=-1
[2024-12-14T07:59:54.093+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:59:54.093+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.task1 manual__2024-12-14T02:29:53.863829+00:00 [scheduled]>
[2024-12-14T07:59:59.217+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:59:59.216+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T07:59:59.508+0530] {logging_mixin.py:190} INFO - [2024-12-14 07:59:59,508] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:29:53.863829+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:29:53.863829+00:00'
[2024-12-14T07:59:59.509+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:59:59.508+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:29:53.863829+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:29:53.863829+00:00'
[2024-12-14T07:59:59.525+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T07:59:59.528+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T07:59:59.534+0530] {logging_mixin.py:190} INFO - Current task name:task1 state:scheduled start_date:None
[2024-12-14T07:59:59.534+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T07:59:59.538+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:59:59.537+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T07:59:59.542+0530] {logging_mixin.py:190} INFO - 2024-12-10
[2024-12-14T07:59:59.550+0530] {logging_mixin.py:190} INFO - 2024-12-14 07:59:53.863829+05:30
[2024-12-14T07:59:59.552+0530] {logging_mixin.py:190} INFO - [2024-12-14 07:59:59,551] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T07:59:59.553+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:59:59.551+0530] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T07:59:59.560+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:59:59.560+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T07:59:59.561+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:59:59.561+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=task1, run_id=manual__2024-12-14T02:29:53.863829+00:00, execution_date=20241214T022953, start_date=, end_date=20241214T022959
[2024-12-14T07:59:59.606+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T07:59:59.606+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T07:59:59.607+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T07:59:59.607+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:_PythonDecoratedOperator
[2024-12-14T07:59:59.607+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:59:59.607+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=task1 map_index=-1
[2024-12-14T07:59:59.613+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:59:59.612+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 02:29:53.863829+00:00: manual__2024-12-14T02:29:53.863829+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T07:59:59.613+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T07:59:59.613+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 02:29:53.863829+00:00 end:2024-12-14 02:29:59.613271+00:00
[2024-12-14T07:59:59.613+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:59:59.613+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 02:29:53.863829+00:00, run_id=manual__2024-12-14T02:29:53.863829+00:00, run_start_date=2024-12-14 02:29:53.863829+00:00, run_end_date=2024-12-14 02:29:59.613271+00:00, run_duration=5.749442, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 02:29:53.863829+00:00, data_interval_end=2024-12-14 02:29:53.863829+00:00, dag_hash=None
[2024-12-14T07:59:59.627+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T07:59:59.656+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:59:59.651+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T07:59:59.694+0530] {logging_mixin.py:190} INFO - [2024-12-14T07:59:59.694+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T07:59:59.730+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 6.015 seconds
[2024-12-14T08:04:38.396+0530] {processor.py:186} INFO - Started process (PID=25079) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:04:38.399+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T08:04:38.401+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:04:38.401+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:04:38.634+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:04:38.633+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T08:04:38.650+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:04:38.649+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 02:34:38.459465+00:00: manual__2024-12-14T02:34:38.459465+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T08:04:38.685+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:04:38.685+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=task1 map_index=-1
[2024-12-14T08:04:38.685+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:04:38.685+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.task1 manual__2024-12-14T02:34:38.459465+00:00 [scheduled]>
[2024-12-14T08:04:43.884+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:04:43.883+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T08:04:44.036+0530] {logging_mixin.py:190} INFO - [2024-12-14 08:04:44,036] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:34:38.459465+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:34:38.459465+00:00'
[2024-12-14T08:04:44.037+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:04:44.036+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:34:38.459465+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:34:38.459465+00:00'
[2024-12-14T08:04:44.052+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T08:04:44.052+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T08:04:44.052+0530] {logging_mixin.py:190} INFO - Current task name:task1 state:scheduled start_date:None
[2024-12-14T08:04:44.053+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T08:04:44.053+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:04:44.053+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T08:04:44.056+0530] {logging_mixin.py:190} INFO - 2024-12-10
[2024-12-14T08:04:44.063+0530] {logging_mixin.py:190} INFO - 2024-12-14 08:04:38.459465+05:30
[2024-12-14T08:04:44.064+0530] {logging_mixin.py:190} INFO - [2024-12-14 08:04:44,063] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T08:04:44.064+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:04:44.063+0530] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T08:04:44.070+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:04:44.070+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T08:04:44.071+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:04:44.070+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=task1, run_id=manual__2024-12-14T02:34:38.459465+00:00, execution_date=20241214T023438, start_date=, end_date=20241214T023444
[2024-12-14T08:04:44.084+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T08:04:44.085+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T08:04:44.085+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T08:04:44.086+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:_PythonDecoratedOperator
[2024-12-14T08:04:44.086+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:04:44.086+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=task1 map_index=-1
[2024-12-14T08:04:44.092+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:04:44.092+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 02:34:38.459465+00:00: manual__2024-12-14T02:34:38.459465+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T08:04:44.095+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T08:04:44.096+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 02:34:38.459465+00:00 end:2024-12-14 02:34:44.095509+00:00
[2024-12-14T08:04:44.096+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:04:44.096+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 02:34:38.459465+00:00, run_id=manual__2024-12-14T02:34:38.459465+00:00, run_start_date=2024-12-14 02:34:38.459465+00:00, run_end_date=2024-12-14 02:34:44.095509+00:00, run_duration=5.636044, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 02:34:38.459465+00:00, data_interval_end=2024-12-14 02:34:38.459465+00:00, dag_hash=None
[2024-12-14T08:04:44.113+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:04:44.135+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:04:44.135+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T08:04:44.153+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:04:44.153+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T08:04:44.173+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.784 seconds
[2024-12-14T08:08:05.398+0530] {processor.py:186} INFO - Started process (PID=25353) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:08:05.400+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T08:08:05.405+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:08:05.403+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:08:05.594+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:08:05.594+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T08:08:05.610+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:08:05.609+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 02:38:05.448970+00:00: manual__2024-12-14T02:38:05.448970+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T08:08:05.639+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:08:05.639+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=task1 map_index=-1
[2024-12-14T08:08:05.640+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:08:05.640+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.task1 manual__2024-12-14T02:38:05.448970+00:00 [scheduled]>
[2024-12-14T08:08:10.749+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:08:10.749+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T08:08:10.820+0530] {logging_mixin.py:190} INFO - [2024-12-14 08:08:10,820] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:38:05.448970+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:38:05.448970+00:00'
[2024-12-14T08:08:10.820+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:08:10.820+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:38:05.448970+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:38:05.448970+00:00'
[2024-12-14T08:08:10.832+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T08:08:10.832+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T08:08:10.833+0530] {logging_mixin.py:190} INFO - Current task name:task1 state:scheduled start_date:None
[2024-12-14T08:08:10.833+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T08:08:10.833+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:08:10.833+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T08:08:10.838+0530] {logging_mixin.py:190} INFO - 2024-12-10
[2024-12-14T08:08:10.841+0530] {logging_mixin.py:190} INFO - 2024-12-14 08:08:05.448970+05:30
[2024-12-14T08:08:10.842+0530] {logging_mixin.py:190} INFO - [2024-12-14 08:08:10,842] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T08:08:10.842+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:08:10.842+0530] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T08:08:10.847+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:08:10.847+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T08:08:10.847+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:08:10.847+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=task1, run_id=manual__2024-12-14T02:38:05.448970+00:00, execution_date=20241214T023805, start_date=, end_date=20241214T023810
[2024-12-14T08:08:10.858+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T08:08:10.858+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T08:08:10.858+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T08:08:10.859+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:_PythonDecoratedOperator
[2024-12-14T08:08:10.859+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:08:10.859+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=task1 map_index=-1
[2024-12-14T08:08:10.863+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:08:10.863+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 02:38:05.448970+00:00: manual__2024-12-14T02:38:05.448970+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T08:08:10.864+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T08:08:10.864+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 02:38:05.448970+00:00 end:2024-12-14 02:38:10.864159+00:00
[2024-12-14T08:08:10.865+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:08:10.864+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 02:38:05.448970+00:00, run_id=manual__2024-12-14T02:38:05.448970+00:00, run_start_date=2024-12-14 02:38:05.448970+00:00, run_end_date=2024-12-14 02:38:10.864159+00:00, run_duration=5.415189, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 02:38:05.448970+00:00, data_interval_end=2024-12-14 02:38:05.448970+00:00, dag_hash=None
[2024-12-14T08:08:10.875+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:08:10.889+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:08:10.888+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T08:08:10.906+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:08:10.906+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T08:08:10.924+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.528 seconds
[2024-12-14T08:11:23.597+0530] {processor.py:186} INFO - Started process (PID=25571) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:11:23.600+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T08:11:23.603+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:11:23.602+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:11:23.807+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:11:23.807+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T08:11:23.823+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:11:23.822+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 02:41:23.650595+00:00: manual__2024-12-14T02:41:23.650595+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T08:11:23.853+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:11:23.853+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=task1 map_index=-1
[2024-12-14T08:11:23.853+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:11:23.853+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.task1 manual__2024-12-14T02:41:23.650595+00:00 [scheduled]>
[2024-12-14T08:11:28.951+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:11:28.951+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T08:11:29.017+0530] {logging_mixin.py:190} INFO - [2024-12-14 08:11:29,017] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:41:23.650595+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:41:23.650595+00:00'
[2024-12-14T08:11:29.018+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:11:29.017+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:41:23.650595+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:41:23.650595+00:00'
[2024-12-14T08:11:29.032+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T08:11:29.032+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T08:11:29.032+0530] {logging_mixin.py:190} INFO - Current task name:task1 state:scheduled start_date:None
[2024-12-14T08:11:29.033+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T08:11:29.033+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:11:29.033+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T08:11:29.037+0530] {logging_mixin.py:190} INFO - 2024-12-10
[2024-12-14T08:11:29.041+0530] {logging_mixin.py:190} INFO - 2024-12-14 08:11:23.650595+05:30
[2024-12-14T08:11:29.042+0530] {logging_mixin.py:190} INFO - [2024-12-14 08:11:29,042] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T08:11:29.042+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:11:29.042+0530] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T08:11:29.047+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:11:29.047+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T08:11:29.048+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:11:29.048+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=task1, run_id=manual__2024-12-14T02:41:23.650595+00:00, execution_date=20241214T024123, start_date=, end_date=20241214T024129
[2024-12-14T08:11:29.059+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T08:11:29.059+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T08:11:29.060+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T08:11:29.060+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:_PythonDecoratedOperator
[2024-12-14T08:11:29.060+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:11:29.060+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=task1 map_index=-1
[2024-12-14T08:11:29.064+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:11:29.064+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 02:41:23.650595+00:00: manual__2024-12-14T02:41:23.650595+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T08:11:29.065+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T08:11:29.065+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 02:41:23.650595+00:00 end:2024-12-14 02:41:29.064988+00:00
[2024-12-14T08:11:29.066+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:11:29.065+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 02:41:23.650595+00:00, run_id=manual__2024-12-14T02:41:23.650595+00:00, run_start_date=2024-12-14 02:41:23.650595+00:00, run_end_date=2024-12-14 02:41:29.064988+00:00, run_duration=5.414393, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 02:41:23.650595+00:00, data_interval_end=2024-12-14 02:41:23.650595+00:00, dag_hash=None
[2024-12-14T08:11:29.074+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:11:29.087+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:11:29.087+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T08:11:29.107+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:11:29.106+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T08:11:29.127+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.534 seconds
[2024-12-14T08:14:34.223+0530] {processor.py:186} INFO - Started process (PID=25788) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:14:34.226+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T08:14:34.227+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:14:34.227+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:14:34.420+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:14:34.420+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T08:14:34.441+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:14:34.439+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 02:44:34.272068+00:00: manual__2024-12-14T02:44:34.272068+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T08:14:34.475+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:14:34.475+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=task1 map_index=-1
[2024-12-14T08:14:34.476+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:14:34.475+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.task1 manual__2024-12-14T02:44:34.272068+00:00 [scheduled]>
[2024-12-14T08:14:39.574+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:14:39.574+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T08:14:39.644+0530] {logging_mixin.py:190} INFO - [2024-12-14 08:14:39,644] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:44:34.272068+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:44:34.272068+00:00'
[2024-12-14T08:14:39.644+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:14:39.644+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:44:34.272068+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:44:34.272068+00:00'
[2024-12-14T08:14:39.657+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T08:14:39.657+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T08:14:39.658+0530] {logging_mixin.py:190} INFO - Current task name:task1 state:scheduled start_date:None
[2024-12-14T08:14:39.658+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T08:14:39.658+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:14:39.658+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T08:14:39.660+0530] {logging_mixin.py:190} INFO - 2024-12-10
[2024-12-14T08:14:39.664+0530] {logging_mixin.py:190} INFO - 2024-12-14 08:14:34.272068+05:30
[2024-12-14T08:14:39.665+0530] {logging_mixin.py:190} INFO - [2024-12-14 08:14:39,664] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T08:14:39.665+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:14:39.664+0530] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T08:14:39.671+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:14:39.671+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T08:14:39.672+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:14:39.671+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=task1, run_id=manual__2024-12-14T02:44:34.272068+00:00, execution_date=20241214T024434, start_date=, end_date=20241214T024439
[2024-12-14T08:14:39.681+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T08:14:39.681+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T08:14:39.681+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T08:14:39.682+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:_PythonDecoratedOperator
[2024-12-14T08:14:39.682+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:14:39.682+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=task1 map_index=-1
[2024-12-14T08:14:39.686+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:14:39.686+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 02:44:34.272068+00:00: manual__2024-12-14T02:44:34.272068+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T08:14:39.686+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T08:14:39.686+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 02:44:34.272068+00:00 end:2024-12-14 02:44:39.686643+00:00
[2024-12-14T08:14:39.687+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:14:39.687+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 02:44:34.272068+00:00, run_id=manual__2024-12-14T02:44:34.272068+00:00, run_start_date=2024-12-14 02:44:34.272068+00:00, run_end_date=2024-12-14 02:44:39.686643+00:00, run_duration=5.414575, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 02:44:34.272068+00:00, data_interval_end=2024-12-14 02:44:34.272068+00:00, dag_hash=None
[2024-12-14T08:14:39.696+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:14:39.709+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:14:39.708+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T08:14:39.730+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:14:39.729+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T08:14:39.749+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.530 seconds
[2024-12-14T08:17:40.144+0530] {processor.py:186} INFO - Started process (PID=26015) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:17:40.147+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T08:17:40.148+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:17:40.148+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:17:40.323+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:17:40.322+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T08:17:40.340+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:17:40.339+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 02:47:40.191541+00:00: manual__2024-12-14T02:47:40.191541+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T08:17:40.370+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:17:40.369+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=task1 map_index=-1
[2024-12-14T08:17:40.370+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:17:40.370+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.task1 manual__2024-12-14T02:47:40.191541+00:00 [scheduled]>
[2024-12-14T08:17:45.481+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:17:45.480+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T08:17:45.556+0530] {logging_mixin.py:190} INFO - [2024-12-14 08:17:45,556] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:47:40.191541+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:47:40.191541+00:00'
[2024-12-14T08:17:45.557+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:17:45.556+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:47:40.191541+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:47:40.191541+00:00'
[2024-12-14T08:17:45.567+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T08:17:45.568+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T08:17:45.568+0530] {logging_mixin.py:190} INFO - Current task name:task1 state:scheduled start_date:None
[2024-12-14T08:17:45.568+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T08:17:45.569+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:17:45.569+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T08:17:45.574+0530] {logging_mixin.py:190} INFO - 2024-12-10
[2024-12-14T08:17:45.578+0530] {logging_mixin.py:190} INFO - 2024-12-14 08:17:40.191541+05:30
[2024-12-14T08:17:45.578+0530] {logging_mixin.py:190} INFO - [2024-12-14 08:17:45,578] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T08:17:45.579+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:17:45.578+0530] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T08:17:45.583+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:17:45.583+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T08:17:45.584+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:17:45.584+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=task1, run_id=manual__2024-12-14T02:47:40.191541+00:00, execution_date=20241214T024740, start_date=, end_date=20241214T024745
[2024-12-14T08:17:45.593+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T08:17:45.594+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T08:17:45.594+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T08:17:45.594+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:_PythonDecoratedOperator
[2024-12-14T08:17:45.595+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:17:45.594+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=task1 map_index=-1
[2024-12-14T08:17:45.598+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:17:45.598+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 02:47:40.191541+00:00: manual__2024-12-14T02:47:40.191541+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T08:17:45.598+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T08:17:45.599+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 02:47:40.191541+00:00 end:2024-12-14 02:47:45.598754+00:00
[2024-12-14T08:17:45.599+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:17:45.599+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 02:47:40.191541+00:00, run_id=manual__2024-12-14T02:47:40.191541+00:00, run_start_date=2024-12-14 02:47:40.191541+00:00, run_end_date=2024-12-14 02:47:45.598754+00:00, run_duration=5.407213, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 02:47:40.191541+00:00, data_interval_end=2024-12-14 02:47:40.191541+00:00, dag_hash=None
[2024-12-14T08:17:45.608+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:17:45.621+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:17:45.621+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T08:17:45.638+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:17:45.637+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T08:17:45.665+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.524 seconds
[2024-12-14T08:20:35.724+0530] {processor.py:186} INFO - Started process (PID=26235) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:20:35.726+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T08:20:35.729+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:20:35.728+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:20:35.968+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:20:35.968+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T08:20:35.990+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:20:35.989+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 02:50:35.778227+00:00: manual__2024-12-14T02:50:35.778227+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T08:20:36.015+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:20:36.015+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=task1 map_index=-1
[2024-12-14T08:20:36.016+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:20:36.015+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.task1 manual__2024-12-14T02:50:35.778227+00:00 [scheduled]>
[2024-12-14T08:20:41.116+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:20:41.116+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T08:20:41.175+0530] {logging_mixin.py:190} INFO - [2024-12-14 08:20:41,175] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:50:35.778227+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:50:35.778227+00:00'
[2024-12-14T08:20:41.176+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:20:41.175+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:50:35.778227+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:50:35.778227+00:00'
[2024-12-14T08:20:41.179+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T08:20:41.180+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T08:20:41.180+0530] {logging_mixin.py:190} INFO - Current task name:task1 state:scheduled start_date:None
[2024-12-14T08:20:41.180+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T08:20:41.180+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:20:41.180+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T08:20:41.182+0530] {logging_mixin.py:190} INFO - 2024-12-10
[2024-12-14T08:20:41.186+0530] {logging_mixin.py:190} INFO - 2024-12-14 08:20:35.778227+05:30
[2024-12-14T08:20:41.187+0530] {logging_mixin.py:190} INFO - [2024-12-14 08:20:41,187] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T08:20:41.187+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:20:41.187+0530] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T08:20:41.192+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:20:41.191+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T08:20:41.192+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:20:41.192+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=task1, run_id=manual__2024-12-14T02:50:35.778227+00:00, execution_date=20241214T025035, start_date=, end_date=20241214T025041
[2024-12-14T08:20:41.202+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T08:20:41.203+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T08:20:41.203+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T08:20:41.203+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:_PythonDecoratedOperator
[2024-12-14T08:20:41.203+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:20:41.203+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=task1 map_index=-1
[2024-12-14T08:20:41.207+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:20:41.207+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 02:50:35.778227+00:00: manual__2024-12-14T02:50:35.778227+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T08:20:41.207+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T08:20:41.207+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 02:50:35.778227+00:00 end:2024-12-14 02:50:41.207603+00:00
[2024-12-14T08:20:41.208+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:20:41.208+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 02:50:35.778227+00:00, run_id=manual__2024-12-14T02:50:35.778227+00:00, run_start_date=2024-12-14 02:50:35.778227+00:00, run_end_date=2024-12-14 02:50:41.207603+00:00, run_duration=5.429376, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 02:50:35.778227+00:00, data_interval_end=2024-12-14 02:50:35.778227+00:00, dag_hash=None
[2024-12-14T08:20:41.217+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:20:41.229+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:20:41.228+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T08:20:41.245+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:20:41.244+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T08:20:41.264+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.545 seconds
[2024-12-14T08:23:31.192+0530] {processor.py:186} INFO - Started process (PID=26434) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:23:31.194+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T08:23:31.195+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:23:31.195+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:23:31.369+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:23:31.369+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T08:23:31.384+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:23:31.384+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 02:53:31.237487+00:00: manual__2024-12-14T02:53:31.237487+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T08:23:31.409+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:23:31.409+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=task1 map_index=-1
[2024-12-14T08:23:31.409+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:23:31.409+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.task1 manual__2024-12-14T02:53:31.237487+00:00 [scheduled]>
[2024-12-14T08:23:36.507+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:23:36.507+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T08:23:36.568+0530] {logging_mixin.py:190} INFO - [2024-12-14 08:23:36,568] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:53:31.237487+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:53:31.237487+00:00'
[2024-12-14T08:23:36.569+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:23:36.568+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:53:31.237487+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:53:31.237487+00:00'
[2024-12-14T08:23:36.571+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T08:23:36.571+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T08:23:36.572+0530] {logging_mixin.py:190} INFO - Current task name:task1 state:scheduled start_date:None
[2024-12-14T08:23:36.572+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T08:23:36.573+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:23:36.573+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T08:23:36.575+0530] {logging_mixin.py:190} INFO - 2024-12-10
[2024-12-14T08:23:36.579+0530] {logging_mixin.py:190} INFO - 2024-12-14 08:23:31.237487+05:30
[2024-12-14T08:23:36.580+0530] {logging_mixin.py:190} INFO - [2024-12-14 08:23:36,579] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T08:23:36.580+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:23:36.579+0530] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T08:23:36.586+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:23:36.586+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T08:23:36.586+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:23:36.586+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=task1, run_id=manual__2024-12-14T02:53:31.237487+00:00, execution_date=20241214T025331, start_date=, end_date=20241214T025336
[2024-12-14T08:23:36.595+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T08:23:36.596+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T08:23:36.596+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T08:23:36.596+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:_PythonDecoratedOperator
[2024-12-14T08:23:36.597+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:23:36.596+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=task1 map_index=-1
[2024-12-14T08:23:36.601+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:23:36.600+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 02:53:31.237487+00:00: manual__2024-12-14T02:53:31.237487+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T08:23:36.601+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T08:23:36.601+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 02:53:31.237487+00:00 end:2024-12-14 02:53:36.601510+00:00
[2024-12-14T08:23:36.602+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:23:36.602+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 02:53:31.237487+00:00, run_id=manual__2024-12-14T02:53:31.237487+00:00, run_start_date=2024-12-14 02:53:31.237487+00:00, run_end_date=2024-12-14 02:53:36.601510+00:00, run_duration=5.364023, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 02:53:31.237487+00:00, data_interval_end=2024-12-14 02:53:31.237487+00:00, dag_hash=None
[2024-12-14T08:23:36.610+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:23:36.622+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:23:36.621+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T08:23:36.638+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:23:36.638+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T08:23:36.658+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.471 seconds
[2024-12-14T08:26:26.384+0530] {processor.py:186} INFO - Started process (PID=26641) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:26:26.385+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T08:26:26.386+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:26:26.386+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:26:26.562+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:26:26.562+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T08:26:26.578+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:26:26.577+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 02:56:26.430285+00:00: manual__2024-12-14T02:56:26.430285+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T08:26:26.604+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:26:26.604+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=task1 map_index=-1
[2024-12-14T08:26:26.606+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:26:26.605+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.task1 manual__2024-12-14T02:56:26.430285+00:00 [scheduled]>
[2024-12-14T08:26:31.701+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:26:31.701+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T08:26:31.764+0530] {logging_mixin.py:190} INFO - [2024-12-14 08:26:31,764] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:56:26.430285+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:56:26.430285+00:00'
[2024-12-14T08:26:31.765+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:26:31.764+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:56:26.430285+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:56:26.430285+00:00'
[2024-12-14T08:26:31.768+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T08:26:31.768+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T08:26:31.768+0530] {logging_mixin.py:190} INFO - Current task name:task1 state:scheduled start_date:None
[2024-12-14T08:26:31.768+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T08:26:31.769+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:26:31.769+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T08:26:31.771+0530] {logging_mixin.py:190} INFO - 2024-12-10
[2024-12-14T08:26:31.775+0530] {logging_mixin.py:190} INFO - 2024-12-14 08:26:26.430285+05:30
[2024-12-14T08:26:31.776+0530] {logging_mixin.py:190} INFO - [2024-12-14 08:26:31,776] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T08:26:31.776+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:26:31.776+0530] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T08:26:31.781+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:26:31.781+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T08:26:31.782+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:26:31.782+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=task1, run_id=manual__2024-12-14T02:56:26.430285+00:00, execution_date=20241214T025626, start_date=, end_date=20241214T025631
[2024-12-14T08:26:31.792+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T08:26:31.793+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T08:26:31.793+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T08:26:31.793+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:_PythonDecoratedOperator
[2024-12-14T08:26:31.793+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:26:31.793+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=task1 map_index=-1
[2024-12-14T08:26:31.797+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:26:31.797+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 02:56:26.430285+00:00: manual__2024-12-14T02:56:26.430285+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T08:26:31.797+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T08:26:31.797+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 02:56:26.430285+00:00 end:2024-12-14 02:56:31.797628+00:00
[2024-12-14T08:26:31.798+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:26:31.798+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 02:56:26.430285+00:00, run_id=manual__2024-12-14T02:56:26.430285+00:00, run_start_date=2024-12-14 02:56:26.430285+00:00, run_end_date=2024-12-14 02:56:31.797628+00:00, run_duration=5.367343, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 02:56:26.430285+00:00, data_interval_end=2024-12-14 02:56:26.430285+00:00, dag_hash=None
[2024-12-14T08:26:31.807+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:26:31.820+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:26:31.820+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T08:26:31.838+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:26:31.838+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T08:26:31.863+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.483 seconds
[2024-12-14T08:29:18.644+0530] {processor.py:186} INFO - Started process (PID=26836) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:29:18.645+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T08:29:18.647+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:29:18.646+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:29:18.821+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:29:18.821+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T08:29:18.837+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:29:18.837+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 02:59:18.689114+00:00: manual__2024-12-14T02:59:18.689114+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T08:29:18.862+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:29:18.861+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=task1 map_index=-1
[2024-12-14T08:29:18.862+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:29:18.862+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.task1 manual__2024-12-14T02:59:18.689114+00:00 [scheduled]>
[2024-12-14T08:29:23.956+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:29:23.956+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T08:29:24.019+0530] {logging_mixin.py:190} INFO - [2024-12-14 08:29:24,018] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:59:18.689114+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:59:18.689114+00:00'
[2024-12-14T08:29:24.019+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:29:24.018+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T02:59:18.689114+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T02:59:18.689114+00:00'
[2024-12-14T08:29:24.022+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T08:29:24.022+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T08:29:24.022+0530] {logging_mixin.py:190} INFO - Current task name:task1 state:scheduled start_date:None
[2024-12-14T08:29:24.023+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T08:29:24.023+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:29:24.023+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T08:29:24.025+0530] {logging_mixin.py:190} INFO - 2024-12-10
[2024-12-14T08:29:24.029+0530] {logging_mixin.py:190} INFO - 2024-12-14 08:29:18.689114+05:30
[2024-12-14T08:29:24.029+0530] {logging_mixin.py:190} INFO - [2024-12-14 08:29:24,029] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T08:29:24.030+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:29:24.029+0530] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T08:29:24.034+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:29:24.034+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T08:29:24.035+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:29:24.035+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=task1, run_id=manual__2024-12-14T02:59:18.689114+00:00, execution_date=20241214T025918, start_date=, end_date=20241214T025924
[2024-12-14T08:29:24.044+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T08:29:24.044+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T08:29:24.045+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T08:29:24.045+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:_PythonDecoratedOperator
[2024-12-14T08:29:24.046+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:29:24.045+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=task1 map_index=-1
[2024-12-14T08:29:24.049+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:29:24.049+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 02:59:18.689114+00:00: manual__2024-12-14T02:59:18.689114+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T08:29:24.050+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T08:29:24.050+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 02:59:18.689114+00:00 end:2024-12-14 02:59:24.049961+00:00
[2024-12-14T08:29:24.050+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:29:24.050+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 02:59:18.689114+00:00, run_id=manual__2024-12-14T02:59:18.689114+00:00, run_start_date=2024-12-14 02:59:18.689114+00:00, run_end_date=2024-12-14 02:59:24.049961+00:00, run_duration=5.360847, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 02:59:18.689114+00:00, data_interval_end=2024-12-14 02:59:18.689114+00:00, dag_hash=None
[2024-12-14T08:29:24.060+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:29:24.073+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:29:24.073+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T08:29:24.091+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:29:24.091+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T08:29:24.112+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.472 seconds
[2024-12-14T08:32:13.385+0530] {processor.py:186} INFO - Started process (PID=27044) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:32:13.386+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T08:32:13.387+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:32:13.387+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:32:13.556+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:32:13.555+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T08:32:13.571+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:32:13.570+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 03:02:13.426629+00:00: manual__2024-12-14T03:02:13.426629+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T08:32:13.595+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:32:13.595+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=task1 map_index=-1
[2024-12-14T08:32:13.595+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:32:13.595+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.task1 manual__2024-12-14T03:02:13.426629+00:00 [scheduled]>
[2024-12-14T08:32:18.692+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:32:18.692+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T08:32:18.753+0530] {logging_mixin.py:190} INFO - [2024-12-14 08:32:18,752] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T03:02:13.426629+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T03:02:13.426629+00:00'
[2024-12-14T08:32:18.753+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:32:18.752+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T03:02:13.426629+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T03:02:13.426629+00:00'
[2024-12-14T08:32:18.756+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T08:32:18.756+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T08:32:18.756+0530] {logging_mixin.py:190} INFO - Current task name:task1 state:scheduled start_date:None
[2024-12-14T08:32:18.757+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T08:32:18.757+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:32:18.757+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T08:32:18.759+0530] {logging_mixin.py:190} INFO - 2024-12-10
[2024-12-14T08:32:18.762+0530] {logging_mixin.py:190} INFO - 2024-12-14 08:32:13.426629+05:30
[2024-12-14T08:32:18.763+0530] {logging_mixin.py:190} INFO - [2024-12-14 08:32:18,763] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T08:32:18.763+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:32:18.763+0530] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T08:32:18.768+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:32:18.768+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T08:32:18.769+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:32:18.769+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=task1, run_id=manual__2024-12-14T03:02:13.426629+00:00, execution_date=20241214T030213, start_date=, end_date=20241214T030218
[2024-12-14T08:32:18.780+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T08:32:18.780+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T08:32:18.781+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T08:32:18.781+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:_PythonDecoratedOperator
[2024-12-14T08:32:18.782+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:32:18.782+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=task1 map_index=-1
[2024-12-14T08:32:18.787+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:32:18.787+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 03:02:13.426629+00:00: manual__2024-12-14T03:02:13.426629+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T08:32:18.787+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T08:32:18.788+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 03:02:13.426629+00:00 end:2024-12-14 03:02:18.787874+00:00
[2024-12-14T08:32:18.788+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:32:18.788+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 03:02:13.426629+00:00, run_id=manual__2024-12-14T03:02:13.426629+00:00, run_start_date=2024-12-14 03:02:13.426629+00:00, run_end_date=2024-12-14 03:02:18.787874+00:00, run_duration=5.361245, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 03:02:13.426629+00:00, data_interval_end=2024-12-14 03:02:13.426629+00:00, dag_hash=None
[2024-12-14T08:32:18.797+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:32:18.809+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:32:18.808+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T08:32:18.826+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:32:18.826+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T08:32:18.845+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.464 seconds
[2024-12-14T08:35:06.669+0530] {processor.py:186} INFO - Started process (PID=27238) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:35:06.672+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T08:35:06.673+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:35:06.673+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:35:06.844+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:35:06.844+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T08:35:06.859+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:35:06.859+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 03:05:06.715478+00:00: manual__2024-12-14T03:05:06.715478+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T08:35:06.888+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:35:06.888+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=task1 map_index=-1
[2024-12-14T08:35:06.889+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:35:06.889+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.task1 manual__2024-12-14T03:05:06.715478+00:00 [scheduled]>
[2024-12-14T08:35:11.997+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:35:11.997+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T08:35:12.064+0530] {logging_mixin.py:190} INFO - [2024-12-14 08:35:12,064] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T03:05:06.715478+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T03:05:06.715478+00:00'
[2024-12-14T08:35:12.064+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:35:12.064+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T03:05:06.715478+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T03:05:06.715478+00:00'
[2024-12-14T08:35:12.077+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T08:35:12.077+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T08:35:12.077+0530] {logging_mixin.py:190} INFO - Current task name:task1 state:scheduled start_date:None
[2024-12-14T08:35:12.078+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T08:35:12.078+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:35:12.078+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T08:35:12.081+0530] {logging_mixin.py:190} INFO - 2024-12-10
[2024-12-14T08:35:12.086+0530] {logging_mixin.py:190} INFO - 2024-12-14 08:35:06.715478+05:30
[2024-12-14T08:35:12.086+0530] {logging_mixin.py:190} INFO - [2024-12-14 08:35:12,086] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T08:35:12.086+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:35:12.086+0530] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T08:35:12.092+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:35:12.091+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T08:35:12.092+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:35:12.092+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=task1, run_id=manual__2024-12-14T03:05:06.715478+00:00, execution_date=20241214T030506, start_date=, end_date=20241214T030512
[2024-12-14T08:35:12.101+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T08:35:12.101+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T08:35:12.102+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T08:35:12.102+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:_PythonDecoratedOperator
[2024-12-14T08:35:12.102+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:35:12.102+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=task1 map_index=-1
[2024-12-14T08:35:12.106+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:35:12.106+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 03:05:06.715478+00:00: manual__2024-12-14T03:05:06.715478+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T08:35:12.106+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T08:35:12.107+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 03:05:06.715478+00:00 end:2024-12-14 03:05:12.106741+00:00
[2024-12-14T08:35:12.107+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:35:12.107+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 03:05:06.715478+00:00, run_id=manual__2024-12-14T03:05:06.715478+00:00, run_start_date=2024-12-14 03:05:06.715478+00:00, run_end_date=2024-12-14 03:05:12.106741+00:00, run_duration=5.391263, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 03:05:06.715478+00:00, data_interval_end=2024-12-14 03:05:06.715478+00:00, dag_hash=None
[2024-12-14T08:35:12.115+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:35:12.127+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:35:12.127+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T08:35:12.145+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:35:12.145+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T08:35:12.163+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.497 seconds
[2024-12-14T08:38:02.739+0530] {processor.py:186} INFO - Started process (PID=27447) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:38:02.741+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T08:38:02.743+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:38:02.743+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:38:02.914+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:38:02.914+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T08:38:02.930+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:38:02.930+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 03:08:02.785872+00:00: manual__2024-12-14T03:08:02.785872+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T08:38:02.959+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:38:02.959+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=task1 map_index=-1
[2024-12-14T08:38:02.960+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:38:02.960+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.task1 manual__2024-12-14T03:08:02.785872+00:00 [scheduled]>
[2024-12-14T08:38:08.057+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:38:08.057+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T08:38:08.126+0530] {logging_mixin.py:190} INFO - [2024-12-14 08:38:08,126] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T03:08:02.785872+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T03:08:02.785872+00:00'
[2024-12-14T08:38:08.127+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:38:08.126+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='task1' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T03:08:02.785872+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T03:08:02.785872+00:00'
[2024-12-14T08:38:08.139+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T08:38:08.139+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T08:38:08.139+0530] {logging_mixin.py:190} INFO - Current task name:task1 state:scheduled start_date:None
[2024-12-14T08:38:08.140+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T08:38:08.140+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:38:08.140+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T08:38:08.143+0530] {logging_mixin.py:190} INFO - 2024-12-10
[2024-12-14T08:38:08.149+0530] {logging_mixin.py:190} INFO - 2024-12-14 08:38:02.785872+05:30
[2024-12-14T08:38:08.149+0530] {logging_mixin.py:190} INFO - [2024-12-14 08:38:08,149] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T08:38:08.150+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:38:08.149+0530] {python.py:240} INFO - Done. Returned value was: None
[2024-12-14T08:38:08.154+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:38:08.154+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T08:38:08.155+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:38:08.154+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=task1, run_id=manual__2024-12-14T03:08:02.785872+00:00, execution_date=20241214T030802, start_date=, end_date=20241214T030808
[2024-12-14T08:38:08.164+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T08:38:08.165+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T08:38:08.165+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T08:38:08.165+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:_PythonDecoratedOperator
[2024-12-14T08:38:08.166+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:38:08.165+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=task1 map_index=-1
[2024-12-14T08:38:08.169+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:38:08.169+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 03:08:02.785872+00:00: manual__2024-12-14T03:08:02.785872+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T08:38:08.169+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T08:38:08.170+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 03:08:02.785872+00:00 end:2024-12-14 03:08:08.169774+00:00
[2024-12-14T08:38:08.170+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:38:08.170+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 03:08:02.785872+00:00, run_id=manual__2024-12-14T03:08:02.785872+00:00, run_start_date=2024-12-14 03:08:02.785872+00:00, run_end_date=2024-12-14 03:08:08.169774+00:00, run_duration=5.383902, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 03:08:02.785872+00:00, data_interval_end=2024-12-14 03:08:02.785872+00:00, dag_hash=None
[2024-12-14T08:38:08.179+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:38:08.190+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:38:08.190+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T08:38:08.206+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:38:08.206+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T08:38:08.226+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.490 seconds
[2024-12-14T08:41:09.543+0530] {processor.py:186} INFO - Started process (PID=27705) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:41:09.545+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T08:41:09.548+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:41:09.547+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:41:09.599+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:41:09.737+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:41:09.737+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T08:41:09.761+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:41:09.761+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T08:41:09.787+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.247 seconds
[2024-12-14T08:44:12.526+0530] {processor.py:186} INFO - Started process (PID=28134) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:44:12.528+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T08:44:12.530+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:44:12.530+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:44:12.609+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:44:12.738+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:44:12.738+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T08:44:12.768+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:44:12.767+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T08:44:12.803+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.281 seconds
[2024-12-14T08:47:22.638+0530] {processor.py:186} INFO - Started process (PID=28575) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:47:22.640+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T08:47:22.641+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:47:22.641+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:47:22.698+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:47:22.846+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:47:22.845+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T08:47:22.869+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:47:22.869+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T08:47:22.900+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.267 seconds
[2024-12-14T08:50:36.385+0530] {processor.py:186} INFO - Started process (PID=28927) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:50:36.388+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T08:50:36.389+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:50:36.389+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:50:36.437+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:50:36.570+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:50:36.569+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T08:50:36.594+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:50:36.593+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T08:50:36.620+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.240 seconds
[2024-12-14T08:53:38.452+0530] {processor.py:186} INFO - Started process (PID=29141) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:53:38.459+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T08:53:38.462+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:53:38.461+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:53:38.551+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:53:38.753+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:53:38.752+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T08:53:38.784+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:53:38.784+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T08:53:38.823+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.380 seconds
[2024-12-14T08:56:46.131+0530] {processor.py:186} INFO - Started process (PID=29527) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:56:46.134+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T08:56:46.135+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:56:46.135+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:56:46.185+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T08:56:46.505+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:56:46.505+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T08:56:46.530+0530] {logging_mixin.py:190} INFO - [2024-12-14T08:56:46.529+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T08:56:46.588+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.464 seconds
[2024-12-14T09:00:05.381+0530] {processor.py:186} INFO - Started process (PID=29919) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:00:05.384+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T09:00:05.386+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:00:05.386+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:00:05.543+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:00:05.774+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:00:05.774+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T09:00:05.798+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:00:05.797+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T09:00:05.824+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.447 seconds
[2024-12-14T09:03:15.210+0530] {processor.py:186} INFO - Started process (PID=30320) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:03:15.212+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T09:03:15.214+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:03:15.214+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:03:15.369+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:03:15.567+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:03:15.567+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T09:03:15.589+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:03:15.589+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T09:03:15.612+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.406 seconds
[2024-12-14T09:06:16.234+0530] {processor.py:186} INFO - Started process (PID=30680) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:06:16.237+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T09:06:16.238+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:06:16.238+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:06:16.364+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:06:16.380+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:06:16.379+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T09:06:16.403+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:06:16.403+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T09:06:16.430+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.199 seconds
[2024-12-14T09:09:14.273+0530] {processor.py:186} INFO - Started process (PID=31057) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:09:14.275+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T09:09:14.277+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:09:14.277+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:09:14.405+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:09:14.422+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:09:14.422+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T09:09:14.443+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:09:14.443+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T09:09:14.466+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.197 seconds
[2024-12-14T09:12:07.093+0530] {processor.py:186} INFO - Started process (PID=31401) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:12:07.095+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T09:12:07.097+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:12:07.097+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:12:07.218+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:12:07.236+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:12:07.236+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T09:12:07.258+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:12:07.258+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T09:12:07.279+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.190 seconds
[2024-12-14T09:15:00.346+0530] {processor.py:186} INFO - Started process (PID=31735) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:15:00.347+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T09:15:00.348+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:15:00.348+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:15:00.468+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:15:00.485+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:15:00.485+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T09:15:00.505+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:15:00.505+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T09:15:00.526+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.184 seconds
[2024-12-14T09:17:48.554+0530] {processor.py:186} INFO - Started process (PID=32076) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:17:48.556+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T09:17:48.557+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:17:48.557+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:17:48.678+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:17:48.696+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:17:48.696+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T09:17:48.717+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:17:48.716+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T09:17:48.737+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.187 seconds
[2024-12-14T09:20:41.205+0530] {processor.py:186} INFO - Started process (PID=32422) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:20:41.207+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T09:20:41.208+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:20:41.208+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:20:41.329+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:20:41.345+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:20:41.344+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T09:20:41.365+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:20:41.364+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T09:20:41.386+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.185 seconds
[2024-12-14T09:23:31.660+0530] {processor.py:186} INFO - Started process (PID=32754) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:23:31.661+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T09:23:31.662+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:23:31.662+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:23:31.793+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:23:31.810+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:23:31.810+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T09:23:31.833+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:23:31.833+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T09:23:31.855+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.200 seconds
[2024-12-14T09:26:21.335+0530] {processor.py:186} INFO - Started process (PID=33090) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:26:21.336+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T09:26:21.337+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:26:21.337+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:26:21.496+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:26:21.513+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:26:21.513+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T09:26:21.534+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:26:21.534+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T09:26:21.557+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.226 seconds
[2024-12-14T09:29:12.229+0530] {processor.py:186} INFO - Started process (PID=33417) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:29:12.231+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T09:29:12.232+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:29:12.232+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:29:12.361+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:29:12.380+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:29:12.380+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T09:29:12.401+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:29:12.400+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T09:29:12.425+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.199 seconds
[2024-12-14T09:32:02.949+0530] {processor.py:186} INFO - Started process (PID=33763) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:32:02.951+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T09:32:02.953+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:32:02.952+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:32:03.073+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:32:03.089+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:32:03.089+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T09:32:03.112+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:32:03.112+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T09:32:03.133+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.189 seconds
[2024-12-14T09:34:53.901+0530] {processor.py:186} INFO - Started process (PID=34092) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:34:53.904+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T09:34:53.906+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:34:53.906+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:34:54.036+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:34:54.053+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:34:54.053+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T09:34:54.076+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:34:54.075+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T09:34:54.098+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.201 seconds
[2024-12-14T09:37:43.487+0530] {processor.py:186} INFO - Started process (PID=34416) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:37:43.490+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T09:37:43.492+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:37:43.492+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:37:43.619+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:37:43.635+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:37:43.635+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T09:37:43.662+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:37:43.661+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T09:37:43.702+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.219 seconds
[2024-12-14T09:40:31.883+0530] {processor.py:186} INFO - Started process (PID=34753) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:40:31.886+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T09:40:31.889+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:40:31.888+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:40:32.016+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:40:32.034+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:40:32.034+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T09:40:32.057+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:40:32.056+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T09:40:32.078+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.200 seconds
[2024-12-14T09:43:22.133+0530] {processor.py:186} INFO - Started process (PID=35084) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:43:22.134+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T09:43:22.135+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:43:22.135+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:43:22.284+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:43:22.300+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:43:22.300+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T09:43:22.334+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:43:22.334+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T09:43:22.356+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.226 seconds
[2024-12-14T09:46:10.204+0530] {processor.py:186} INFO - Started process (PID=35418) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:46:10.206+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T09:46:10.208+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:46:10.208+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:46:10.331+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:46:10.348+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:46:10.347+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T09:46:10.372+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:46:10.371+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T09:46:10.392+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.192 seconds
[2024-12-14T09:48:59.974+0530] {processor.py:186} INFO - Started process (PID=35754) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:48:59.977+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T09:48:59.978+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:48:59.978+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:49:00.104+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:49:00.122+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:49:00.122+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T09:49:00.144+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:49:00.143+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T09:49:00.164+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.194 seconds
[2024-12-14T09:52:00.387+0530] {processor.py:186} INFO - Started process (PID=36147) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:52:00.389+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T09:52:00.391+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:52:00.391+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:52:00.512+0530] {logging_mixin.py:190} INFO - 2024-12-14
[2024-12-14T09:52:00.541+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:52:00.540+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T09:52:00.552+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:52:00.552+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 04:22:00.512384+00:00: manual__2024-12-14T04:22:00.512384+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T09:52:00.561+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:52:00.560+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 04:22:00.512384+00:00: manual__2024-12-14T04:22:00.512384+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T09:52:00.567+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:52:00.567+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T09:52:00.587+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T09:52:00.587+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 04:22:00.512384+00:00 end:2024-12-14 04:22:00.561832+00:00
[2024-12-14T09:52:00.588+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:52:00.588+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 04:22:00.512384+00:00, run_id=manual__2024-12-14T04:22:00.512384+00:00, run_start_date=2024-12-14 04:22:00.512384+00:00, run_end_date=2024-12-14 04:22:00.561832+00:00, run_duration=0.049448, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 04:22:00.512384+00:00, data_interval_end=2024-12-14 04:22:00.512384+00:00, dag_hash=None
[2024-12-14T09:52:00.601+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:52:00.790+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:52:00.789+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T09:52:00.811+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:52:00.810+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T09:52:00.840+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.457 seconds
[2024-12-14T09:54:59.177+0530] {processor.py:186} INFO - Started process (PID=36485) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:54:59.180+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T09:54:59.183+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:54:59.182+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:54:59.311+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:54:59.502+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:54:59.501+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T09:54:59.520+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:54:59.520+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T09:54:59.546+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.373 seconds
[2024-12-14T09:57:50.340+0530] {processor.py:186} INFO - Started process (PID=36828) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:57:50.343+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T09:57:50.344+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:57:50.344+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:57:50.472+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T09:57:50.490+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:57:50.489+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T09:57:50.512+0530] {logging_mixin.py:190} INFO - [2024-12-14T09:57:50.511+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T09:57:50.533+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.197 seconds
[2024-12-14T10:00:56.272+0530] {processor.py:186} INFO - Started process (PID=37104) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:00:56.275+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T10:00:56.279+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:00:56.277+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:00:56.434+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:00:56.456+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:00:56.456+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T10:00:56.483+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:00:56.482+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T10:00:56.506+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.238 seconds
[2024-12-14T10:04:01.408+0530] {processor.py:186} INFO - Started process (PID=37344) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:04:01.411+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T10:04:01.412+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:04:01.412+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:04:01.536+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:04:01.552+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:04:01.552+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T10:04:01.572+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:04:01.572+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T10:04:01.594+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.190 seconds
[2024-12-14T10:06:54.045+0530] {processor.py:186} INFO - Started process (PID=37570) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:06:54.047+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T10:06:54.048+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:06:54.048+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:06:54.169+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:06:54.189+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:06:54.189+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T10:06:54.213+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:06:54.213+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T10:06:54.241+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.200 seconds
[2024-12-14T10:09:45.866+0530] {processor.py:186} INFO - Started process (PID=37800) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:09:45.869+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T10:09:45.870+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:09:45.870+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:09:46.002+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:09:46.019+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:09:46.019+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T10:09:46.042+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:09:46.042+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T10:09:46.064+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.202 seconds
[2024-12-14T10:12:50.151+0530] {processor.py:186} INFO - Started process (PID=38176) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:12:50.153+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T10:12:50.155+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:12:50.155+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:12:50.278+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:12:50.295+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:12:50.294+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T10:12:50.317+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:12:50.317+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T10:12:50.342+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.196 seconds
[2024-12-14T10:16:14.456+0530] {processor.py:186} INFO - Started process (PID=38505) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:16:14.459+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T10:16:14.460+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:16:14.460+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:16:14.589+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:16:14.805+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:16:14.805+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T10:16:14.827+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:16:14.827+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T10:16:14.852+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.399 seconds
[2024-12-14T10:16:41.371+0530] {processor.py:186} INFO - Started process (PID=38546) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:16:41.373+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T10:16:41.377+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:16:41.376+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:16:41.534+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:16:41.538+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:16:41.538+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T10:16:41.570+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:16:41.569+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T10:16:41.595+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.229 seconds
[2024-12-14T10:19:34.711+0530] {processor.py:186} INFO - Started process (PID=38870) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:19:34.714+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T10:19:34.716+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:19:34.715+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:19:34.843+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:19:34.860+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:19:34.859+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T10:19:34.883+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:19:34.883+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T10:19:34.912+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.205 seconds
[2024-12-14T10:22:44.558+0530] {processor.py:186} INFO - Started process (PID=39256) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:22:44.561+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T10:22:44.562+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:22:44.562+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:22:44.800+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:22:45.375+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:22:45.375+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T10:22:45.397+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:22:45.396+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T10:22:45.421+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.866 seconds
[2024-12-14T10:22:50.021+0530] {processor.py:186} INFO - Started process (PID=39260) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:22:50.022+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T10:22:50.023+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:22:50.023+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:22:50.159+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:22:50.163+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:22:50.163+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T10:22:50.184+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:22:50.184+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T10:22:50.214+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.197 seconds
[2024-12-14T10:26:03.032+0530] {processor.py:186} INFO - Started process (PID=39570) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:26:03.035+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T10:26:03.038+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:26:03.037+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:26:03.164+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:26:03.180+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:26:03.180+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T10:26:03.203+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:26:03.203+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T10:26:03.228+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.199 seconds
[2024-12-14T10:26:37.639+0530] {processor.py:186} INFO - Started process (PID=39619) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:26:37.642+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T10:26:37.643+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:26:37.643+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:26:38.019+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:26:38.489+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:26:38.489+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T10:26:38.511+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:26:38.511+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T10:26:38.536+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.901 seconds
[2024-12-14T10:29:18.647+0530] {processor.py:186} INFO - Started process (PID=39822) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:29:18.649+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T10:29:18.652+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:29:18.651+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:29:18.778+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:29:18.795+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:29:18.794+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T10:29:18.816+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:29:18.816+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T10:29:18.838+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.195 seconds
[2024-12-14T10:32:43.845+0530] {processor.py:186} INFO - Started process (PID=40166) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:32:43.848+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T10:32:43.849+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:43.849+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:32:44.017+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:44.016+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T10:32:44.036+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:44.035+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 05:02:43.986520+00:00: manual__2024-12-14T05:02:43.986520+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T10:32:44.066+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:44.066+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T10:32:44.067+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:44.066+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T05:02:43.986520+00:00 [scheduled]>
[2024-12-14T10:32:49.102+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.102+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T10:32:49.241+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:32:49,241] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:02:43.986520+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:02:43.986520+00:00'
[2024-12-14T10:32:49.241+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.241+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:02:43.986520+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:02:43.986520+00:00'
[2024-12-14T10:32:49.253+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T10:32:49.254+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T10:32:49.254+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T10:32:49.254+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T10:32:49.255+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.255+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T10:32:49.321+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:32:49,320] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:32:49.326+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.320+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:32:49.327+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:32:49,327] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T10:32:49.328+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.327+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T10:32:49.342+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:32:49,340] {subprocess.py:99} INFO - Output:
[2024-12-14T10:32:49.343+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.340+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T10:32:49.356+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:32:49,356] {subprocess.py:106} INFO - scraping started
[2024-12-14T10:32:49.357+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.356+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T10:32:49.358+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:32:49,358] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T10:32:49.358+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.358+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T10:32:49.383+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.383+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T10:32:49.384+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.384+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T05:02:43.986520+00:00, execution_date=20241214T050243, start_date=, end_date=20241214T050249
[2024-12-14T10:32:49.394+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T10:32:49.395+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T10:32:49.395+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T10:32:49.395+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T10:32:49.396+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.395+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T10:32:49.412+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.411+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T10:32:49.412+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.412+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:02:43.986520+00:00 [scheduled]>
[2024-12-14T10:32:49.440+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:32:49,440] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:02:43.986520+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:02:43.986520+00:00'
[2024-12-14T10:32:49.441+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.440+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:02:43.986520+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:02:43.986520+00:00'
[2024-12-14T10:32:49.441+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T10:32:49.441+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T10:32:49.442+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T10:32:49.442+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T10:32:49.442+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.442+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T10:32:49.443+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:32:49,443] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:32:49.443+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.443+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:32:49.443+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:32:49,443] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T10:32:49.444+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.443+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T10:32:49.454+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:32:49,452] {subprocess.py:99} INFO - Output:
[2024-12-14T10:32:49.456+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.452+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T10:32:49.505+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:32:49,505] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp9yr5gd8s/controller.py': [Errno 2] No such file or directory
[2024-12-14T10:32:49.506+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.505+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp9yr5gd8s/controller.py': [Errno 2] No such file or directory
[2024-12-14T10:32:49.511+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:32:49,510] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T10:32:49.511+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.510+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T10:32:49.524+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:32:49,519] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:32:49.525+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.519+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:32:49.527+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T10:32:49.527+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 05:02:49.526618+00:00 duration:None
[2024-12-14T10:32:49.527+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 05:02:43.986520+00:00: manual__2024-12-14T05:02:43.986520+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T10:32:49.527+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:32:49.528+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.528+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T05:02:43.986520+00:00, execution_date=20241214T050243, start_date=, end_date=20241214T050249
[2024-12-14T10:32:49.539+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.539+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T10:32:49.545+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.539+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:02:43.986520+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:32:49.549+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.548+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 05:02:43.986520+00:00: manual__2024-12-14T05:02:43.986520+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T10:32:49.549+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T10:32:49.549+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T05:02:43.986520+00:00 external trigger: False
[2024-12-14T10:32:49.549+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T10:32:49.550+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.550+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 05:02:43.986520+00:00, run_id=manual__2024-12-14T05:02:43.986520+00:00, run_start_date=2024-12-14 05:02:43.986520+00:00, run_end_date=2024-12-14 05:02:49.549517+00:00, run_duration=5.562997, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 05:02:43.986520+00:00, data_interval_end=2024-12-14 05:02:43.986520+00:00, dag_hash=None
[2024-12-14T10:32:49.559+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:32:49.575+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.575+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T10:32:49.597+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:32:49.596+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T10:32:49.618+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.776 seconds
[2024-12-14T10:36:56.414+0530] {processor.py:186} INFO - Started process (PID=40498) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:36:56.417+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T10:36:56.419+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:36:56.418+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:36:56.609+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:36:56.609+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T10:36:56.627+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:36:56.627+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 05:06:56.566992+00:00: manual__2024-12-14T05:06:56.566992+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T10:36:56.666+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:36:56.666+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T10:36:56.666+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:36:56.666+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T05:06:56.566992+00:00 [scheduled]>
[2024-12-14T10:37:01.698+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:01.698+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T10:37:01.858+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:37:01,858] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:06:56.566992+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:06:56.566992+00:00'
[2024-12-14T10:37:01.859+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:01.858+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:06:56.566992+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:06:56.566992+00:00'
[2024-12-14T10:37:01.873+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T10:37:01.874+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T10:37:01.874+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T10:37:01.874+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T10:37:01.875+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:01.875+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T10:37:01.911+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:37:01,910] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:37:01.911+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:01.910+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:37:01.912+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:37:01,911] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T10:37:01.912+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:01.911+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T10:37:01.925+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:37:01,919] {subprocess.py:99} INFO - Output:
[2024-12-14T10:37:01.927+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:01.919+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T10:37:01.927+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:37:01,927] {subprocess.py:106} INFO - scraping started
[2024-12-14T10:37:01.928+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:01.927+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T10:37:01.928+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:37:01,928] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T10:37:01.928+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:01.928+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T10:37:01.951+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:01.951+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T10:37:01.952+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:01.952+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T05:06:56.566992+00:00, execution_date=20241214T050656, start_date=, end_date=20241214T050701
[2024-12-14T10:37:01.968+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T10:37:01.968+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T10:37:01.968+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T10:37:01.968+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T10:37:01.969+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:01.969+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T10:37:01.986+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:01.985+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T10:37:01.986+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:01.986+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:06:56.566992+00:00 [scheduled]>
[2024-12-14T10:37:02.019+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:37:02,019] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:06:56.566992+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:06:56.566992+00:00'
[2024-12-14T10:37:02.020+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:02.019+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:06:56.566992+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:06:56.566992+00:00'
[2024-12-14T10:37:02.024+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T10:37:02.025+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T10:37:02.025+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T10:37:02.025+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T10:37:02.026+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:02.026+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T10:37:02.027+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:37:02,027] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:37:02.027+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:02.027+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:37:02.028+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:37:02,028] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T10:37:02.028+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:02.028+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T10:37:02.040+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:37:02,035] {subprocess.py:99} INFO - Output:
[2024-12-14T10:37:02.041+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:02.035+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T10:37:02.094+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:37:02,087] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpjw72wa1t/controller.py': [Errno 2] No such file or directory
[2024-12-14T10:37:02.095+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:02.087+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpjw72wa1t/controller.py': [Errno 2] No such file or directory
[2024-12-14T10:37:02.099+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:37:02,099] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T10:37:02.100+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:02.099+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T10:37:02.116+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:37:02,107] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:37:02.116+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:02.107+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:37:02.119+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T10:37:02.120+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 05:07:02.118759+00:00 duration:None
[2024-12-14T10:37:02.120+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 05:06:56.566992+00:00: manual__2024-12-14T05:06:56.566992+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T10:37:02.121+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:37:02.124+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:02.124+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T05:06:56.566992+00:00, execution_date=20241214T050656, start_date=, end_date=20241214T050702
[2024-12-14T10:37:02.136+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:02.135+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T10:37:02.145+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:02.136+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:06:56.566992+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:37:02.149+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:02.148+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 05:06:56.566992+00:00: manual__2024-12-14T05:06:56.566992+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T10:37:02.149+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T10:37:02.149+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T05:06:56.566992+00:00 external trigger: False
[2024-12-14T10:37:02.149+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T10:37:02.150+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:02.150+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 05:06:56.566992+00:00, run_id=manual__2024-12-14T05:06:56.566992+00:00, run_start_date=2024-12-14 05:06:56.566992+00:00, run_end_date=2024-12-14 05:07:02.149540+00:00, run_duration=5.582548, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 05:06:56.566992+00:00, data_interval_end=2024-12-14 05:06:56.566992+00:00, dag_hash=None
[2024-12-14T10:37:02.164+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:37:02.178+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:02.178+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T10:37:02.200+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:37:02.200+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T10:37:02.225+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.814 seconds
[2024-12-14T10:40:27.100+0530] {processor.py:186} INFO - Started process (PID=40733) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:40:27.104+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T10:40:27.112+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:27.110+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:40:27.299+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:27.299+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T10:40:27.314+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:27.313+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 05:10:27.257775+00:00: manual__2024-12-14T05:10:27.257775+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T10:40:27.351+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:27.350+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T10:40:27.351+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:27.351+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T05:10:27.257775+00:00 [scheduled]>
[2024-12-14T10:40:32.382+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.381+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T10:40:32.551+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:40:32,551] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:10:27.257775+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:10:27.257775+00:00'
[2024-12-14T10:40:32.552+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.551+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:10:27.257775+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:10:27.257775+00:00'
[2024-12-14T10:40:32.568+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T10:40:32.568+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T10:40:32.568+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T10:40:32.568+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T10:40:32.569+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.569+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T10:40:32.606+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:40:32,606] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:40:32.607+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.606+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:40:32.608+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:40:32,607] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T10:40:32.608+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.607+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T10:40:32.620+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:40:32,619] {subprocess.py:99} INFO - Output:
[2024-12-14T10:40:32.622+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.619+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T10:40:32.623+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:40:32,623] {subprocess.py:106} INFO - scraping started
[2024-12-14T10:40:32.623+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.623+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T10:40:32.624+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:40:32,624] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T10:40:32.624+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.624+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T10:40:32.650+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.650+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T10:40:32.651+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.651+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T05:10:27.257775+00:00, execution_date=20241214T051027, start_date=, end_date=20241214T051032
[2024-12-14T10:40:32.665+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T10:40:32.666+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T10:40:32.666+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T10:40:32.666+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T10:40:32.667+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.667+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T10:40:32.684+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.684+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T10:40:32.685+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.685+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:10:27.257775+00:00 [scheduled]>
[2024-12-14T10:40:32.719+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:40:32,719] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:10:27.257775+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:10:27.257775+00:00'
[2024-12-14T10:40:32.720+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.719+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:10:27.257775+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:10:27.257775+00:00'
[2024-12-14T10:40:32.720+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T10:40:32.720+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T10:40:32.720+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T10:40:32.721+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T10:40:32.721+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.721+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T10:40:32.722+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:40:32,722] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:40:32.722+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.722+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:40:32.723+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:40:32,723] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T10:40:32.723+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.723+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T10:40:32.737+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:40:32,735] {subprocess.py:99} INFO - Output:
[2024-12-14T10:40:32.738+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.735+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T10:40:32.790+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:40:32,789] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpu6m91uqm/controller.py': [Errno 2] No such file or directory
[2024-12-14T10:40:32.790+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.789+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpu6m91uqm/controller.py': [Errno 2] No such file or directory
[2024-12-14T10:40:32.799+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:40:32,798] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T10:40:32.800+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.798+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T10:40:32.815+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:40:32,806] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:40:32.815+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.806+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:40:32.817+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T10:40:32.817+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 05:10:32.817123+00:00 duration:None
[2024-12-14T10:40:32.818+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 05:10:27.257775+00:00: manual__2024-12-14T05:10:27.257775+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T10:40:32.818+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:40:32.818+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.818+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T05:10:27.257775+00:00, execution_date=20241214T051027, start_date=, end_date=20241214T051032
[2024-12-14T10:40:32.836+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.836+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T10:40:32.842+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.837+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:10:27.257775+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:40:32.848+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.848+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 05:10:27.257775+00:00: manual__2024-12-14T05:10:27.257775+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T10:40:32.848+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T10:40:32.848+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T05:10:27.257775+00:00 external trigger: False
[2024-12-14T10:40:32.849+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T10:40:32.849+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.849+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 05:10:27.257775+00:00, run_id=manual__2024-12-14T05:10:27.257775+00:00, run_start_date=2024-12-14 05:10:27.257775+00:00, run_end_date=2024-12-14 05:10:32.848679+00:00, run_duration=5.590904, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 05:10:27.257775+00:00, data_interval_end=2024-12-14 05:10:27.257775+00:00, dag_hash=None
[2024-12-14T10:40:32.858+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:40:32.879+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.878+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T10:40:32.902+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:40:32.902+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T10:40:32.922+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.829 seconds
[2024-12-14T10:44:00.008+0530] {processor.py:186} INFO - Started process (PID=40964) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:44:00.011+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T10:44:00.018+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:00.018+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:44:00.194+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:00.194+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T10:44:00.209+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:00.209+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 05:14:00.160707+00:00: manual__2024-12-14T05:14:00.160707+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T10:44:00.251+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:00.251+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T10:44:00.252+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:00.252+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T05:14:00.160707+00:00 [scheduled]>
[2024-12-14T10:44:05.286+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.286+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T10:44:05.457+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:44:05,457] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:14:00.160707+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:14:00.160707+00:00'
[2024-12-14T10:44:05.457+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.457+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:14:00.160707+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:14:00.160707+00:00'
[2024-12-14T10:44:05.470+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T10:44:05.470+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T10:44:05.470+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T10:44:05.471+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T10:44:05.471+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.471+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T10:44:05.506+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:44:05,506] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:44:05.506+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.506+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:44:05.507+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:44:05,507] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T10:44:05.507+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.507+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T10:44:05.520+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:44:05,518] {subprocess.py:99} INFO - Output:
[2024-12-14T10:44:05.521+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.518+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T10:44:05.522+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:44:05,522] {subprocess.py:106} INFO - scraping started
[2024-12-14T10:44:05.522+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.522+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T10:44:05.522+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:44:05,522] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T10:44:05.523+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.522+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T10:44:05.551+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.550+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T10:44:05.551+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.551+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T05:14:00.160707+00:00, execution_date=20241214T051400, start_date=, end_date=20241214T051405
[2024-12-14T10:44:05.564+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T10:44:05.564+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T10:44:05.564+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T10:44:05.564+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T10:44:05.565+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.565+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T10:44:05.586+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.586+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T10:44:05.586+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.586+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:14:00.160707+00:00 [scheduled]>
[2024-12-14T10:44:05.619+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:44:05,619] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:14:00.160707+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:14:00.160707+00:00'
[2024-12-14T10:44:05.619+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.619+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:14:00.160707+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:14:00.160707+00:00'
[2024-12-14T10:44:05.620+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T10:44:05.620+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T10:44:05.620+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T10:44:05.620+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T10:44:05.621+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.620+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T10:44:05.621+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:44:05,621] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:44:05.622+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.621+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:44:05.622+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:44:05,622] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T10:44:05.623+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.622+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T10:44:05.632+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:44:05,631] {subprocess.py:99} INFO - Output:
[2024-12-14T10:44:05.633+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.631+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T10:44:05.687+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:44:05,687] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpanyqifzg/controller.py': [Errno 2] No such file or directory
[2024-12-14T10:44:05.687+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.687+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpanyqifzg/controller.py': [Errno 2] No such file or directory
[2024-12-14T10:44:05.692+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:44:05,692] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T10:44:05.692+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.692+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T10:44:05.706+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:44:05,700] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:44:05.706+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.700+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:44:05.708+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T10:44:05.709+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 05:14:05.708261+00:00 duration:None
[2024-12-14T10:44:05.709+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 05:14:00.160707+00:00: manual__2024-12-14T05:14:00.160707+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T10:44:05.709+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:44:05.710+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.709+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T05:14:00.160707+00:00, execution_date=20241214T051400, start_date=, end_date=20241214T051405
[2024-12-14T10:44:05.725+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.725+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T10:44:05.731+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.726+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:14:00.160707+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:44:05.736+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.735+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 05:14:00.160707+00:00: manual__2024-12-14T05:14:00.160707+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T10:44:05.736+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T10:44:05.736+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T05:14:00.160707+00:00 external trigger: False
[2024-12-14T10:44:05.736+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T10:44:05.737+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.737+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 05:14:00.160707+00:00, run_id=manual__2024-12-14T05:14:00.160707+00:00, run_start_date=2024-12-14 05:14:00.160707+00:00, run_end_date=2024-12-14 05:14:05.736328+00:00, run_duration=5.575621, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 05:14:00.160707+00:00, data_interval_end=2024-12-14 05:14:00.160707+00:00, dag_hash=None
[2024-12-14T10:44:05.749+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:44:05.763+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.762+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T10:44:05.787+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:44:05.787+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T10:44:05.807+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.805 seconds
[2024-12-14T10:47:31.805+0530] {processor.py:186} INFO - Started process (PID=41179) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:47:31.806+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T10:47:31.807+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:31.807+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:47:31.993+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:31.993+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T10:47:32.008+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:32.007+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 05:17:31.955417+00:00: manual__2024-12-14T05:17:31.955417+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T10:47:32.041+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:32.041+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T10:47:32.042+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:32.041+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T05:17:31.955417+00:00 [scheduled]>
[2024-12-14T10:47:37.076+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.076+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T10:47:37.246+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:47:37,245] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:17:31.955417+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:17:31.955417+00:00'
[2024-12-14T10:47:37.246+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.245+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:17:31.955417+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:17:31.955417+00:00'
[2024-12-14T10:47:37.254+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T10:47:37.254+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T10:47:37.255+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T10:47:37.255+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T10:47:37.255+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.255+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T10:47:37.292+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:47:37,292] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:47:37.292+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.292+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:47:37.293+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:47:37,293] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T10:47:37.294+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.293+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T10:47:37.303+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:47:37,302] {subprocess.py:99} INFO - Output:
[2024-12-14T10:47:37.305+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.302+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T10:47:37.305+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:47:37,305] {subprocess.py:106} INFO - scraping started
[2024-12-14T10:47:37.306+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.305+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T10:47:37.306+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:47:37,306] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T10:47:37.306+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.306+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T10:47:37.331+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.331+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T10:47:37.334+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.333+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T05:17:31.955417+00:00, execution_date=20241214T051731, start_date=, end_date=20241214T051737
[2024-12-14T10:47:37.344+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T10:47:37.344+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T10:47:37.344+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T10:47:37.345+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T10:47:37.345+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.345+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T10:47:37.368+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.368+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T10:47:37.369+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.369+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:17:31.955417+00:00 [scheduled]>
[2024-12-14T10:47:37.402+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:47:37,402] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:17:31.955417+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:17:31.955417+00:00'
[2024-12-14T10:47:37.403+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.402+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:17:31.955417+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:17:31.955417+00:00'
[2024-12-14T10:47:37.403+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T10:47:37.403+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T10:47:37.404+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T10:47:37.404+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T10:47:37.404+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.404+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T10:47:37.405+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:47:37,405] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:47:37.405+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.405+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:47:37.406+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:47:37,406] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T10:47:37.406+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.406+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T10:47:37.421+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:47:37,420] {subprocess.py:99} INFO - Output:
[2024-12-14T10:47:37.423+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.420+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T10:47:37.470+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:47:37,470] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpefs5uum9/controller.py': [Errno 2] No such file or directory
[2024-12-14T10:47:37.471+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.470+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpefs5uum9/controller.py': [Errno 2] No such file or directory
[2024-12-14T10:47:37.475+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:47:37,474] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T10:47:37.475+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.474+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T10:47:37.489+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:47:37,487] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:47:37.489+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.487+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:47:37.491+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T10:47:37.491+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 05:17:37.491094+00:00 duration:None
[2024-12-14T10:47:37.492+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 05:17:31.955417+00:00: manual__2024-12-14T05:17:31.955417+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T10:47:37.492+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:47:37.492+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.492+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T05:17:31.955417+00:00, execution_date=20241214T051731, start_date=, end_date=20241214T051737
[2024-12-14T10:47:37.504+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.504+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T10:47:37.507+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.504+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:17:31.955417+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:47:37.511+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.511+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 05:17:31.955417+00:00: manual__2024-12-14T05:17:31.955417+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T10:47:37.511+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T10:47:37.512+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T05:17:31.955417+00:00 external trigger: False
[2024-12-14T10:47:37.512+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T10:47:37.512+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.512+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 05:17:31.955417+00:00, run_id=manual__2024-12-14T05:17:31.955417+00:00, run_start_date=2024-12-14 05:17:31.955417+00:00, run_end_date=2024-12-14 05:17:37.511922+00:00, run_duration=5.556505, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 05:17:31.955417+00:00, data_interval_end=2024-12-14 05:17:31.955417+00:00, dag_hash=None
[2024-12-14T10:47:37.527+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:47:37.540+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.540+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T10:47:37.563+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:47:37.562+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T10:47:37.588+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.787 seconds
[2024-12-14T10:51:00.759+0530] {processor.py:186} INFO - Started process (PID=41413) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:51:00.762+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T10:51:00.763+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:00.763+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:51:00.954+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:00.954+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T10:51:00.978+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:00.977+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 05:21:00.919878+00:00: manual__2024-12-14T05:21:00.919878+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T10:51:01.016+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:01.016+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T10:51:01.017+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:01.016+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T05:21:00.919878+00:00 [scheduled]>
[2024-12-14T10:51:06.053+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.053+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T10:51:06.242+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:51:06,242] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:21:00.919878+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:21:00.919878+00:00'
[2024-12-14T10:51:06.243+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.242+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:21:00.919878+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:21:00.919878+00:00'
[2024-12-14T10:51:06.255+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T10:51:06.256+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T10:51:06.256+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T10:51:06.256+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T10:51:06.257+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.256+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T10:51:06.298+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:51:06,298] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:51:06.299+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.298+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:51:06.300+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:51:06,299] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T10:51:06.309+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.299+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T10:51:06.322+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:51:06,321] {subprocess.py:99} INFO - Output:
[2024-12-14T10:51:06.324+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.321+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T10:51:06.325+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:51:06,325] {subprocess.py:106} INFO - scraping started
[2024-12-14T10:51:06.325+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.325+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T10:51:06.325+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:51:06,325] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T10:51:06.326+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.325+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T10:51:06.354+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.353+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T10:51:06.354+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.354+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T05:21:00.919878+00:00, execution_date=20241214T052100, start_date=, end_date=20241214T052106
[2024-12-14T10:51:06.364+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T10:51:06.365+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T10:51:06.365+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T10:51:06.365+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T10:51:06.366+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.366+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T10:51:06.390+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.390+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T10:51:06.391+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.391+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:21:00.919878+00:00 [scheduled]>
[2024-12-14T10:51:06.426+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:51:06,425] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:21:00.919878+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:21:00.919878+00:00'
[2024-12-14T10:51:06.426+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.425+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:21:00.919878+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:21:00.919878+00:00'
[2024-12-14T10:51:06.427+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T10:51:06.427+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T10:51:06.427+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T10:51:06.427+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T10:51:06.428+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.427+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T10:51:06.428+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:51:06,428] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:51:06.429+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.428+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:51:06.429+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:51:06,429] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T10:51:06.429+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.429+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T10:51:06.443+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:51:06,442] {subprocess.py:99} INFO - Output:
[2024-12-14T10:51:06.444+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.442+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T10:51:06.492+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:51:06,492] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpk1fchfn7/controller.py': [Errno 2] No such file or directory
[2024-12-14T10:51:06.493+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.492+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpk1fchfn7/controller.py': [Errno 2] No such file or directory
[2024-12-14T10:51:06.498+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:51:06,497] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T10:51:06.498+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.497+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T10:51:06.521+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:51:06,510] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:51:06.522+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.510+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:51:06.524+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T10:51:06.524+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 05:21:06.523607+00:00 duration:None
[2024-12-14T10:51:06.524+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 05:21:00.919878+00:00: manual__2024-12-14T05:21:00.919878+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T10:51:06.524+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:51:06.525+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.525+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T05:21:00.919878+00:00, execution_date=20241214T052100, start_date=, end_date=20241214T052106
[2024-12-14T10:51:06.541+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.541+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T10:51:06.547+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.541+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:21:00.919878+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:51:06.553+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.552+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 05:21:00.919878+00:00: manual__2024-12-14T05:21:00.919878+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T10:51:06.553+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T10:51:06.553+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T05:21:00.919878+00:00 external trigger: False
[2024-12-14T10:51:06.554+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T10:51:06.554+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.554+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 05:21:00.919878+00:00, run_id=manual__2024-12-14T05:21:00.919878+00:00, run_start_date=2024-12-14 05:21:00.919878+00:00, run_end_date=2024-12-14 05:21:06.553601+00:00, run_duration=5.633723, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 05:21:00.919878+00:00, data_interval_end=2024-12-14 05:21:00.919878+00:00, dag_hash=None
[2024-12-14T10:51:06.564+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:51:06.582+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.582+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T10:51:06.607+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:51:06.606+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T10:51:06.628+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.872 seconds
[2024-12-14T10:54:33.219+0530] {processor.py:186} INFO - Started process (PID=41647) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:54:33.222+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T10:54:33.228+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:33.227+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:54:33.411+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:33.411+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T10:54:33.430+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:33.430+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 05:24:33.376646+00:00: manual__2024-12-14T05:24:33.376646+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T10:54:33.466+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:33.466+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T10:54:33.467+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:33.466+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T05:24:33.376646+00:00 [scheduled]>
[2024-12-14T10:54:38.503+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:38.502+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T10:54:38.679+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:54:38,678] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:24:33.376646+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:24:33.376646+00:00'
[2024-12-14T10:54:38.679+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:38.678+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:24:33.376646+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:24:33.376646+00:00'
[2024-12-14T10:54:38.693+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T10:54:38.694+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T10:54:38.694+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T10:54:38.694+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T10:54:38.695+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:38.694+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T10:54:38.732+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:54:38,732] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:54:38.733+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:38.732+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:54:38.734+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:54:38,734] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T10:54:38.734+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:38.734+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T10:54:38.744+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:54:38,742] {subprocess.py:99} INFO - Output:
[2024-12-14T10:54:38.745+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:38.742+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T10:54:38.746+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:54:38,746] {subprocess.py:106} INFO - scraping started
[2024-12-14T10:54:38.746+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:38.746+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T10:54:38.747+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:54:38,746] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T10:54:38.747+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:38.746+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T10:54:38.773+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:38.773+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T10:54:38.774+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:38.774+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T05:24:33.376646+00:00, execution_date=20241214T052433, start_date=, end_date=20241214T052438
[2024-12-14T10:54:38.786+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T10:54:38.786+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T10:54:38.787+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T10:54:38.787+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T10:54:38.792+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:38.787+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T10:54:38.810+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:38.810+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T10:54:38.810+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:38.810+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:24:33.376646+00:00 [scheduled]>
[2024-12-14T10:54:38.845+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:54:38,845] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:24:33.376646+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:24:33.376646+00:00'
[2024-12-14T10:54:38.845+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:38.845+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:24:33.376646+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:24:33.376646+00:00'
[2024-12-14T10:54:38.846+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T10:54:38.846+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T10:54:38.846+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T10:54:38.846+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T10:54:38.847+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:38.846+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T10:54:38.847+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:54:38,847] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:54:38.848+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:38.847+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:54:38.848+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:54:38,848] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T10:54:38.848+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:38.848+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T10:54:38.862+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:54:38,861] {subprocess.py:99} INFO - Output:
[2024-12-14T10:54:38.863+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:38.861+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T10:54:38.910+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:54:38,910] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpi8n_74d_/controller.py': [Errno 2] No such file or directory
[2024-12-14T10:54:38.911+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:38.910+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpi8n_74d_/controller.py': [Errno 2] No such file or directory
[2024-12-14T10:54:38.916+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:54:38,916] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T10:54:38.917+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:38.916+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T10:54:38.936+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:54:38,930] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:54:38.936+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:38.930+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:54:38.938+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T10:54:38.939+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 05:24:38.938197+00:00 duration:None
[2024-12-14T10:54:38.940+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 05:24:33.376646+00:00: manual__2024-12-14T05:24:33.376646+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T10:54:38.940+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:54:38.940+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:38.940+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T05:24:33.376646+00:00, execution_date=20241214T052433, start_date=, end_date=20241214T052438
[2024-12-14T10:54:38.952+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:38.951+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T10:54:38.964+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:38.953+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:24:33.376646+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:54:38.969+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:38.968+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 05:24:33.376646+00:00: manual__2024-12-14T05:24:33.376646+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T10:54:38.969+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T10:54:38.969+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T05:24:33.376646+00:00 external trigger: False
[2024-12-14T10:54:38.969+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T10:54:38.970+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:38.970+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 05:24:33.376646+00:00, run_id=manual__2024-12-14T05:24:33.376646+00:00, run_start_date=2024-12-14 05:24:33.376646+00:00, run_end_date=2024-12-14 05:24:38.969323+00:00, run_duration=5.592677, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 05:24:33.376646+00:00, data_interval_end=2024-12-14 05:24:33.376646+00:00, dag_hash=None
[2024-12-14T10:54:38.979+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:54:39.001+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:39.000+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T10:54:39.019+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:54:39.019+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T10:54:39.045+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.830 seconds
[2024-12-14T10:57:59.991+0530] {processor.py:186} INFO - Started process (PID=41871) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:57:59.998+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T10:57:59.999+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:57:59.999+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:58:00.178+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:00.177+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T10:58:00.197+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:00.196+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 05:28:00.143713+00:00: manual__2024-12-14T05:28:00.143713+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T10:58:00.234+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:00.234+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T10:58:00.235+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:00.234+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T05:28:00.143713+00:00 [scheduled]>
[2024-12-14T10:58:05.277+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.276+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T10:58:05.453+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:58:05,452] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:28:00.143713+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:28:00.143713+00:00'
[2024-12-14T10:58:05.453+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.452+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:28:00.143713+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:28:00.143713+00:00'
[2024-12-14T10:58:05.469+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T10:58:05.470+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T10:58:05.470+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T10:58:05.470+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T10:58:05.471+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.471+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T10:58:05.510+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:58:05,510] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:58:05.510+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.510+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:58:05.511+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:58:05,511] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T10:58:05.512+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.511+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T10:58:05.521+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:58:05,519] {subprocess.py:99} INFO - Output:
[2024-12-14T10:58:05.522+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.519+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T10:58:05.522+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:58:05,522] {subprocess.py:106} INFO - scraping started
[2024-12-14T10:58:05.523+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.522+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T10:58:05.523+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:58:05,523] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T10:58:05.524+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.523+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T10:58:05.551+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.551+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T10:58:05.552+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.552+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T05:28:00.143713+00:00, execution_date=20241214T052800, start_date=, end_date=20241214T052805
[2024-12-14T10:58:05.568+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T10:58:05.568+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T10:58:05.568+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T10:58:05.569+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T10:58:05.569+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.569+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T10:58:05.587+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.587+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T10:58:05.587+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.587+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:28:00.143713+00:00 [scheduled]>
[2024-12-14T10:58:05.622+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:58:05,622] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:28:00.143713+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:28:00.143713+00:00'
[2024-12-14T10:58:05.623+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.622+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:28:00.143713+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:28:00.143713+00:00'
[2024-12-14T10:58:05.623+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T10:58:05.623+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T10:58:05.623+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T10:58:05.624+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T10:58:05.624+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.624+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T10:58:05.625+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:58:05,625] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:58:05.625+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.625+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T10:58:05.630+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:58:05,630] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T10:58:05.631+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.630+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T10:58:05.640+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:58:05,638] {subprocess.py:99} INFO - Output:
[2024-12-14T10:58:05.642+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.638+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T10:58:05.689+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:58:05,689] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpageqfa_g/controller.py': [Errno 2] No such file or directory
[2024-12-14T10:58:05.690+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.689+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpageqfa_g/controller.py': [Errno 2] No such file or directory
[2024-12-14T10:58:05.699+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:58:05,698] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T10:58:05.699+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.698+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T10:58:05.713+0530] {logging_mixin.py:190} INFO - [2024-12-14 10:58:05,706] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:58:05.714+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.706+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:58:05.716+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T10:58:05.716+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 05:28:05.715686+00:00 duration:None
[2024-12-14T10:58:05.716+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 05:28:00.143713+00:00: manual__2024-12-14T05:28:00.143713+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T10:58:05.716+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:58:05.717+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.717+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T05:28:00.143713+00:00, execution_date=20241214T052800, start_date=, end_date=20241214T052805
[2024-12-14T10:58:05.732+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.732+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T10:58:05.738+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.733+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:28:00.143713+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T10:58:05.744+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.743+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 05:28:00.143713+00:00: manual__2024-12-14T05:28:00.143713+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T10:58:05.744+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T10:58:05.744+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T05:28:00.143713+00:00 external trigger: False
[2024-12-14T10:58:05.744+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T10:58:05.745+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.745+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 05:28:00.143713+00:00, run_id=manual__2024-12-14T05:28:00.143713+00:00, run_start_date=2024-12-14 05:28:00.143713+00:00, run_end_date=2024-12-14 05:28:05.744466+00:00, run_duration=5.600753, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 05:28:00.143713+00:00, data_interval_end=2024-12-14 05:28:00.143713+00:00, dag_hash=None
[2024-12-14T10:58:05.755+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T10:58:05.773+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.773+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T10:58:05.796+0530] {logging_mixin.py:190} INFO - [2024-12-14T10:58:05.796+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T10:58:05.817+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.830 seconds
[2024-12-14T11:01:14.384+0530] {processor.py:186} INFO - Started process (PID=42094) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:01:14.386+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T11:01:14.388+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:14.388+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:01:14.544+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:14.544+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T11:01:14.559+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:14.558+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 05:31:14.513529+00:00: manual__2024-12-14T05:31:14.513529+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:01:14.596+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:14.595+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T11:01:14.596+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:14.596+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T05:31:14.513529+00:00 [scheduled]>
[2024-12-14T11:01:19.625+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:19.625+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T11:01:19.767+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:01:19,767] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:31:14.513529+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:31:14.513529+00:00'
[2024-12-14T11:01:19.768+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:19.767+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:31:14.513529+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:31:14.513529+00:00'
[2024-12-14T11:01:19.780+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:01:19.780+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:01:19.780+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T11:01:19.780+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:01:19.781+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:19.781+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:01:19.811+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:01:19,811] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:01:19.812+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:19.811+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:01:19.812+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:01:19,812] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:01:19.813+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:19.812+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:01:19.823+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:01:19,821] {subprocess.py:99} INFO - Output:
[2024-12-14T11:01:19.824+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:19.821+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:01:19.825+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:01:19,825] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:01:19.825+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:19.825+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:01:19.826+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:01:19,825] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:01:19.826+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:19.825+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:01:19.846+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:19.845+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:01:19.846+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:19.846+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T05:31:14.513529+00:00, execution_date=20241214T053114, start_date=, end_date=20241214T053119
[2024-12-14T11:01:19.857+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T11:01:19.857+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T11:01:19.857+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T11:01:19.858+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T11:01:19.858+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:19.858+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T11:01:19.875+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:19.875+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T11:01:19.876+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:19.876+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:31:14.513529+00:00 [scheduled]>
[2024-12-14T11:01:19.905+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:01:19,905] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:31:14.513529+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:31:14.513529+00:00'
[2024-12-14T11:01:19.906+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:19.905+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:31:14.513529+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:31:14.513529+00:00'
[2024-12-14T11:01:19.907+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:01:19.907+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:01:19.907+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T11:01:19.907+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:01:19.908+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:19.907+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:01:19.908+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:01:19,908] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:01:19.909+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:19.908+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:01:19.909+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:01:19,909] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:01:19.910+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:19.909+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:01:19.919+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:01:19,918] {subprocess.py:99} INFO - Output:
[2024-12-14T11:01:19.921+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:19.918+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:01:19.963+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:01:19,962] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp02axaa0v/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:01:19.963+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:19.962+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp02axaa0v/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:01:19.970+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:01:19,969] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:01:19.970+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:19.969+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:01:19.986+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:01:19,976] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:01:19.986+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:19.976+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:01:19.988+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T11:01:19.988+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 05:31:19.987870+00:00 duration:None
[2024-12-14T11:01:19.988+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 05:31:14.513529+00:00: manual__2024-12-14T05:31:14.513529+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:01:19.989+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:01:19.989+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:19.989+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T05:31:14.513529+00:00, execution_date=20241214T053114, start_date=, end_date=20241214T053119
[2024-12-14T11:01:20.000+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:20.000+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:01:20.008+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:20.001+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:31:14.513529+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:01:20.013+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:20.012+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 05:31:14.513529+00:00: manual__2024-12-14T05:31:14.513529+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T11:01:20.013+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T11:01:20.013+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T05:31:14.513529+00:00 external trigger: False
[2024-12-14T11:01:20.013+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T11:01:20.014+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:20.014+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 05:31:14.513529+00:00, run_id=manual__2024-12-14T05:31:14.513529+00:00, run_start_date=2024-12-14 05:31:14.513529+00:00, run_end_date=2024-12-14 05:31:20.013399+00:00, run_duration=5.49987, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 05:31:14.513529+00:00, data_interval_end=2024-12-14 05:31:14.513529+00:00, dag_hash=None
[2024-12-14T11:01:20.023+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:01:20.036+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:20.036+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T11:01:20.057+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:01:20.057+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T11:01:20.076+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.696 seconds
[2024-12-14T11:04:09.076+0530] {processor.py:186} INFO - Started process (PID=42301) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:04:09.077+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T11:04:09.078+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:09.078+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:04:09.232+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:09.232+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T11:04:09.248+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:09.247+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 05:34:09.202069+00:00: manual__2024-12-14T05:34:09.202069+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:04:09.276+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:09.276+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T11:04:09.277+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:09.276+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T05:34:09.202069+00:00 [scheduled]>
[2024-12-14T11:04:14.305+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.305+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T11:04:14.439+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:04:14,439] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:34:09.202069+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:34:09.202069+00:00'
[2024-12-14T11:04:14.440+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.439+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:34:09.202069+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:34:09.202069+00:00'
[2024-12-14T11:04:14.443+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:04:14.443+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:04:14.443+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T11:04:14.444+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:04:14.444+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.444+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:04:14.475+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:04:14,475] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:04:14.475+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.475+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:04:14.476+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:04:14,476] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:04:14.476+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.476+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:04:14.485+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:04:14,483] {subprocess.py:99} INFO - Output:
[2024-12-14T11:04:14.486+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.483+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:04:14.487+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:04:14,487] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:04:14.487+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.487+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:04:14.487+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:04:14,487] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:04:14.488+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.487+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:04:14.510+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.509+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:04:14.510+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.510+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T05:34:09.202069+00:00, execution_date=20241214T053409, start_date=, end_date=20241214T053414
[2024-12-14T11:04:14.522+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T11:04:14.523+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T11:04:14.523+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T11:04:14.524+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T11:04:14.524+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.524+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T11:04:14.541+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.541+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T11:04:14.541+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.541+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:34:09.202069+00:00 [scheduled]>
[2024-12-14T11:04:14.568+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:04:14,568] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:34:09.202069+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:34:09.202069+00:00'
[2024-12-14T11:04:14.569+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.568+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:34:09.202069+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:34:09.202069+00:00'
[2024-12-14T11:04:14.569+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:04:14.569+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:04:14.569+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T11:04:14.569+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:04:14.570+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.570+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:04:14.570+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:04:14,570] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:04:14.571+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.570+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:04:14.571+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:04:14,571] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:04:14.572+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.571+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:04:14.584+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:04:14,582] {subprocess.py:99} INFO - Output:
[2024-12-14T11:04:14.585+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.582+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:04:14.627+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:04:14,627] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp7rgoriq8/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:04:14.628+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.627+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp7rgoriq8/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:04:14.633+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:04:14,632] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:04:14.633+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.632+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:04:14.643+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:04:14,641] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:04:14.643+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.641+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:04:14.645+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T11:04:14.646+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 05:34:14.645049+00:00 duration:None
[2024-12-14T11:04:14.646+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 05:34:09.202069+00:00: manual__2024-12-14T05:34:09.202069+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:04:14.646+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:04:14.646+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.646+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T05:34:09.202069+00:00, execution_date=20241214T053409, start_date=, end_date=20241214T053414
[2024-12-14T11:04:14.657+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.657+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:04:14.660+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.657+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:34:09.202069+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:04:14.664+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.664+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 05:34:09.202069+00:00: manual__2024-12-14T05:34:09.202069+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T11:04:14.665+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T11:04:14.665+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T05:34:09.202069+00:00 external trigger: False
[2024-12-14T11:04:14.665+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T11:04:14.665+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.665+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 05:34:09.202069+00:00, run_id=manual__2024-12-14T05:34:09.202069+00:00, run_start_date=2024-12-14 05:34:09.202069+00:00, run_end_date=2024-12-14 05:34:14.665054+00:00, run_duration=5.462985, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 05:34:09.202069+00:00, data_interval_end=2024-12-14 05:34:09.202069+00:00, dag_hash=None
[2024-12-14T11:04:14.676+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:04:14.689+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.689+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T11:04:14.706+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:04:14.706+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T11:04:14.725+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.653 seconds
[2024-12-14T11:07:04.117+0530] {processor.py:186} INFO - Started process (PID=42515) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:07:04.118+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T11:07:04.119+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:04.119+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:07:04.268+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:04.268+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T11:07:04.282+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:04.281+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 05:37:04.239767+00:00: manual__2024-12-14T05:37:04.239767+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:07:04.312+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:04.311+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T11:07:04.312+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:04.312+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T05:37:04.239767+00:00 [scheduled]>
[2024-12-14T11:07:09.340+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.339+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T11:07:09.477+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:07:09,477] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:37:04.239767+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:37:04.239767+00:00'
[2024-12-14T11:07:09.478+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.477+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:37:04.239767+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:37:04.239767+00:00'
[2024-12-14T11:07:09.480+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:07:09.480+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:07:09.481+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T11:07:09.481+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:07:09.481+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.481+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:07:09.512+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:07:09,512] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:07:09.512+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.512+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:07:09.513+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:07:09,513] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:07:09.513+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.513+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:07:09.522+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:07:09,520] {subprocess.py:99} INFO - Output:
[2024-12-14T11:07:09.523+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.520+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:07:09.524+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:07:09,524] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:07:09.524+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.524+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:07:09.524+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:07:09,524] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:07:09.526+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.524+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:07:09.547+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.547+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:07:09.548+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.547+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T05:37:04.239767+00:00, execution_date=20241214T053704, start_date=, end_date=20241214T053709
[2024-12-14T11:07:09.557+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T11:07:09.558+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T11:07:09.558+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T11:07:09.558+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T11:07:09.559+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.558+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T11:07:09.576+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.575+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T11:07:09.576+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.576+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:37:04.239767+00:00 [scheduled]>
[2024-12-14T11:07:09.605+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:07:09,605] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:37:04.239767+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:37:04.239767+00:00'
[2024-12-14T11:07:09.605+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.605+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:37:04.239767+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:37:04.239767+00:00'
[2024-12-14T11:07:09.606+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:07:09.606+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:07:09.606+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T11:07:09.606+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:07:09.607+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.606+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:07:09.607+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:07:09,607] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:07:09.608+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.607+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:07:09.609+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:07:09,609] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:07:09.609+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.609+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:07:09.618+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:07:09,616] {subprocess.py:99} INFO - Output:
[2024-12-14T11:07:09.619+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.616+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:07:09.659+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:07:09,659] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpfymmterk/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:07:09.660+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.659+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpfymmterk/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:07:09.666+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:07:09,665] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:07:09.666+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.665+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:07:09.676+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:07:09,673] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:07:09.677+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.673+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:07:09.679+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T11:07:09.679+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 05:37:09.679157+00:00 duration:None
[2024-12-14T11:07:09.680+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 05:37:04.239767+00:00: manual__2024-12-14T05:37:04.239767+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:07:09.680+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:07:09.680+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.680+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T05:37:04.239767+00:00, execution_date=20241214T053704, start_date=, end_date=20241214T053709
[2024-12-14T11:07:09.693+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.692+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:07:09.695+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.693+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:37:04.239767+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:07:09.700+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.700+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 05:37:04.239767+00:00: manual__2024-12-14T05:37:04.239767+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T11:07:09.700+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T11:07:09.700+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T05:37:04.239767+00:00 external trigger: False
[2024-12-14T11:07:09.700+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T11:07:09.701+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.701+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 05:37:04.239767+00:00, run_id=manual__2024-12-14T05:37:04.239767+00:00, run_start_date=2024-12-14 05:37:04.239767+00:00, run_end_date=2024-12-14 05:37:09.700529+00:00, run_duration=5.460762, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 05:37:04.239767+00:00, data_interval_end=2024-12-14 05:37:04.239767+00:00, dag_hash=None
[2024-12-14T11:07:09.711+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:07:09.723+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.723+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T11:07:09.742+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:07:09.741+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T11:07:09.764+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.650 seconds
[2024-12-14T11:09:57.778+0530] {processor.py:186} INFO - Started process (PID=42723) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:09:57.779+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T11:09:57.780+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:09:57.780+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:09:57.932+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:09:57.932+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T11:09:57.945+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:09:57.945+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 05:39:57.901711+00:00: manual__2024-12-14T05:39:57.901711+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:09:57.973+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:09:57.973+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T11:09:57.973+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:09:57.973+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T05:39:57.901711+00:00 [scheduled]>
[2024-12-14T11:10:02.998+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:02.998+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T11:10:03.131+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:10:03,131] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:39:57.901711+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:39:57.901711+00:00'
[2024-12-14T11:10:03.132+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.131+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:39:57.901711+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:39:57.901711+00:00'
[2024-12-14T11:10:03.135+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:10:03.135+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:10:03.136+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T11:10:03.136+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:10:03.136+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.136+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:10:03.166+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:10:03,166] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:10:03.167+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.166+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:10:03.167+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:10:03,167] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:10:03.168+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.167+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:10:03.176+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:10:03,175] {subprocess.py:99} INFO - Output:
[2024-12-14T11:10:03.177+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.175+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:10:03.178+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:10:03,178] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:10:03.178+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.178+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:10:03.179+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:10:03,179] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:10:03.179+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.179+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:10:03.199+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.199+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:10:03.200+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.200+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T05:39:57.901711+00:00, execution_date=20241214T053957, start_date=, end_date=20241214T054003
[2024-12-14T11:10:03.210+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T11:10:03.210+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T11:10:03.210+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T11:10:03.210+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T11:10:03.211+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.211+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T11:10:03.228+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.228+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T11:10:03.228+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.228+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:39:57.901711+00:00 [scheduled]>
[2024-12-14T11:10:03.255+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:10:03,255] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:39:57.901711+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:39:57.901711+00:00'
[2024-12-14T11:10:03.256+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.255+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:39:57.901711+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:39:57.901711+00:00'
[2024-12-14T11:10:03.256+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:10:03.256+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:10:03.256+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T11:10:03.256+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:10:03.257+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.257+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:10:03.257+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:10:03,257] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:10:03.258+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.257+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:10:03.258+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:10:03,258] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:10:03.259+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.258+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:10:03.267+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:10:03,266] {subprocess.py:99} INFO - Output:
[2024-12-14T11:10:03.268+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.266+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:10:03.312+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:10:03,312] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpzy5jpizk/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:10:03.313+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.312+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpzy5jpizk/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:10:03.319+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:10:03,318] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:10:03.319+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.318+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:10:03.328+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:10:03,326] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:10:03.328+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.326+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:10:03.330+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T11:10:03.330+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 05:40:03.330136+00:00 duration:None
[2024-12-14T11:10:03.331+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 05:39:57.901711+00:00: manual__2024-12-14T05:39:57.901711+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:10:03.331+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:10:03.331+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.331+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T05:39:57.901711+00:00, execution_date=20241214T053957, start_date=, end_date=20241214T054003
[2024-12-14T11:10:03.344+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.344+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:10:03.347+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.344+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:39:57.901711+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:10:03.352+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.352+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 05:39:57.901711+00:00: manual__2024-12-14T05:39:57.901711+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T11:10:03.352+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T11:10:03.352+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T05:39:57.901711+00:00 external trigger: False
[2024-12-14T11:10:03.353+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T11:10:03.353+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.353+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 05:39:57.901711+00:00, run_id=manual__2024-12-14T05:39:57.901711+00:00, run_start_date=2024-12-14 05:39:57.901711+00:00, run_end_date=2024-12-14 05:40:03.352565+00:00, run_duration=5.450854, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 05:39:57.901711+00:00, data_interval_end=2024-12-14 05:39:57.901711+00:00, dag_hash=None
[2024-12-14T11:10:03.363+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:10:03.377+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.376+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T11:10:03.395+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:10:03.395+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T11:10:03.415+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.641 seconds
[2024-12-14T11:13:05.993+0530] {processor.py:186} INFO - Started process (PID=42940) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:13:05.996+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T11:13:06.000+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:05.999+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:13:06.448+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:06.448+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T11:13:06.472+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:06.471+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 05:43:06.377227+00:00: manual__2024-12-14T05:43:06.377227+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:13:06.509+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:06.509+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T11:13:06.511+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:06.510+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T05:43:06.377227+00:00 [scheduled]>
[2024-12-14T11:13:11.549+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:11.549+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T11:13:11.715+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:13:11,714] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:43:06.377227+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:43:06.377227+00:00'
[2024-12-14T11:13:11.715+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:11.714+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:43:06.377227+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:43:06.377227+00:00'
[2024-12-14T11:13:11.729+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:13:11.729+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:13:11.730+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T11:13:11.730+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:13:11.730+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:11.730+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:13:11.816+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:13:11,816] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:13:11.816+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:11.816+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:13:11.817+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:13:11,817] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:13:11.818+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:11.817+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:13:11.831+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:13:11,829] {subprocess.py:99} INFO - Output:
[2024-12-14T11:13:11.832+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:11.829+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:13:11.839+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:13:11,838] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:13:11.840+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:11.838+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:13:11.840+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:13:11,840] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:13:11.841+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:11.840+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:13:11.862+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:11.862+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:13:11.863+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:11.863+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T05:43:06.377227+00:00, execution_date=20241214T054306, start_date=, end_date=20241214T054311
[2024-12-14T11:13:11.877+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T11:13:11.877+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T11:13:11.878+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T11:13:11.878+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T11:13:11.878+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:11.878+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T11:13:11.897+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:11.896+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T11:13:11.898+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:11.897+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:43:06.377227+00:00 [scheduled]>
[2024-12-14T11:13:11.932+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:13:11,932] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:43:06.377227+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:43:06.377227+00:00'
[2024-12-14T11:13:11.932+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:11.932+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:43:06.377227+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:43:06.377227+00:00'
[2024-12-14T11:13:11.933+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:13:11.933+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:13:11.933+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T11:13:11.933+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:13:11.934+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:11.933+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:13:11.934+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:13:11,934] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:13:11.934+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:11.934+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:13:11.935+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:13:11,935] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:13:11.936+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:11.935+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:13:11.946+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:13:11,944] {subprocess.py:99} INFO - Output:
[2024-12-14T11:13:11.947+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:11.944+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:13:12.038+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:13:12,038] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp_4rjys2k/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:13:12.039+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:12.038+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp_4rjys2k/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:13:12.046+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:13:12,046] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:13:12.047+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:12.046+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:13:12.062+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:13:12,055] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:13:12.062+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:12.055+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:13:12.064+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T11:13:12.064+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 05:43:12.064153+00:00 duration:None
[2024-12-14T11:13:12.065+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 05:43:06.377227+00:00: manual__2024-12-14T05:43:06.377227+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:13:12.065+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:13:12.065+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:12.065+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T05:43:06.377227+00:00, execution_date=20241214T054306, start_date=, end_date=20241214T054312
[2024-12-14T11:13:12.081+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:12.081+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:13:12.091+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:12.082+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:43:06.377227+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:13:12.095+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:12.095+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 05:43:06.377227+00:00: manual__2024-12-14T05:43:06.377227+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T11:13:12.096+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T11:13:12.096+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T05:43:06.377227+00:00 external trigger: False
[2024-12-14T11:13:12.096+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T11:13:12.097+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:12.096+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 05:43:06.377227+00:00, run_id=manual__2024-12-14T05:43:06.377227+00:00, run_start_date=2024-12-14 05:43:06.377227+00:00, run_end_date=2024-12-14 05:43:12.096145+00:00, run_duration=5.718918, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 05:43:06.377227+00:00, data_interval_end=2024-12-14 05:43:06.377227+00:00, dag_hash=None
[2024-12-14T11:13:12.107+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:13:12.128+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:12.128+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T11:13:12.155+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:13:12.154+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T11:13:12.175+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 6.293 seconds
[2024-12-14T11:16:21.029+0530] {processor.py:186} INFO - Started process (PID=43167) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:16:21.032+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T11:16:21.034+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:21.033+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:16:21.193+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:21.193+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T11:16:21.209+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:21.208+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 05:46:21.162403+00:00: manual__2024-12-14T05:46:21.162403+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:16:21.243+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:21.243+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T11:16:21.243+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:21.243+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T05:46:21.162403+00:00 [scheduled]>
[2024-12-14T11:16:26.272+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.272+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T11:16:26.421+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:16:26,421] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:46:21.162403+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:46:21.162403+00:00'
[2024-12-14T11:16:26.422+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.421+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:46:21.162403+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:46:21.162403+00:00'
[2024-12-14T11:16:26.434+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:16:26.435+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:16:26.435+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T11:16:26.435+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:16:26.436+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.436+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:16:26.469+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:16:26,469] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:16:26.470+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.469+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:16:26.470+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:16:26,470] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:16:26.471+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.470+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:16:26.480+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:16:26,479] {subprocess.py:99} INFO - Output:
[2024-12-14T11:16:26.482+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.479+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:16:26.482+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:16:26,482] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:16:26.482+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.482+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:16:26.483+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:16:26,483] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:16:26.483+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.483+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:16:26.503+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.503+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:16:26.503+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.503+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T05:46:21.162403+00:00, execution_date=20241214T054621, start_date=, end_date=20241214T054626
[2024-12-14T11:16:26.516+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T11:16:26.517+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T11:16:26.517+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T11:16:26.517+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T11:16:26.518+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.517+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T11:16:26.536+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.536+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T11:16:26.536+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.536+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:46:21.162403+00:00 [scheduled]>
[2024-12-14T11:16:26.566+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:16:26,566] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:46:21.162403+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:46:21.162403+00:00'
[2024-12-14T11:16:26.567+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.566+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:46:21.162403+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:46:21.162403+00:00'
[2024-12-14T11:16:26.567+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:16:26.567+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:16:26.568+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T11:16:26.568+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:16:26.568+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.568+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:16:26.569+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:16:26,569] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:16:26.569+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.569+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:16:26.570+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:16:26,569] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:16:26.570+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.569+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:16:26.581+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:16:26,580] {subprocess.py:99} INFO - Output:
[2024-12-14T11:16:26.582+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.580+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:16:26.628+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:16:26,628] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp6dfkdvmq/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:16:26.629+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.628+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp6dfkdvmq/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:16:26.633+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:16:26,633] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:16:26.633+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.633+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:16:26.651+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:16:26,639] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:16:26.651+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.639+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:16:26.653+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T11:16:26.654+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 05:46:26.653237+00:00 duration:None
[2024-12-14T11:16:26.654+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 05:46:21.162403+00:00: manual__2024-12-14T05:46:21.162403+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:16:26.654+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:16:26.654+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.654+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T05:46:21.162403+00:00, execution_date=20241214T054621, start_date=, end_date=20241214T054626
[2024-12-14T11:16:26.668+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.668+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:16:26.674+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.668+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:46:21.162403+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:16:26.679+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.679+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 05:46:21.162403+00:00: manual__2024-12-14T05:46:21.162403+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T11:16:26.680+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T11:16:26.680+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T05:46:21.162403+00:00 external trigger: False
[2024-12-14T11:16:26.680+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T11:16:26.681+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.680+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 05:46:21.162403+00:00, run_id=manual__2024-12-14T05:46:21.162403+00:00, run_start_date=2024-12-14 05:46:21.162403+00:00, run_end_date=2024-12-14 05:46:26.680152+00:00, run_duration=5.517749, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 05:46:21.162403+00:00, data_interval_end=2024-12-14 05:46:21.162403+00:00, dag_hash=None
[2024-12-14T11:16:26.690+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:16:26.703+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.703+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T11:16:26.722+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:16:26.722+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T11:16:26.745+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.719 seconds
[2024-12-14T11:19:24.271+0530] {processor.py:186} INFO - Started process (PID=43377) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:19:24.273+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T11:19:24.274+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:24.274+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:19:24.438+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:24.437+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T11:19:24.461+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:24.460+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 05:49:24.404185+00:00: manual__2024-12-14T05:49:24.404185+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:19:24.493+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:24.493+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T11:19:24.494+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:24.493+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T05:49:24.404185+00:00 [scheduled]>
[2024-12-14T11:19:29.520+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.520+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T11:19:29.663+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:19:29,662] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:49:24.404185+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:49:24.404185+00:00'
[2024-12-14T11:19:29.663+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.662+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:49:24.404185+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:49:24.404185+00:00'
[2024-12-14T11:19:29.675+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:19:29.675+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:19:29.676+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T11:19:29.676+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:19:29.677+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.676+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:19:29.707+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:19:29,707] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:19:29.708+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.707+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:19:29.708+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:19:29,708] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:19:29.709+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.708+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:19:29.718+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:19:29,716] {subprocess.py:99} INFO - Output:
[2024-12-14T11:19:29.719+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.716+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:19:29.720+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:19:29,720] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:19:29.720+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.720+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:19:29.721+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:19:29,720] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:19:29.721+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.720+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:19:29.742+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.741+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:19:29.742+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.742+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T05:49:24.404185+00:00, execution_date=20241214T054924, start_date=, end_date=20241214T054929
[2024-12-14T11:19:29.754+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T11:19:29.754+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T11:19:29.754+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T11:19:29.755+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T11:19:29.755+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.755+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T11:19:29.773+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.773+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T11:19:29.774+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.774+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:49:24.404185+00:00 [scheduled]>
[2024-12-14T11:19:29.803+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:19:29,803] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:49:24.404185+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:49:24.404185+00:00'
[2024-12-14T11:19:29.804+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.803+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:49:24.404185+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:49:24.404185+00:00'
[2024-12-14T11:19:29.804+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:19:29.804+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:19:29.805+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T11:19:29.805+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:19:29.806+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.805+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:19:29.807+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:19:29,807] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:19:29.807+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.807+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:19:29.808+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:19:29,808] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:19:29.808+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.808+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:19:29.819+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:19:29,817] {subprocess.py:99} INFO - Output:
[2024-12-14T11:19:29.820+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.817+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:19:29.864+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:19:29,864] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpty4tb7w0/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:19:29.865+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.864+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpty4tb7w0/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:19:29.870+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:19:29,870] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:19:29.871+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.870+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:19:29.884+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:19:29,877] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:19:29.884+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.877+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:19:29.886+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T11:19:29.887+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 05:49:29.886373+00:00 duration:None
[2024-12-14T11:19:29.887+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 05:49:24.404185+00:00: manual__2024-12-14T05:49:24.404185+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:19:29.887+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:19:29.888+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.887+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T05:49:24.404185+00:00, execution_date=20241214T054924, start_date=, end_date=20241214T054929
[2024-12-14T11:19:29.901+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.900+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:19:29.905+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.901+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:49:24.404185+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:19:29.910+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.910+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 05:49:24.404185+00:00: manual__2024-12-14T05:49:24.404185+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T11:19:29.910+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T11:19:29.911+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T05:49:24.404185+00:00 external trigger: False
[2024-12-14T11:19:29.911+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T11:19:29.912+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.912+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 05:49:24.404185+00:00, run_id=manual__2024-12-14T05:49:24.404185+00:00, run_start_date=2024-12-14 05:49:24.404185+00:00, run_end_date=2024-12-14 05:49:29.910640+00:00, run_duration=5.506455, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 05:49:24.404185+00:00, data_interval_end=2024-12-14 05:49:24.404185+00:00, dag_hash=None
[2024-12-14T11:19:29.922+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:19:29.935+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.935+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T11:19:29.954+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:19:29.954+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T11:19:29.976+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.709 seconds
[2024-12-14T11:22:33.439+0530] {processor.py:186} INFO - Started process (PID=43593) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:22:33.440+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T11:22:33.442+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:33.442+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:22:33.596+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:33.596+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T11:22:33.612+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:33.612+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 05:52:33.565457+00:00: manual__2024-12-14T05:52:33.565457+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:22:33.646+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:33.645+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T11:22:33.646+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:33.646+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T05:52:33.565457+00:00 [scheduled]>
[2024-12-14T11:22:38.676+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:38.675+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T11:22:38.848+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:22:38,848] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:52:33.565457+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:52:33.565457+00:00'
[2024-12-14T11:22:38.850+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:38.848+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:52:33.565457+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:52:33.565457+00:00'
[2024-12-14T11:22:38.863+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:22:38.863+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:22:38.864+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T11:22:38.864+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:22:38.865+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:38.864+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:22:38.896+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:22:38,896] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:22:38.897+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:38.896+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:22:38.897+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:22:38,897] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:22:38.898+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:38.897+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:22:38.909+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:22:38,906] {subprocess.py:99} INFO - Output:
[2024-12-14T11:22:38.910+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:38.906+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:22:38.910+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:22:38,910] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:22:38.911+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:38.910+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:22:38.911+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:22:38,911] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:22:38.911+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:38.911+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:22:38.931+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:38.931+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:22:38.932+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:38.932+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T05:52:33.565457+00:00, execution_date=20241214T055233, start_date=, end_date=20241214T055238
[2024-12-14T11:22:38.942+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T11:22:38.943+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T11:22:38.943+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T11:22:38.943+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T11:22:38.944+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:38.943+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T11:22:38.980+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:38.980+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T11:22:38.981+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:38.981+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:52:33.565457+00:00 [scheduled]>
[2024-12-14T11:22:39.019+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:22:39,019] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:52:33.565457+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:52:33.565457+00:00'
[2024-12-14T11:22:39.019+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:39.019+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:52:33.565457+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:52:33.565457+00:00'
[2024-12-14T11:22:39.020+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:22:39.020+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:22:39.020+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T11:22:39.020+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:22:39.020+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:39.020+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:22:39.021+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:22:39,021] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:22:39.021+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:39.021+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:22:39.022+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:22:39,022] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:22:39.022+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:39.022+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:22:39.031+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:22:39,029] {subprocess.py:99} INFO - Output:
[2024-12-14T11:22:39.033+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:39.029+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:22:39.077+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:22:39,077] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp9_d17iw1/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:22:39.078+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:39.077+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp9_d17iw1/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:22:39.083+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:22:39,083] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:22:39.083+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:39.083+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:22:39.102+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:22:39,090] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:22:39.103+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:39.090+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:22:39.105+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T11:22:39.105+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 05:52:39.104872+00:00 duration:None
[2024-12-14T11:22:39.106+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 05:52:33.565457+00:00: manual__2024-12-14T05:52:33.565457+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:22:39.106+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:22:39.106+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:39.106+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T05:52:33.565457+00:00, execution_date=20241214T055233, start_date=, end_date=20241214T055239
[2024-12-14T11:22:39.118+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:39.118+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:22:39.124+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:39.118+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:52:33.565457+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:22:39.129+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:39.129+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 05:52:33.565457+00:00: manual__2024-12-14T05:52:33.565457+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T11:22:39.129+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T11:22:39.129+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T05:52:33.565457+00:00 external trigger: False
[2024-12-14T11:22:39.129+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T11:22:39.130+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:39.130+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 05:52:33.565457+00:00, run_id=manual__2024-12-14T05:52:33.565457+00:00, run_start_date=2024-12-14 05:52:33.565457+00:00, run_end_date=2024-12-14 05:52:39.129524+00:00, run_duration=5.564067, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 05:52:33.565457+00:00, data_interval_end=2024-12-14 05:52:33.565457+00:00, dag_hash=None
[2024-12-14T11:22:39.141+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:22:39.155+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:39.155+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T11:22:39.191+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:22:39.191+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T11:22:39.214+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.779 seconds
[2024-12-14T11:25:48.242+0530] {processor.py:186} INFO - Started process (PID=43827) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:25:48.245+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T11:25:48.247+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:48.246+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:25:48.444+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:48.444+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T11:25:48.460+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:48.460+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 05:55:48.409280+00:00: manual__2024-12-14T05:55:48.409280+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:25:48.493+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:48.493+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T11:25:48.494+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:48.493+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T05:55:48.409280+00:00 [scheduled]>
[2024-12-14T11:25:53.531+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.531+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T11:25:53.708+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:25:53,708] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:55:48.409280+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:55:48.409280+00:00'
[2024-12-14T11:25:53.708+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.708+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:55:48.409280+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:55:48.409280+00:00'
[2024-12-14T11:25:53.722+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:25:53.723+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:25:53.723+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T11:25:53.723+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:25:53.723+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.723+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:25:53.762+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:25:53,761] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:25:53.762+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.761+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:25:53.763+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:25:53,763] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:25:53.763+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.763+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:25:53.773+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:25:53,772] {subprocess.py:99} INFO - Output:
[2024-12-14T11:25:53.774+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.772+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:25:53.775+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:25:53,775] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:25:53.776+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.775+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:25:53.776+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:25:53,776] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:25:53.776+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.776+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:25:53.796+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.796+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:25:53.796+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.796+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T05:55:48.409280+00:00, execution_date=20241214T055548, start_date=, end_date=20241214T055553
[2024-12-14T11:25:53.808+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T11:25:53.808+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T11:25:53.809+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T11:25:53.809+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T11:25:53.809+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.809+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T11:25:53.828+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.828+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T11:25:53.829+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.829+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:55:48.409280+00:00 [scheduled]>
[2024-12-14T11:25:53.859+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:25:53,859] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:55:48.409280+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:55:48.409280+00:00'
[2024-12-14T11:25:53.860+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.859+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:55:48.409280+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:55:48.409280+00:00'
[2024-12-14T11:25:53.860+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:25:53.860+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:25:53.860+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T11:25:53.860+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:25:53.861+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.861+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:25:53.862+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:25:53,862] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:25:53.862+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.862+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:25:53.863+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:25:53,862] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:25:53.863+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.862+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:25:53.874+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:25:53,872] {subprocess.py:99} INFO - Output:
[2024-12-14T11:25:53.875+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.872+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:25:53.919+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:25:53,918] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpxbi3fmen/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:25:53.921+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.918+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpxbi3fmen/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:25:53.926+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:25:53,926] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:25:53.927+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.926+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:25:53.943+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:25:53,933] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:25:53.944+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.933+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:25:53.946+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T11:25:53.946+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 05:55:53.945817+00:00 duration:None
[2024-12-14T11:25:53.947+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 05:55:48.409280+00:00: manual__2024-12-14T05:55:48.409280+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:25:53.947+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:25:53.947+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.947+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T05:55:48.409280+00:00, execution_date=20241214T055548, start_date=, end_date=20241214T055553
[2024-12-14T11:25:53.959+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.959+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:25:53.965+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.959+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:55:48.409280+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:25:53.970+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.970+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 05:55:48.409280+00:00: manual__2024-12-14T05:55:48.409280+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T11:25:53.971+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T11:25:53.971+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T05:55:48.409280+00:00 external trigger: False
[2024-12-14T11:25:53.971+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T11:25:53.972+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.972+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 05:55:48.409280+00:00, run_id=manual__2024-12-14T05:55:48.409280+00:00, run_start_date=2024-12-14 05:55:48.409280+00:00, run_end_date=2024-12-14 05:55:53.970974+00:00, run_duration=5.561694, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 05:55:48.409280+00:00, data_interval_end=2024-12-14 05:55:48.409280+00:00, dag_hash=None
[2024-12-14T11:25:53.982+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:25:53.997+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:53.997+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T11:25:54.018+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:25:54.018+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T11:25:54.063+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.825 seconds
[2024-12-14T11:29:05.334+0530] {processor.py:186} INFO - Started process (PID=44038) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:29:05.336+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T11:29:05.338+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:05.338+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:29:05.506+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:05.506+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T11:29:05.521+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:05.520+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 05:59:05.473368+00:00: manual__2024-12-14T05:59:05.473368+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:29:05.556+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:05.556+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T11:29:05.557+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:05.556+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T05:59:05.473368+00:00 [scheduled]>
[2024-12-14T11:29:10.592+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:10.591+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T11:29:10.742+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:29:10,742] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:59:05.473368+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:59:05.473368+00:00'
[2024-12-14T11:29:10.742+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:10.742+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:59:05.473368+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:59:05.473368+00:00'
[2024-12-14T11:29:10.754+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:29:10.754+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:29:10.754+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T11:29:10.755+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:29:10.755+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:10.755+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:29:10.791+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:29:10,791] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:29:10.791+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:10.791+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:29:10.792+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:29:10,792] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:29:10.792+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:10.792+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:29:10.802+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:29:10,801] {subprocess.py:99} INFO - Output:
[2024-12-14T11:29:10.804+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:10.801+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:29:10.804+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:29:10,804] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:29:10.805+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:10.804+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:29:10.805+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:29:10,805] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:29:10.805+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:10.805+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:29:10.824+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:10.824+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:29:10.825+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:10.825+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T05:59:05.473368+00:00, execution_date=20241214T055905, start_date=, end_date=20241214T055910
[2024-12-14T11:29:10.838+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T11:29:10.838+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T11:29:10.839+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T11:29:10.839+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T11:29:10.839+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:10.839+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T11:29:10.856+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:10.856+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T11:29:10.857+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:10.856+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:59:05.473368+00:00 [scheduled]>
[2024-12-14T11:29:10.888+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:29:10,888] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:59:05.473368+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:59:05.473368+00:00'
[2024-12-14T11:29:10.889+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:10.888+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T05:59:05.473368+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T05:59:05.473368+00:00'
[2024-12-14T11:29:10.889+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:29:10.889+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:29:10.889+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T11:29:10.890+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:29:10.890+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:10.890+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:29:10.891+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:29:10,890] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:29:10.891+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:10.890+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:29:10.891+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:29:10,891] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:29:10.892+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:10.891+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:29:10.901+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:29:10,899] {subprocess.py:99} INFO - Output:
[2024-12-14T11:29:10.902+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:10.899+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:29:10.947+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:29:10,946] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmprx0mgsd1/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:29:10.948+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:10.946+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmprx0mgsd1/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:29:10.954+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:29:10,954] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:29:10.954+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:10.954+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:29:10.969+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:29:10,961] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:29:10.969+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:10.961+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:29:10.971+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T11:29:10.971+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 05:59:10.971168+00:00 duration:None
[2024-12-14T11:29:10.972+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 05:59:05.473368+00:00: manual__2024-12-14T05:59:05.473368+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:29:10.972+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:29:10.972+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:10.972+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T05:59:05.473368+00:00, execution_date=20241214T055905, start_date=, end_date=20241214T055910
[2024-12-14T11:29:10.985+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:10.984+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:29:10.991+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:10.985+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T05:59:05.473368+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:29:10.994+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:10.994+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 05:59:05.473368+00:00: manual__2024-12-14T05:59:05.473368+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T11:29:10.995+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T11:29:10.995+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T05:59:05.473368+00:00 external trigger: False
[2024-12-14T11:29:10.995+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T11:29:10.995+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:10.995+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 05:59:05.473368+00:00, run_id=manual__2024-12-14T05:59:05.473368+00:00, run_start_date=2024-12-14 05:59:05.473368+00:00, run_end_date=2024-12-14 05:59:10.995143+00:00, run_duration=5.521775, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 05:59:05.473368+00:00, data_interval_end=2024-12-14 05:59:05.473368+00:00, dag_hash=None
[2024-12-14T11:29:11.006+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:29:11.020+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:11.020+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T11:29:11.040+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:29:11.040+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T11:29:11.060+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.731 seconds
[2024-12-14T11:32:17.895+0530] {processor.py:186} INFO - Started process (PID=44258) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:32:17.898+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T11:32:17.899+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:17.899+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:32:18.056+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:18.056+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T11:32:18.072+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:18.070+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 06:02:18.027005+00:00: manual__2024-12-14T06:02:18.027005+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:32:18.110+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:18.110+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T11:32:18.111+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:18.110+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T06:02:18.027005+00:00 [scheduled]>
[2024-12-14T11:32:23.137+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.137+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T11:32:23.285+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:32:23,285] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:02:18.027005+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:02:18.027005+00:00'
[2024-12-14T11:32:23.285+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.285+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:02:18.027005+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:02:18.027005+00:00'
[2024-12-14T11:32:23.297+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:32:23.297+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:32:23.298+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T11:32:23.298+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:32:23.298+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.298+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:32:23.333+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:32:23,333] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:32:23.333+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.333+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:32:23.334+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:32:23,334] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:32:23.334+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.334+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:32:23.344+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:32:23,342] {subprocess.py:99} INFO - Output:
[2024-12-14T11:32:23.345+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.342+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:32:23.346+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:32:23,346] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:32:23.346+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.346+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:32:23.347+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:32:23,346] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:32:23.347+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.346+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:32:23.366+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.366+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:32:23.367+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.366+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T06:02:18.027005+00:00, execution_date=20241214T060218, start_date=, end_date=20241214T060223
[2024-12-14T11:32:23.379+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T11:32:23.379+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T11:32:23.379+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T11:32:23.379+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T11:32:23.380+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.380+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T11:32:23.398+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.398+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T11:32:23.399+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.398+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:02:18.027005+00:00 [scheduled]>
[2024-12-14T11:32:23.432+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:32:23,432] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:02:18.027005+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:02:18.027005+00:00'
[2024-12-14T11:32:23.432+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.432+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:02:18.027005+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:02:18.027005+00:00'
[2024-12-14T11:32:23.433+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:32:23.433+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:32:23.433+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T11:32:23.433+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:32:23.434+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.434+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:32:23.434+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:32:23,434] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:32:23.435+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.434+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:32:23.435+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:32:23,435] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:32:23.436+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.435+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:32:23.445+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:32:23,444] {subprocess.py:99} INFO - Output:
[2024-12-14T11:32:23.447+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.444+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:32:23.492+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:32:23,492] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp1wn9wa1l/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:32:23.493+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.492+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp1wn9wa1l/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:32:23.497+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:32:23,497] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:32:23.498+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.497+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:32:23.515+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:32:23,504] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:32:23.516+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.504+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:32:23.518+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T11:32:23.518+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 06:02:23.517801+00:00 duration:None
[2024-12-14T11:32:23.518+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 06:02:18.027005+00:00: manual__2024-12-14T06:02:18.027005+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:32:23.519+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:32:23.519+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.519+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T06:02:18.027005+00:00, execution_date=20241214T060218, start_date=, end_date=20241214T060223
[2024-12-14T11:32:23.532+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.531+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:32:23.540+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.532+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:02:18.027005+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:32:23.545+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.544+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 06:02:18.027005+00:00: manual__2024-12-14T06:02:18.027005+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T11:32:23.545+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T11:32:23.545+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T06:02:18.027005+00:00 external trigger: False
[2024-12-14T11:32:23.545+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T11:32:23.546+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.546+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 06:02:18.027005+00:00, run_id=manual__2024-12-14T06:02:18.027005+00:00, run_start_date=2024-12-14 06:02:18.027005+00:00, run_end_date=2024-12-14 06:02:23.545427+00:00, run_duration=5.518422, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 06:02:18.027005+00:00, data_interval_end=2024-12-14 06:02:18.027005+00:00, dag_hash=None
[2024-12-14T11:32:23.557+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:32:23.570+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.570+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T11:32:23.591+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:32:23.591+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T11:32:23.613+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.722 seconds
[2024-12-14T11:35:31.486+0530] {processor.py:186} INFO - Started process (PID=44466) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:35:31.489+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T11:35:31.490+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:31.490+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:35:31.648+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:31.647+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T11:35:31.663+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:31.662+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 06:05:31.613136+00:00: manual__2024-12-14T06:05:31.613136+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:35:31.705+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:31.705+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T11:35:31.706+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:31.706+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T06:05:31.613136+00:00 [scheduled]>
[2024-12-14T11:35:36.740+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:36.740+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T11:35:36.897+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:35:36,897] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:05:31.613136+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:05:31.613136+00:00'
[2024-12-14T11:35:36.898+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:36.897+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:05:31.613136+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:05:31.613136+00:00'
[2024-12-14T11:35:36.911+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:35:36.912+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:35:36.912+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T11:35:36.912+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:35:36.913+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:36.913+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:35:36.950+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:35:36,949] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:35:36.950+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:36.949+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:35:36.951+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:35:36,950] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:35:36.951+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:36.950+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:35:36.961+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:35:36,959] {subprocess.py:99} INFO - Output:
[2024-12-14T11:35:36.963+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:36.959+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:35:36.964+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:35:36,963] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:35:36.964+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:36.963+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:35:36.964+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:35:36,964] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:35:36.965+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:36.964+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:35:36.984+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:36.984+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:35:36.985+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:36.985+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T06:05:31.613136+00:00, execution_date=20241214T060531, start_date=, end_date=20241214T060536
[2024-12-14T11:35:36.997+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T11:35:36.997+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T11:35:36.998+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T11:35:36.998+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T11:35:36.998+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:36.998+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T11:35:37.017+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:37.017+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T11:35:37.018+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:37.018+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:05:31.613136+00:00 [scheduled]>
[2024-12-14T11:35:37.048+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:35:37,048] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:05:31.613136+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:05:31.613136+00:00'
[2024-12-14T11:35:37.049+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:37.048+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:05:31.613136+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:05:31.613136+00:00'
[2024-12-14T11:35:37.049+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:35:37.049+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:35:37.049+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T11:35:37.049+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:35:37.050+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:37.050+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:35:37.050+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:35:37,050] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:35:37.051+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:37.050+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:35:37.051+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:35:37,051] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:35:37.052+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:37.051+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:35:37.060+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:35:37,059] {subprocess.py:99} INFO - Output:
[2024-12-14T11:35:37.063+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:37.059+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:35:37.130+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:35:37,129] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp3s3tkeov/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:35:37.130+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:37.129+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp3s3tkeov/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:35:37.134+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:35:37,134] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:35:37.135+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:37.134+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:35:37.152+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:35:37,146] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:35:37.153+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:37.146+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:35:37.155+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T11:35:37.155+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 06:05:37.154474+00:00 duration:None
[2024-12-14T11:35:37.156+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 06:05:31.613136+00:00: manual__2024-12-14T06:05:31.613136+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:35:37.156+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:35:37.156+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:37.156+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T06:05:31.613136+00:00, execution_date=20241214T060531, start_date=, end_date=20241214T060537
[2024-12-14T11:35:37.169+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:37.169+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:35:37.178+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:37.169+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:05:31.613136+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:35:37.182+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:37.182+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 06:05:31.613136+00:00: manual__2024-12-14T06:05:31.613136+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T11:35:37.182+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T11:35:37.182+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T06:05:31.613136+00:00 external trigger: False
[2024-12-14T11:35:37.183+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T11:35:37.183+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:37.183+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 06:05:31.613136+00:00, run_id=manual__2024-12-14T06:05:31.613136+00:00, run_start_date=2024-12-14 06:05:31.613136+00:00, run_end_date=2024-12-14 06:05:37.182561+00:00, run_duration=5.569425, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 06:05:31.613136+00:00, data_interval_end=2024-12-14 06:05:31.613136+00:00, dag_hash=None
[2024-12-14T11:35:37.192+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:35:37.206+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:37.206+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T11:35:37.229+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:35:37.229+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T11:35:37.253+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.771 seconds
[2024-12-14T11:38:47.664+0530] {processor.py:186} INFO - Started process (PID=44684) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:38:47.666+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T11:38:47.668+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:47.668+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:38:47.824+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:47.824+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T11:38:47.838+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:47.837+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 06:08:47.795245+00:00: manual__2024-12-14T06:08:47.795245+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:38:47.874+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:47.874+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T11:38:47.875+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:47.875+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T06:08:47.795245+00:00 [scheduled]>
[2024-12-14T11:38:52.910+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:52.910+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T11:38:53.075+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:38:53,075] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:08:47.795245+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:08:47.795245+00:00'
[2024-12-14T11:38:53.076+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.075+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:08:47.795245+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:08:47.795245+00:00'
[2024-12-14T11:38:53.087+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:38:53.087+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:38:53.088+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T11:38:53.088+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:38:53.089+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.088+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:38:53.124+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:38:53,124] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:38:53.125+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.124+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:38:53.126+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:38:53,125] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:38:53.126+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.125+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:38:53.135+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:38:53,134] {subprocess.py:99} INFO - Output:
[2024-12-14T11:38:53.137+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.134+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:38:53.140+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:38:53,140] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:38:53.141+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.140+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:38:53.141+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:38:53,141] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:38:53.141+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.141+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:38:53.162+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.162+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:38:53.163+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.163+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T06:08:47.795245+00:00, execution_date=20241214T060847, start_date=, end_date=20241214T060853
[2024-12-14T11:38:53.175+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T11:38:53.175+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T11:38:53.176+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T11:38:53.176+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T11:38:53.176+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.176+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T11:38:53.194+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.194+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T11:38:53.195+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.195+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:08:47.795245+00:00 [scheduled]>
[2024-12-14T11:38:53.224+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:38:53,224] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:08:47.795245+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:08:47.795245+00:00'
[2024-12-14T11:38:53.224+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.224+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:08:47.795245+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:08:47.795245+00:00'
[2024-12-14T11:38:53.224+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:38:53.225+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:38:53.225+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T11:38:53.225+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:38:53.225+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.225+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:38:53.226+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:38:53,226] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:38:53.227+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.226+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:38:53.229+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:38:53,229] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:38:53.230+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.229+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:38:53.242+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:38:53,239] {subprocess.py:99} INFO - Output:
[2024-12-14T11:38:53.243+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.239+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:38:53.300+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:38:53,300] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmposj8epad/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:38:53.301+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.300+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmposj8epad/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:38:53.308+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:38:53,307] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:38:53.308+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.307+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:38:53.323+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:38:53,317] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:38:53.324+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.317+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:38:53.326+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T11:38:53.327+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 06:08:53.326199+00:00 duration:None
[2024-12-14T11:38:53.327+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 06:08:47.795245+00:00: manual__2024-12-14T06:08:47.795245+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:38:53.327+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:38:53.328+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.327+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T06:08:47.795245+00:00, execution_date=20241214T060847, start_date=, end_date=20241214T060853
[2024-12-14T11:38:53.340+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.340+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:38:53.346+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.340+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:08:47.795245+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:38:53.351+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.351+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 06:08:47.795245+00:00: manual__2024-12-14T06:08:47.795245+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T11:38:53.351+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T11:38:53.351+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T06:08:47.795245+00:00 external trigger: False
[2024-12-14T11:38:53.352+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T11:38:53.352+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.352+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 06:08:47.795245+00:00, run_id=manual__2024-12-14T06:08:47.795245+00:00, run_start_date=2024-12-14 06:08:47.795245+00:00, run_end_date=2024-12-14 06:08:53.351643+00:00, run_duration=5.556398, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 06:08:47.795245+00:00, data_interval_end=2024-12-14 06:08:47.795245+00:00, dag_hash=None
[2024-12-14T11:38:53.361+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:38:53.376+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.376+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T11:38:53.400+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:38:53.400+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T11:38:53.419+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.759 seconds
[2024-12-14T11:41:58.120+0530] {processor.py:186} INFO - Started process (PID=44927) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:41:58.123+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T11:41:58.125+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:41:58.125+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:41:58.286+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:41:58.286+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T11:41:58.302+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:41:58.302+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 06:11:58.256334+00:00: manual__2024-12-14T06:11:58.256334+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:41:58.346+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:41:58.346+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T11:41:58.347+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:41:58.347+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T06:11:58.256334+00:00 [scheduled]>
[2024-12-14T11:42:03.374+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.374+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T11:42:03.521+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:42:03,520] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:11:58.256334+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:11:58.256334+00:00'
[2024-12-14T11:42:03.521+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.520+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:11:58.256334+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:11:58.256334+00:00'
[2024-12-14T11:42:03.533+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:42:03.534+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:42:03.534+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T11:42:03.534+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:42:03.535+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.534+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:42:03.569+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:42:03,569] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:42:03.570+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.569+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:42:03.571+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:42:03,571] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:42:03.571+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.571+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:42:03.581+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:42:03,580] {subprocess.py:99} INFO - Output:
[2024-12-14T11:42:03.583+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.580+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:42:03.584+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:42:03,583] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:42:03.584+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.583+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:42:03.584+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:42:03,584] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:42:03.585+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.584+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:42:03.604+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.604+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:42:03.605+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.605+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T06:11:58.256334+00:00, execution_date=20241214T061158, start_date=, end_date=20241214T061203
[2024-12-14T11:42:03.615+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T11:42:03.616+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T11:42:03.616+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T11:42:03.616+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T11:42:03.617+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.617+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T11:42:03.636+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.636+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T11:42:03.637+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.636+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:11:58.256334+00:00 [scheduled]>
[2024-12-14T11:42:03.667+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:42:03,667] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:11:58.256334+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:11:58.256334+00:00'
[2024-12-14T11:42:03.668+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.667+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:11:58.256334+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:11:58.256334+00:00'
[2024-12-14T11:42:03.668+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:42:03.669+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:42:03.669+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T11:42:03.669+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:42:03.669+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.669+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:42:03.670+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:42:03,670] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:42:03.671+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.670+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:42:03.671+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:42:03,671] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:42:03.672+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.671+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:42:03.680+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:42:03,679] {subprocess.py:99} INFO - Output:
[2024-12-14T11:42:03.682+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.679+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:42:03.726+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:42:03,726] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpf9h9_soq/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:42:03.727+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.726+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpf9h9_soq/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:42:03.731+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:42:03,731] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:42:03.732+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.731+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:42:03.746+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:42:03,739] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:42:03.747+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.739+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:42:03.748+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T11:42:03.749+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 06:12:03.748449+00:00 duration:None
[2024-12-14T11:42:03.749+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 06:11:58.256334+00:00: manual__2024-12-14T06:11:58.256334+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:42:03.749+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:42:03.750+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.749+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T06:11:58.256334+00:00, execution_date=20241214T061158, start_date=, end_date=20241214T061203
[2024-12-14T11:42:03.761+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.760+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:42:03.767+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.761+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:11:58.256334+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:42:03.774+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.773+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 06:11:58.256334+00:00: manual__2024-12-14T06:11:58.256334+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T11:42:03.774+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T11:42:03.775+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T06:11:58.256334+00:00 external trigger: False
[2024-12-14T11:42:03.775+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T11:42:03.776+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.775+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 06:11:58.256334+00:00, run_id=manual__2024-12-14T06:11:58.256334+00:00, run_start_date=2024-12-14 06:11:58.256334+00:00, run_end_date=2024-12-14 06:12:03.774445+00:00, run_duration=5.518111, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 06:11:58.256334+00:00, data_interval_end=2024-12-14 06:11:58.256334+00:00, dag_hash=None
[2024-12-14T11:42:03.785+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:42:03.800+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.800+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T11:42:03.822+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:42:03.822+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T11:42:03.841+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.725 seconds
[2024-12-14T11:45:06.297+0530] {processor.py:186} INFO - Started process (PID=45132) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:45:06.298+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T11:45:06.300+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:06.299+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:45:06.460+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:06.460+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T11:45:06.481+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:06.480+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 06:15:06.429928+00:00: manual__2024-12-14T06:15:06.429928+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:45:06.513+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:06.512+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T11:45:06.513+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:06.513+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T06:15:06.429928+00:00 [scheduled]>
[2024-12-14T11:45:11.540+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.540+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T11:45:11.685+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:45:11,685] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:15:06.429928+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:15:06.429928+00:00'
[2024-12-14T11:45:11.686+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.685+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:15:06.429928+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:15:06.429928+00:00'
[2024-12-14T11:45:11.689+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:45:11.689+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:45:11.689+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T11:45:11.689+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:45:11.690+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.690+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:45:11.723+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:45:11,723] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:45:11.725+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.723+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:45:11.726+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:45:11,726] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:45:11.727+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.726+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:45:11.737+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:45:11,735] {subprocess.py:99} INFO - Output:
[2024-12-14T11:45:11.738+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.735+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:45:11.738+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:45:11,738] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:45:11.739+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.738+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:45:11.739+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:45:11,739] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:45:11.739+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.739+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:45:11.761+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.761+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:45:11.762+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.762+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T06:15:06.429928+00:00, execution_date=20241214T061506, start_date=, end_date=20241214T061511
[2024-12-14T11:45:11.772+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T11:45:11.773+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T11:45:11.773+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T11:45:11.773+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T11:45:11.774+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.773+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T11:45:11.792+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.792+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T11:45:11.793+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.793+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:15:06.429928+00:00 [scheduled]>
[2024-12-14T11:45:11.823+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:45:11,822] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:15:06.429928+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:15:06.429928+00:00'
[2024-12-14T11:45:11.823+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.822+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:15:06.429928+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:15:06.429928+00:00'
[2024-12-14T11:45:11.824+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:45:11.824+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:45:11.825+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T11:45:11.826+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:45:11.826+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.826+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:45:11.827+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:45:11,827] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:45:11.827+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.827+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:45:11.828+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:45:11,827] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:45:11.828+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.827+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:45:11.837+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:45:11,835] {subprocess.py:99} INFO - Output:
[2024-12-14T11:45:11.839+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.835+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:45:11.884+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:45:11,884] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpsw3mfsfe/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:45:11.885+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.884+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpsw3mfsfe/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:45:11.890+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:45:11,890] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:45:11.892+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.890+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:45:11.901+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:45:11,899] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:45:11.901+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.899+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:45:11.903+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T11:45:11.904+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 06:15:11.903348+00:00 duration:None
[2024-12-14T11:45:11.904+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 06:15:06.429928+00:00: manual__2024-12-14T06:15:06.429928+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:45:11.904+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:45:11.905+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.905+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T06:15:06.429928+00:00, execution_date=20241214T061506, start_date=, end_date=20241214T061511
[2024-12-14T11:45:11.916+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.916+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:45:11.919+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.917+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:15:06.429928+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:45:11.924+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.923+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 06:15:06.429928+00:00: manual__2024-12-14T06:15:06.429928+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T11:45:11.924+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T11:45:11.924+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T06:15:06.429928+00:00 external trigger: False
[2024-12-14T11:45:11.924+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T11:45:11.925+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.925+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 06:15:06.429928+00:00, run_id=manual__2024-12-14T06:15:06.429928+00:00, run_start_date=2024-12-14 06:15:06.429928+00:00, run_end_date=2024-12-14 06:15:11.924373+00:00, run_duration=5.494445, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 06:15:06.429928+00:00, data_interval_end=2024-12-14 06:15:06.429928+00:00, dag_hash=None
[2024-12-14T11:45:11.935+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:45:11.949+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.949+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T11:45:11.971+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:45:11.970+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T11:45:11.992+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.698 seconds
[2024-12-14T11:48:13.162+0530] {processor.py:186} INFO - Started process (PID=45347) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:48:13.163+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T11:48:13.165+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:13.164+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:48:13.327+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:13.327+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T11:48:13.342+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:13.342+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 06:18:13.292538+00:00: manual__2024-12-14T06:18:13.292538+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:48:13.371+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:13.371+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T11:48:13.371+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:13.371+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T06:18:13.292538+00:00 [scheduled]>
[2024-12-14T11:48:18.399+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.399+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T11:48:18.546+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:48:18,545] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:18:13.292538+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:18:13.292538+00:00'
[2024-12-14T11:48:18.546+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.545+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:18:13.292538+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:18:13.292538+00:00'
[2024-12-14T11:48:18.549+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:48:18.550+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:48:18.550+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T11:48:18.551+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:48:18.551+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.551+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:48:18.585+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:48:18,584] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:48:18.585+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.584+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:48:18.586+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:48:18,586] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:48:18.586+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.586+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:48:18.595+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:48:18,593] {subprocess.py:99} INFO - Output:
[2024-12-14T11:48:18.596+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.593+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:48:18.597+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:48:18,597] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:48:18.597+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.597+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:48:18.597+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:48:18,597] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:48:18.598+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.597+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:48:18.621+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.621+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:48:18.621+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.621+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T06:18:13.292538+00:00, execution_date=20241214T061813, start_date=, end_date=20241214T061818
[2024-12-14T11:48:18.631+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T11:48:18.632+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T11:48:18.632+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T11:48:18.632+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T11:48:18.633+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.632+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T11:48:18.649+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.649+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T11:48:18.650+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.649+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:18:13.292538+00:00 [scheduled]>
[2024-12-14T11:48:18.677+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:48:18,677] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:18:13.292538+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:18:13.292538+00:00'
[2024-12-14T11:48:18.678+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.677+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:18:13.292538+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:18:13.292538+00:00'
[2024-12-14T11:48:18.678+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:48:18.678+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:48:18.678+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T11:48:18.678+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:48:18.679+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.679+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:48:18.679+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:48:18,679] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:48:18.680+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.679+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:48:18.681+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:48:18,681] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:48:18.682+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.681+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:48:18.693+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:48:18,691] {subprocess.py:99} INFO - Output:
[2024-12-14T11:48:18.694+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.691+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:48:18.739+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:48:18,739] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp2d7_x8zj/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:48:18.740+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.739+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp2d7_x8zj/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:48:18.745+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:48:18,744] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:48:18.745+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.744+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:48:18.755+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:48:18,753] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:48:18.755+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.753+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:48:18.758+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T11:48:18.758+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 06:18:18.757347+00:00 duration:None
[2024-12-14T11:48:18.759+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 06:18:13.292538+00:00: manual__2024-12-14T06:18:13.292538+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:48:18.759+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:48:18.759+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.759+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T06:18:13.292538+00:00, execution_date=20241214T061813, start_date=, end_date=20241214T061818
[2024-12-14T11:48:18.774+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.774+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:48:18.777+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.774+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:18:13.292538+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:48:18.781+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.781+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 06:18:13.292538+00:00: manual__2024-12-14T06:18:13.292538+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T11:48:18.782+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T11:48:18.782+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T06:18:13.292538+00:00 external trigger: False
[2024-12-14T11:48:18.782+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T11:48:18.782+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.782+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 06:18:13.292538+00:00, run_id=manual__2024-12-14T06:18:13.292538+00:00, run_start_date=2024-12-14 06:18:13.292538+00:00, run_end_date=2024-12-14 06:18:18.781926+00:00, run_duration=5.489388, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 06:18:13.292538+00:00, data_interval_end=2024-12-14 06:18:13.292538+00:00, dag_hash=None
[2024-12-14T11:48:18.793+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:48:18.806+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.806+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T11:48:18.825+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:48:18.825+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T11:48:18.846+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.688 seconds
[2024-12-14T11:51:29.550+0530] {processor.py:186} INFO - Started process (PID=45564) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:51:29.552+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T11:51:29.554+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:29.554+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:51:29.719+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:29.718+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T11:51:29.734+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:29.733+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 06:21:29.683934+00:00: manual__2024-12-14T06:21:29.683934+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:51:29.763+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:29.762+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T11:51:29.764+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:29.763+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T06:21:29.683934+00:00 [scheduled]>
[2024-12-14T11:51:34.794+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:34.793+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T11:51:34.950+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:51:34,949] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:21:29.683934+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:21:29.683934+00:00'
[2024-12-14T11:51:34.950+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:34.949+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:21:29.683934+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:21:29.683934+00:00'
[2024-12-14T11:51:34.953+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:51:34.953+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:51:34.954+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T11:51:34.954+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:51:34.954+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:34.954+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:51:34.987+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:51:34,986] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:51:34.987+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:34.986+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:51:34.988+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:51:34,988] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:51:34.988+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:34.988+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:51:34.999+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:51:34,997] {subprocess.py:99} INFO - Output:
[2024-12-14T11:51:35.001+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:34.997+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:51:35.002+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:51:35,001] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:51:35.002+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:35.001+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:51:35.003+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:51:35,003] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:51:35.003+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:35.003+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:51:35.027+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:35.027+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:51:35.028+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:35.028+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T06:21:29.683934+00:00, execution_date=20241214T062129, start_date=, end_date=20241214T062135
[2024-12-14T11:51:35.039+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T11:51:35.039+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T11:51:35.039+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T11:51:35.039+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T11:51:35.040+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:35.040+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T11:51:35.056+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:35.056+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T11:51:35.056+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:35.056+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:21:29.683934+00:00 [scheduled]>
[2024-12-14T11:51:35.087+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:51:35,087] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:21:29.683934+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:21:29.683934+00:00'
[2024-12-14T11:51:35.088+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:35.087+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:21:29.683934+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:21:29.683934+00:00'
[2024-12-14T11:51:35.088+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:51:35.088+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:51:35.089+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T11:51:35.089+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:51:35.089+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:35.089+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:51:35.092+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:51:35,090] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:51:35.093+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:35.090+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:51:35.094+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:51:35,094] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:51:35.095+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:35.094+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:51:35.104+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:51:35,103] {subprocess.py:99} INFO - Output:
[2024-12-14T11:51:35.105+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:35.103+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:51:35.156+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:51:35,156] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp9p3sdtgv/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:51:35.159+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:35.156+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp9p3sdtgv/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:51:35.163+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:51:35,162] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:51:35.163+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:35.162+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:51:35.173+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:51:35,171] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:51:35.175+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:35.171+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:51:35.177+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T11:51:35.177+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 06:21:35.176651+00:00 duration:None
[2024-12-14T11:51:35.177+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 06:21:29.683934+00:00: manual__2024-12-14T06:21:29.683934+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:51:35.177+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:51:35.178+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:35.178+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T06:21:29.683934+00:00, execution_date=20241214T062129, start_date=, end_date=20241214T062135
[2024-12-14T11:51:35.189+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:35.189+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:51:35.193+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:35.190+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:21:29.683934+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:51:35.197+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:35.197+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 06:21:29.683934+00:00: manual__2024-12-14T06:21:29.683934+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T11:51:35.198+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T11:51:35.198+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T06:21:29.683934+00:00 external trigger: False
[2024-12-14T11:51:35.198+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T11:51:35.199+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:35.198+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 06:21:29.683934+00:00, run_id=manual__2024-12-14T06:21:29.683934+00:00, run_start_date=2024-12-14 06:21:29.683934+00:00, run_end_date=2024-12-14 06:21:35.198052+00:00, run_duration=5.514118, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 06:21:29.683934+00:00, data_interval_end=2024-12-14 06:21:29.683934+00:00, dag_hash=None
[2024-12-14T11:51:35.209+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:51:35.222+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:35.222+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T11:51:35.246+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:51:35.246+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T11:51:35.267+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.720 seconds
[2024-12-14T11:54:48.333+0530] {processor.py:186} INFO - Started process (PID=45798) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:54:48.335+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T11:54:48.337+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:48.337+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:54:48.526+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:48.526+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T11:54:48.541+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:48.541+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 06:24:48.494964+00:00: manual__2024-12-14T06:24:48.494964+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:54:48.581+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:48.581+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T11:54:48.582+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:48.581+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T06:24:48.494964+00:00 [scheduled]>
[2024-12-14T11:54:53.607+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:53.607+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T11:54:53.756+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:54:53,756] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:24:48.494964+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:24:48.494964+00:00'
[2024-12-14T11:54:53.757+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:53.756+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:24:48.494964+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:24:48.494964+00:00'
[2024-12-14T11:54:53.770+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:54:53.771+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:54:53.771+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T11:54:53.772+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:54:53.772+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:53.772+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:54:53.808+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:54:53,807] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:54:53.808+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:53.807+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:54:53.809+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:54:53,808] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:54:53.809+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:53.808+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:54:53.820+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:54:53,818] {subprocess.py:99} INFO - Output:
[2024-12-14T11:54:53.821+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:53.818+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:54:53.821+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:54:53,821] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:54:53.822+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:53.821+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:54:53.822+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:54:53,822] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:54:53.822+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:53.822+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:54:53.841+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:53.841+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:54:53.842+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:53.842+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T06:24:48.494964+00:00, execution_date=20241214T062448, start_date=, end_date=20241214T062453
[2024-12-14T11:54:53.853+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T11:54:53.853+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T11:54:53.854+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T11:54:53.854+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T11:54:53.855+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:53.855+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T11:54:53.874+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:53.873+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T11:54:53.874+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:53.874+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:24:48.494964+00:00 [scheduled]>
[2024-12-14T11:54:53.905+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:54:53,904] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:24:48.494964+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:24:48.494964+00:00'
[2024-12-14T11:54:53.905+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:53.904+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:24:48.494964+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:24:48.494964+00:00'
[2024-12-14T11:54:53.906+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:54:53.906+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:54:53.906+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T11:54:53.906+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:54:53.906+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:53.906+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:54:53.907+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:54:53,907] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:54:53.907+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:53.907+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:54:53.908+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:54:53,908] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:54:53.908+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:53.908+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:54:53.918+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:54:53,917] {subprocess.py:99} INFO - Output:
[2024-12-14T11:54:53.920+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:53.917+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:54:53.965+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:54:53,965] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpovwwe9wj/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:54:53.966+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:53.965+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpovwwe9wj/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:54:53.970+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:54:53,970] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:54:53.971+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:53.970+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:54:53.986+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:54:53,977] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:54:53.987+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:53.977+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:54:53.989+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T11:54:53.989+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 06:24:53.988877+00:00 duration:None
[2024-12-14T11:54:53.990+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 06:24:48.494964+00:00: manual__2024-12-14T06:24:48.494964+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:54:53.990+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:54:53.990+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:53.990+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T06:24:48.494964+00:00, execution_date=20241214T062448, start_date=, end_date=20241214T062453
[2024-12-14T11:54:54.002+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:54.001+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:54:54.008+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:54.002+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:24:48.494964+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:54:54.011+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:54.011+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 06:24:48.494964+00:00: manual__2024-12-14T06:24:48.494964+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T11:54:54.012+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T11:54:54.012+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T06:24:48.494964+00:00 external trigger: False
[2024-12-14T11:54:54.013+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T11:54:54.014+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:54.014+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 06:24:48.494964+00:00, run_id=manual__2024-12-14T06:24:48.494964+00:00, run_start_date=2024-12-14 06:24:48.494964+00:00, run_end_date=2024-12-14 06:24:54.012201+00:00, run_duration=5.517237, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 06:24:48.494964+00:00, data_interval_end=2024-12-14 06:24:48.494964+00:00, dag_hash=None
[2024-12-14T11:54:54.024+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:54:54.039+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:54.039+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T11:54:54.059+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:54:54.058+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T11:54:54.079+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.751 seconds
[2024-12-14T11:57:59.158+0530] {processor.py:186} INFO - Started process (PID=46012) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:57:59.160+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T11:57:59.162+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:57:59.161+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:57:59.324+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:57:59.324+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T11:57:59.339+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:57:59.339+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 06:27:59.289361+00:00: manual__2024-12-14T06:27:59.289361+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:57:59.375+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:57:59.375+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T11:57:59.375+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:57:59.375+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T06:27:59.289361+00:00 [scheduled]>
[2024-12-14T11:58:04.402+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.401+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T11:58:04.550+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:58:04,550] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:27:59.289361+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:27:59.289361+00:00'
[2024-12-14T11:58:04.550+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.550+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:27:59.289361+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:27:59.289361+00:00'
[2024-12-14T11:58:04.563+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:58:04.563+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:58:04.564+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T11:58:04.564+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:58:04.564+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.564+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:58:04.597+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:58:04,597] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:58:04.598+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.597+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:58:04.598+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:58:04,598] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:58:04.599+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.598+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T11:58:04.608+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:58:04,606] {subprocess.py:99} INFO - Output:
[2024-12-14T11:58:04.610+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.606+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:58:04.610+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:58:04,610] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:58:04.611+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.610+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T11:58:04.611+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:58:04,611] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:58:04.611+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.611+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T11:58:04.632+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.632+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:58:04.632+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.632+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T06:27:59.289361+00:00, execution_date=20241214T062759, start_date=, end_date=20241214T062804
[2024-12-14T11:58:04.644+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T11:58:04.645+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T11:58:04.645+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T11:58:04.645+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T11:58:04.646+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.645+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T11:58:04.664+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.663+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T11:58:04.664+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.664+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:27:59.289361+00:00 [scheduled]>
[2024-12-14T11:58:04.693+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:58:04,693] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:27:59.289361+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:27:59.289361+00:00'
[2024-12-14T11:58:04.694+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.693+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:27:59.289361+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:27:59.289361+00:00'
[2024-12-14T11:58:04.694+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T11:58:04.694+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T11:58:04.694+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T11:58:04.694+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T11:58:04.695+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.695+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T11:58:04.695+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:58:04,695] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:58:04.696+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.695+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T11:58:04.696+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:58:04,696] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:58:04.697+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.696+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T11:58:04.708+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:58:04,706] {subprocess.py:99} INFO - Output:
[2024-12-14T11:58:04.710+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.706+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T11:58:04.764+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:58:04,764] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpfg2q074d/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:58:04.765+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.764+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpfg2q074d/controller.py': [Errno 2] No such file or directory
[2024-12-14T11:58:04.769+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:58:04,769] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:58:04.770+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.769+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T11:58:04.791+0530] {logging_mixin.py:190} INFO - [2024-12-14 11:58:04,778] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:58:04.792+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.778+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:58:04.794+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T11:58:04.794+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 06:28:04.793705+00:00 duration:None
[2024-12-14T11:58:04.794+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 06:27:59.289361+00:00: manual__2024-12-14T06:27:59.289361+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T11:58:04.794+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:58:04.795+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.795+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T06:27:59.289361+00:00, execution_date=20241214T062759, start_date=, end_date=20241214T062804
[2024-12-14T11:58:04.808+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.807+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T11:58:04.813+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.808+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:27:59.289361+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T11:58:04.817+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.816+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 06:27:59.289361+00:00: manual__2024-12-14T06:27:59.289361+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T11:58:04.817+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T11:58:04.817+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T06:27:59.289361+00:00 external trigger: False
[2024-12-14T11:58:04.817+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T11:58:04.818+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.818+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 06:27:59.289361+00:00, run_id=manual__2024-12-14T06:27:59.289361+00:00, run_start_date=2024-12-14 06:27:59.289361+00:00, run_end_date=2024-12-14 06:28:04.817476+00:00, run_duration=5.528115, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 06:27:59.289361+00:00, data_interval_end=2024-12-14 06:27:59.289361+00:00, dag_hash=None
[2024-12-14T11:58:04.828+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T11:58:04.842+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.842+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T11:58:04.862+0530] {logging_mixin.py:190} INFO - [2024-12-14T11:58:04.862+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T11:58:04.881+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.727 seconds
[2024-12-14T12:01:07.513+0530] {processor.py:186} INFO - Started process (PID=46229) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:01:07.515+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T12:01:07.517+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:07.517+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:01:07.693+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:07.692+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T12:01:07.714+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:07.713+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 06:31:07.656140+00:00: manual__2024-12-14T06:31:07.656140+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:01:07.753+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:07.752+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T12:01:07.753+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:07.753+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T06:31:07.656140+00:00 [scheduled]>
[2024-12-14T12:01:12.787+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:12.787+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T12:01:12.966+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:01:12,966] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:31:07.656140+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:31:07.656140+00:00'
[2024-12-14T12:01:12.968+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:12.966+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:31:07.656140+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:31:07.656140+00:00'
[2024-12-14T12:01:12.980+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:01:12.980+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:01:12.981+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T12:01:12.981+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:01:12.981+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:12.981+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:01:13.067+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:01:13,067] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:01:13.068+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:13.067+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:01:13.069+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:01:13,069] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:01:13.069+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:13.069+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:01:13.080+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:01:13,078] {subprocess.py:99} INFO - Output:
[2024-12-14T12:01:13.081+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:13.078+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:01:13.085+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:01:13,085] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:01:13.086+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:13.085+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:01:13.086+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:01:13,086] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:01:13.087+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:13.086+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:01:13.115+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:13.114+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:01:13.115+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:13.115+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T06:31:07.656140+00:00, execution_date=20241214T063107, start_date=, end_date=20241214T063113
[2024-12-14T12:01:13.127+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T12:01:13.127+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T12:01:13.128+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T12:01:13.128+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T12:01:13.128+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:13.128+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T12:01:13.146+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:13.146+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T12:01:13.146+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:13.146+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:31:07.656140+00:00 [scheduled]>
[2024-12-14T12:01:13.177+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:01:13,177] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:31:07.656140+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:31:07.656140+00:00'
[2024-12-14T12:01:13.178+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:13.177+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:31:07.656140+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:31:07.656140+00:00'
[2024-12-14T12:01:13.178+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:01:13.179+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:01:13.179+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T12:01:13.179+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:01:13.179+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:13.179+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:01:13.180+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:01:13,180] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:01:13.180+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:13.180+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:01:13.181+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:01:13,181] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:01:13.181+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:13.181+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:01:13.195+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:01:13,189] {subprocess.py:99} INFO - Output:
[2024-12-14T12:01:13.196+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:13.189+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:01:13.247+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:01:13,247] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpsmp7v6aj/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:01:13.247+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:13.247+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpsmp7v6aj/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:01:13.252+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:01:13,252] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:01:13.252+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:13.252+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:01:13.267+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:01:13,261] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:01:13.267+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:13.261+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:01:13.269+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T12:01:13.269+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 06:31:13.269010+00:00 duration:None
[2024-12-14T12:01:13.270+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 06:31:07.656140+00:00: manual__2024-12-14T06:31:07.656140+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:01:13.270+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:01:13.270+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:13.270+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T06:31:07.656140+00:00, execution_date=20241214T063107, start_date=, end_date=20241214T063113
[2024-12-14T12:01:13.283+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:13.283+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:01:13.292+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:13.283+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:31:07.656140+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:01:13.296+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:13.296+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 06:31:07.656140+00:00: manual__2024-12-14T06:31:07.656140+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T12:01:13.296+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T12:01:13.297+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T06:31:07.656140+00:00 external trigger: False
[2024-12-14T12:01:13.297+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T12:01:13.297+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:13.297+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 06:31:07.656140+00:00, run_id=manual__2024-12-14T06:31:07.656140+00:00, run_start_date=2024-12-14 06:31:07.656140+00:00, run_end_date=2024-12-14 06:31:13.296864+00:00, run_duration=5.640724, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 06:31:07.656140+00:00, data_interval_end=2024-12-14 06:31:07.656140+00:00, dag_hash=None
[2024-12-14T12:01:13.306+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:01:13.321+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:13.321+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T12:01:13.347+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:01:13.346+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T12:01:13.394+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.886 seconds
[2024-12-14T12:04:29.565+0530] {processor.py:186} INFO - Started process (PID=46461) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:04:29.567+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T12:04:29.570+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:29.569+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:04:29.751+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:29.751+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T12:04:29.768+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:29.767+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 06:34:29.716210+00:00: manual__2024-12-14T06:34:29.716210+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:04:29.812+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:29.812+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T12:04:29.813+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:29.812+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T06:34:29.716210+00:00 [scheduled]>
[2024-12-14T12:04:34.841+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:34.841+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T12:04:34.985+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:04:34,985] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:34:29.716210+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:34:29.716210+00:00'
[2024-12-14T12:04:34.986+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:34.985+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:34:29.716210+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:34:29.716210+00:00'
[2024-12-14T12:04:34.999+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:04:34.999+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:04:34.999+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T12:04:35.000+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:04:35.000+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:35.000+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:04:35.039+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:04:35,039] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:04:35.039+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:35.039+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:04:35.040+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:04:35,040] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:04:35.040+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:35.040+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:04:35.053+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:04:35,051] {subprocess.py:99} INFO - Output:
[2024-12-14T12:04:35.054+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:35.051+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:04:35.054+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:04:35,054] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:04:35.055+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:35.054+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:04:35.055+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:04:35,055] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:04:35.055+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:35.055+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:04:35.077+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:35.077+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:04:35.078+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:35.078+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T06:34:29.716210+00:00, execution_date=20241214T063429, start_date=, end_date=20241214T063435
[2024-12-14T12:04:35.090+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T12:04:35.090+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T12:04:35.091+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T12:04:35.091+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T12:04:35.092+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:35.091+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T12:04:35.112+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:35.111+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T12:04:35.112+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:35.112+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:34:29.716210+00:00 [scheduled]>
[2024-12-14T12:04:35.144+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:04:35,144] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:34:29.716210+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:34:29.716210+00:00'
[2024-12-14T12:04:35.144+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:35.144+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:34:29.716210+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:34:29.716210+00:00'
[2024-12-14T12:04:35.145+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:04:35.145+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:04:35.145+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T12:04:35.146+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:04:35.147+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:35.146+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:04:35.148+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:04:35,148] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:04:35.148+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:35.148+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:04:35.149+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:04:35,148] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:04:35.149+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:35.148+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:04:35.159+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:04:35,157] {subprocess.py:99} INFO - Output:
[2024-12-14T12:04:35.162+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:35.157+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:04:35.211+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:04:35,211] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp5c7e5umc/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:04:35.212+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:35.211+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp5c7e5umc/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:04:35.219+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:04:35,219] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:04:35.219+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:35.219+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:04:35.231+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:04:35,225] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:04:35.232+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:35.225+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:04:35.234+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T12:04:35.235+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 06:34:35.233633+00:00 duration:None
[2024-12-14T12:04:35.236+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 06:34:29.716210+00:00: manual__2024-12-14T06:34:29.716210+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:04:35.236+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:04:35.237+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:35.237+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T06:34:29.716210+00:00, execution_date=20241214T063429, start_date=, end_date=20241214T063435
[2024-12-14T12:04:35.251+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:35.251+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:04:35.256+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:35.251+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:34:29.716210+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:04:35.262+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:35.261+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 06:34:29.716210+00:00: manual__2024-12-14T06:34:29.716210+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T12:04:35.262+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T12:04:35.262+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T06:34:29.716210+00:00 external trigger: False
[2024-12-14T12:04:35.262+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T12:04:35.263+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:35.263+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 06:34:29.716210+00:00, run_id=manual__2024-12-14T06:34:29.716210+00:00, run_start_date=2024-12-14 06:34:29.716210+00:00, run_end_date=2024-12-14 06:34:35.262328+00:00, run_duration=5.546118, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 06:34:29.716210+00:00, data_interval_end=2024-12-14 06:34:29.716210+00:00, dag_hash=None
[2024-12-14T12:04:35.272+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:04:35.285+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:35.284+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T12:04:35.305+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:04:35.305+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T12:04:35.324+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.766 seconds
[2024-12-14T12:07:47.175+0530] {processor.py:186} INFO - Started process (PID=46703) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:07:47.177+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T12:07:47.179+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:47.179+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:07:47.336+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:47.336+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T12:07:47.361+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:47.361+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 06:37:47.304037+00:00: manual__2024-12-14T06:37:47.304037+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:07:47.403+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:47.402+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T12:07:47.404+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:47.403+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T06:37:47.304037+00:00 [scheduled]>
[2024-12-14T12:07:52.438+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.438+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T12:07:52.601+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:07:52,601] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:37:47.304037+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:37:47.304037+00:00'
[2024-12-14T12:07:52.601+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.601+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:37:47.304037+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:37:47.304037+00:00'
[2024-12-14T12:07:52.613+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:07:52.614+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:07:52.614+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T12:07:52.614+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:07:52.615+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.615+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:07:52.655+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:07:52,654] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:07:52.655+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.654+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:07:52.656+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:07:52,656] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:07:52.657+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.656+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:07:52.669+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:07:52,667] {subprocess.py:99} INFO - Output:
[2024-12-14T12:07:52.670+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.667+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:07:52.674+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:07:52,673] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:07:52.675+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.673+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:07:52.675+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:07:52,675] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:07:52.675+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.675+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:07:52.696+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.696+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:07:52.697+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.697+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T06:37:47.304037+00:00, execution_date=20241214T063747, start_date=, end_date=20241214T063752
[2024-12-14T12:07:52.709+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T12:07:52.710+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T12:07:52.710+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T12:07:52.710+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T12:07:52.711+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.711+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T12:07:52.730+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.730+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T12:07:52.731+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.731+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:37:47.304037+00:00 [scheduled]>
[2024-12-14T12:07:52.762+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:07:52,762] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:37:47.304037+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:37:47.304037+00:00'
[2024-12-14T12:07:52.762+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.762+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:37:47.304037+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:37:47.304037+00:00'
[2024-12-14T12:07:52.763+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:07:52.763+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:07:52.763+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T12:07:52.763+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:07:52.763+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.763+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:07:52.764+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:07:52,764] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:07:52.764+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.764+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:07:52.765+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:07:52,765] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:07:52.765+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.765+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:07:52.775+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:07:52,773] {subprocess.py:99} INFO - Output:
[2024-12-14T12:07:52.776+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.773+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:07:52.829+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:07:52,828] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmph3vmvaov/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:07:52.829+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.828+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmph3vmvaov/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:07:52.834+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:07:52,833] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:07:52.834+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.833+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:07:52.847+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:07:52,841] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:07:52.847+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.841+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:07:52.849+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T12:07:52.849+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 06:37:52.848814+00:00 duration:None
[2024-12-14T12:07:52.849+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 06:37:47.304037+00:00: manual__2024-12-14T06:37:47.304037+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:07:52.850+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:07:52.850+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.850+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T06:37:47.304037+00:00, execution_date=20241214T063747, start_date=, end_date=20241214T063752
[2024-12-14T12:07:52.862+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.861+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:07:52.872+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.862+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:37:47.304037+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:07:52.876+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.876+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 06:37:47.304037+00:00: manual__2024-12-14T06:37:47.304037+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T12:07:52.876+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T12:07:52.877+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T06:37:47.304037+00:00 external trigger: False
[2024-12-14T12:07:52.877+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T12:07:52.877+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.877+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 06:37:47.304037+00:00, run_id=manual__2024-12-14T06:37:47.304037+00:00, run_start_date=2024-12-14 06:37:47.304037+00:00, run_end_date=2024-12-14 06:37:52.876753+00:00, run_duration=5.572716, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 06:37:47.304037+00:00, data_interval_end=2024-12-14 06:37:47.304037+00:00, dag_hash=None
[2024-12-14T12:07:52.888+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:07:52.904+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.904+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T12:07:52.922+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:07:52.922+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T12:07:52.943+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.772 seconds
[2024-12-14T12:11:12.254+0530] {processor.py:186} INFO - Started process (PID=46934) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:11:12.256+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T12:11:12.259+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:12.258+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:11:12.440+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:12.439+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T12:11:12.459+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:12.457+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 06:41:12.399492+00:00: manual__2024-12-14T06:41:12.399492+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:11:12.501+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:12.500+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T12:11:12.501+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:12.501+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T06:41:12.399492+00:00 [scheduled]>
[2024-12-14T12:11:17.532+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:17.532+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T12:11:17.705+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:11:17,705] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:41:12.399492+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:41:12.399492+00:00'
[2024-12-14T12:11:17.706+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:17.705+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:41:12.399492+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:41:12.399492+00:00'
[2024-12-14T12:11:17.726+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:11:17.731+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:11:17.732+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T12:11:17.733+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:11:17.733+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:17.733+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:11:17.777+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:11:17,777] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:11:17.778+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:17.777+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:11:17.779+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:11:17,778] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:11:17.779+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:17.778+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:11:17.791+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:11:17,787] {subprocess.py:99} INFO - Output:
[2024-12-14T12:11:17.792+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:17.787+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:11:17.794+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:11:17,793] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:11:17.794+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:17.793+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:11:17.795+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:11:17,794] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:11:17.795+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:17.794+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:11:17.820+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:17.820+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:11:17.821+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:17.821+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T06:41:12.399492+00:00, execution_date=20241214T064112, start_date=, end_date=20241214T064117
[2024-12-14T12:11:17.834+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T12:11:17.835+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T12:11:17.835+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T12:11:17.835+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T12:11:17.836+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:17.835+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T12:11:17.853+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:17.853+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T12:11:17.853+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:17.853+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:41:12.399492+00:00 [scheduled]>
[2024-12-14T12:11:17.889+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:11:17,888] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:41:12.399492+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:41:12.399492+00:00'
[2024-12-14T12:11:17.890+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:17.888+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:41:12.399492+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:41:12.399492+00:00'
[2024-12-14T12:11:17.890+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:11:17.890+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:11:17.891+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T12:11:17.891+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:11:17.891+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:17.891+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:11:17.892+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:11:17,892] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:11:17.892+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:17.892+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:11:17.894+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:11:17,894] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:11:17.895+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:17.894+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:11:17.906+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:11:17,904] {subprocess.py:99} INFO - Output:
[2024-12-14T12:11:17.908+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:17.904+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:11:17.951+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:11:17,951] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpyh03_arv/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:11:17.952+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:17.951+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpyh03_arv/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:11:17.956+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:11:17,956] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:11:17.957+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:17.956+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:11:17.970+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:11:17,964] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:11:17.970+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:17.964+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:11:17.972+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T12:11:17.972+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 06:41:17.971887+00:00 duration:None
[2024-12-14T12:11:17.973+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 06:41:12.399492+00:00: manual__2024-12-14T06:41:12.399492+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:11:17.973+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:11:17.974+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:17.973+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T06:41:12.399492+00:00, execution_date=20241214T064112, start_date=, end_date=20241214T064117
[2024-12-14T12:11:17.985+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:17.985+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:11:17.991+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:17.986+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:41:12.399492+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:11:17.995+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:17.995+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 06:41:12.399492+00:00: manual__2024-12-14T06:41:12.399492+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T12:11:17.995+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T12:11:17.995+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T06:41:12.399492+00:00 external trigger: False
[2024-12-14T12:11:17.996+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T12:11:17.996+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:17.996+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 06:41:12.399492+00:00, run_id=manual__2024-12-14T06:41:12.399492+00:00, run_start_date=2024-12-14 06:41:12.399492+00:00, run_end_date=2024-12-14 06:41:17.995643+00:00, run_duration=5.596151, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 06:41:12.399492+00:00, data_interval_end=2024-12-14 06:41:12.399492+00:00, dag_hash=None
[2024-12-14T12:11:18.005+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:11:18.020+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:18.019+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T12:11:18.044+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:11:18.044+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T12:11:18.067+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.818 seconds
[2024-12-14T12:14:24.774+0530] {processor.py:186} INFO - Started process (PID=47156) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:14:24.776+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T12:14:24.777+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:24.776+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:14:24.931+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:24.931+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T12:14:24.944+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:24.944+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 06:44:24.902383+00:00: manual__2024-12-14T06:44:24.902383+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:14:24.977+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:24.976+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T12:14:24.977+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:24.977+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T06:44:24.902383+00:00 [scheduled]>
[2024-12-14T12:14:30.005+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.004+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T12:14:30.154+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:14:30,154] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:44:24.902383+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:44:24.902383+00:00'
[2024-12-14T12:14:30.155+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.154+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:44:24.902383+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:44:24.902383+00:00'
[2024-12-14T12:14:30.158+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:14:30.158+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:14:30.158+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T12:14:30.159+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:14:30.159+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.159+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:14:30.193+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:14:30,193] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:14:30.193+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.193+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:14:30.194+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:14:30,194] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:14:30.194+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.194+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:14:30.205+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:14:30,203] {subprocess.py:99} INFO - Output:
[2024-12-14T12:14:30.207+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.203+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:14:30.210+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:14:30,210] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:14:30.210+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.210+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:14:30.211+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:14:30,211] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:14:30.211+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.211+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:14:30.232+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.232+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:14:30.232+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.232+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T06:44:24.902383+00:00, execution_date=20241214T064424, start_date=, end_date=20241214T064430
[2024-12-14T12:14:30.243+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T12:14:30.243+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T12:14:30.243+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T12:14:30.243+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T12:14:30.244+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.244+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T12:14:30.261+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.261+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T12:14:30.262+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.262+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:44:24.902383+00:00 [scheduled]>
[2024-12-14T12:14:30.294+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:14:30,294] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:44:24.902383+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:44:24.902383+00:00'
[2024-12-14T12:14:30.295+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.294+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:44:24.902383+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:44:24.902383+00:00'
[2024-12-14T12:14:30.296+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:14:30.296+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:14:30.297+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T12:14:30.297+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:14:30.297+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.297+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:14:30.298+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:14:30,298] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:14:30.298+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.298+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:14:30.299+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:14:30,299] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:14:30.299+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.299+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:14:30.308+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:14:30,307] {subprocess.py:99} INFO - Output:
[2024-12-14T12:14:30.309+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.307+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:14:30.356+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:14:30,356] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp974qoyj8/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:14:30.357+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.356+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp974qoyj8/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:14:30.361+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:14:30,361] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:14:30.362+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.361+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:14:30.372+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:14:30,370] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:14:30.373+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.370+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:14:30.375+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T12:14:30.375+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 06:44:30.374751+00:00 duration:None
[2024-12-14T12:14:30.376+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 06:44:24.902383+00:00: manual__2024-12-14T06:44:24.902383+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:14:30.376+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:14:30.376+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.376+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T06:44:24.902383+00:00, execution_date=20241214T064424, start_date=, end_date=20241214T064430
[2024-12-14T12:14:30.388+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.388+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:14:30.391+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.389+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:44:24.902383+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:14:30.396+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.395+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 06:44:24.902383+00:00: manual__2024-12-14T06:44:24.902383+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T12:14:30.396+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T12:14:30.396+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T06:44:24.902383+00:00 external trigger: False
[2024-12-14T12:14:30.397+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T12:14:30.397+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.397+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 06:44:24.902383+00:00, run_id=manual__2024-12-14T06:44:24.902383+00:00, run_start_date=2024-12-14 06:44:24.902383+00:00, run_end_date=2024-12-14 06:44:30.396354+00:00, run_duration=5.493971, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 06:44:24.902383+00:00, data_interval_end=2024-12-14 06:44:24.902383+00:00, dag_hash=None
[2024-12-14T12:14:30.407+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:14:30.423+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.423+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T12:14:30.443+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:14:30.443+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T12:14:30.464+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.693 seconds
[2024-12-14T12:17:39.069+0530] {processor.py:186} INFO - Started process (PID=47364) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:17:39.072+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T12:17:39.074+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:39.073+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:17:39.239+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:39.239+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T12:17:39.255+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:39.254+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 06:47:39.199661+00:00: manual__2024-12-14T06:47:39.199661+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:17:39.293+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:39.293+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T12:17:39.294+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:39.293+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T06:47:39.199661+00:00 [scheduled]>
[2024-12-14T12:17:44.331+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.331+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T12:17:44.490+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:17:44,490] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:47:39.199661+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:47:39.199661+00:00'
[2024-12-14T12:17:44.491+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.490+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:47:39.199661+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:47:39.199661+00:00'
[2024-12-14T12:17:44.500+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:17:44.500+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:17:44.500+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T12:17:44.501+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:17:44.502+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.501+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:17:44.543+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:17:44,542] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:17:44.543+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.542+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:17:44.544+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:17:44,544] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:17:44.546+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.544+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:17:44.558+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:17:44,556] {subprocess.py:99} INFO - Output:
[2024-12-14T12:17:44.559+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.556+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:17:44.561+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:17:44,561] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:17:44.562+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.561+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:17:44.563+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:17:44,562] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:17:44.563+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.562+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:17:44.585+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.584+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:17:44.585+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.585+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T06:47:39.199661+00:00, execution_date=20241214T064739, start_date=, end_date=20241214T064744
[2024-12-14T12:17:44.597+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T12:17:44.597+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T12:17:44.597+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T12:17:44.598+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T12:17:44.599+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.599+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T12:17:44.617+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.617+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T12:17:44.618+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.617+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:47:39.199661+00:00 [scheduled]>
[2024-12-14T12:17:44.647+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:17:44,647] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:47:39.199661+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:47:39.199661+00:00'
[2024-12-14T12:17:44.647+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.647+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:47:39.199661+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:47:39.199661+00:00'
[2024-12-14T12:17:44.647+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:17:44.648+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:17:44.648+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T12:17:44.648+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:17:44.648+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.648+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:17:44.649+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:17:44,649] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:17:44.650+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.649+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:17:44.650+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:17:44,650] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:17:44.650+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.650+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:17:44.665+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:17:44,660] {subprocess.py:99} INFO - Output:
[2024-12-14T12:17:44.666+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.660+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:17:44.712+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:17:44,711] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp_d3y4p2q/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:17:44.713+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.711+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp_d3y4p2q/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:17:44.717+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:17:44,717] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:17:44.718+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.717+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:17:44.735+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:17:44,724] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:17:44.736+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.724+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:17:44.738+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T12:17:44.738+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 06:47:44.737656+00:00 duration:None
[2024-12-14T12:17:44.738+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 06:47:39.199661+00:00: manual__2024-12-14T06:47:39.199661+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:17:44.738+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:17:44.739+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.739+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T06:47:39.199661+00:00, execution_date=20241214T064739, start_date=, end_date=20241214T064744
[2024-12-14T12:17:44.751+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.751+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:17:44.759+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.752+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:47:39.199661+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:17:44.765+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.764+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 06:47:39.199661+00:00: manual__2024-12-14T06:47:39.199661+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T12:17:44.765+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T12:17:44.765+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T06:47:39.199661+00:00 external trigger: False
[2024-12-14T12:17:44.765+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T12:17:44.766+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.766+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 06:47:39.199661+00:00, run_id=manual__2024-12-14T06:47:39.199661+00:00, run_start_date=2024-12-14 06:47:39.199661+00:00, run_end_date=2024-12-14 06:47:44.765355+00:00, run_duration=5.565694, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 06:47:39.199661+00:00, data_interval_end=2024-12-14 06:47:39.199661+00:00, dag_hash=None
[2024-12-14T12:17:44.775+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:17:44.789+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.789+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T12:17:44.807+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:17:44.807+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T12:17:44.831+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.757 seconds
[2024-12-14T12:20:54.664+0530] {processor.py:186} INFO - Started process (PID=47599) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:20:54.667+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T12:20:54.668+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:20:54.668+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:20:54.891+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:20:54.891+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T12:20:54.907+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:20:54.907+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 06:50:54.859591+00:00: manual__2024-12-14T06:50:54.859591+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:20:54.944+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:20:54.944+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T12:20:54.945+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:20:54.945+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T06:50:54.859591+00:00 [scheduled]>
[2024-12-14T12:20:59.981+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:20:59.981+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T12:21:00.153+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:21:00,153] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:50:54.859591+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:50:54.859591+00:00'
[2024-12-14T12:21:00.154+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.153+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:50:54.859591+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:50:54.859591+00:00'
[2024-12-14T12:21:00.168+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:21:00.168+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:21:00.168+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T12:21:00.169+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:21:00.169+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.169+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:21:00.204+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:21:00,204] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:21:00.204+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.204+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:21:00.205+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:21:00,205] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:21:00.205+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.205+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:21:00.216+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:21:00,214] {subprocess.py:99} INFO - Output:
[2024-12-14T12:21:00.218+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.214+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:21:00.218+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:21:00,218] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:21:00.219+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.218+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:21:00.219+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:21:00,219] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:21:00.220+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.219+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:21:00.257+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.257+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:21:00.259+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.258+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T06:50:54.859591+00:00, execution_date=20241214T065054, start_date=, end_date=20241214T065100
[2024-12-14T12:21:00.269+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T12:21:00.269+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T12:21:00.270+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T12:21:00.270+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T12:21:00.271+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.270+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T12:21:00.289+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.288+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T12:21:00.289+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.289+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:50:54.859591+00:00 [scheduled]>
[2024-12-14T12:21:00.338+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:21:00,338] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:50:54.859591+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:50:54.859591+00:00'
[2024-12-14T12:21:00.343+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.338+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:50:54.859591+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:50:54.859591+00:00'
[2024-12-14T12:21:00.343+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:21:00.355+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:21:00.356+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T12:21:00.361+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:21:00.362+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.362+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:21:00.363+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:21:00,363] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:21:00.363+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.363+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:21:00.365+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:21:00,365] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:21:00.374+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.365+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:21:00.420+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:21:00,415] {subprocess.py:99} INFO - Output:
[2024-12-14T12:21:00.427+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.415+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:21:00.478+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:21:00,477] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpq_e_tlox/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:21:00.478+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.477+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpq_e_tlox/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:21:00.485+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:21:00,485] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:21:00.485+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.485+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:21:00.503+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:21:00,494] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:21:00.503+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.494+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:21:00.506+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T12:21:00.506+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 06:51:00.506054+00:00 duration:None
[2024-12-14T12:21:00.507+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 06:50:54.859591+00:00: manual__2024-12-14T06:50:54.859591+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:21:00.507+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:21:00.507+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.507+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T06:50:54.859591+00:00, execution_date=20241214T065054, start_date=, end_date=20241214T065100
[2024-12-14T12:21:00.522+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.522+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:21:00.530+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.523+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:50:54.859591+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:21:00.535+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.534+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 06:50:54.859591+00:00: manual__2024-12-14T06:50:54.859591+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T12:21:00.535+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T12:21:00.536+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T06:50:54.859591+00:00 external trigger: False
[2024-12-14T12:21:00.536+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T12:21:00.537+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.537+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 06:50:54.859591+00:00, run_id=manual__2024-12-14T06:50:54.859591+00:00, run_start_date=2024-12-14 06:50:54.859591+00:00, run_end_date=2024-12-14 06:51:00.535377+00:00, run_duration=5.675786, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 06:50:54.859591+00:00, data_interval_end=2024-12-14 06:50:54.859591+00:00, dag_hash=None
[2024-12-14T12:21:00.550+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:21:00.570+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.570+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T12:21:00.592+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:21:00.591+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T12:21:00.616+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.955 seconds
[2024-12-14T12:24:12.323+0530] {processor.py:186} INFO - Started process (PID=47827) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:24:12.324+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T12:24:12.325+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:12.325+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:24:12.485+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:12.485+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T12:24:12.503+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:12.502+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 06:54:12.451159+00:00: manual__2024-12-14T06:54:12.451159+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:24:12.540+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:12.539+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T12:24:12.540+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:12.540+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T06:54:12.451159+00:00 [scheduled]>
[2024-12-14T12:24:17.569+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.569+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T12:24:17.709+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:24:17,709] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:54:12.451159+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:54:12.451159+00:00'
[2024-12-14T12:24:17.709+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.709+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:54:12.451159+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:54:12.451159+00:00'
[2024-12-14T12:24:17.714+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:24:17.714+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:24:17.715+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T12:24:17.715+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:24:17.715+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.715+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:24:17.746+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:24:17,746] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:24:17.746+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.746+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:24:17.747+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:24:17,747] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:24:17.748+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.747+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:24:17.756+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:24:17,755] {subprocess.py:99} INFO - Output:
[2024-12-14T12:24:17.758+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.755+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:24:17.758+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:24:17,758] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:24:17.759+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.758+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:24:17.759+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:24:17,759] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:24:17.759+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.759+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:24:17.783+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.783+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:24:17.784+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.784+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T06:54:12.451159+00:00, execution_date=20241214T065412, start_date=, end_date=20241214T065417
[2024-12-14T12:24:17.794+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T12:24:17.795+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T12:24:17.795+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T12:24:17.795+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T12:24:17.795+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.795+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T12:24:17.812+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.812+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T12:24:17.813+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.813+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:54:12.451159+00:00 [scheduled]>
[2024-12-14T12:24:17.842+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:24:17,842] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:54:12.451159+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:54:12.451159+00:00'
[2024-12-14T12:24:17.843+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.842+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:54:12.451159+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:54:12.451159+00:00'
[2024-12-14T12:24:17.844+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:24:17.845+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:24:17.846+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T12:24:17.846+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:24:17.847+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.846+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:24:17.849+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:24:17,848] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:24:17.849+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.848+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:24:17.850+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:24:17,850] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:24:17.850+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.850+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:24:17.860+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:24:17,858] {subprocess.py:99} INFO - Output:
[2024-12-14T12:24:17.862+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.858+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:24:17.905+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:24:17,905] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp7cpsk2lr/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:24:17.906+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.905+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp7cpsk2lr/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:24:17.910+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:24:17,910] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:24:17.911+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.910+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:24:17.920+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:24:17,918] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:24:17.921+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.918+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:24:17.923+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T12:24:17.924+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 06:54:17.923074+00:00 duration:None
[2024-12-14T12:24:17.924+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 06:54:12.451159+00:00: manual__2024-12-14T06:54:12.451159+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:24:17.925+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:24:17.925+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.925+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T06:54:12.451159+00:00, execution_date=20241214T065412, start_date=, end_date=20241214T065417
[2024-12-14T12:24:17.938+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.938+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:24:17.941+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.938+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:54:12.451159+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:24:17.945+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.945+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 06:54:12.451159+00:00: manual__2024-12-14T06:54:12.451159+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T12:24:17.946+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T12:24:17.946+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T06:54:12.451159+00:00 external trigger: False
[2024-12-14T12:24:17.947+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T12:24:17.947+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.947+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 06:54:12.451159+00:00, run_id=manual__2024-12-14T06:54:12.451159+00:00, run_start_date=2024-12-14 06:54:12.451159+00:00, run_end_date=2024-12-14 06:54:17.946353+00:00, run_duration=5.495194, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 06:54:12.451159+00:00, data_interval_end=2024-12-14 06:54:12.451159+00:00, dag_hash=None
[2024-12-14T12:24:17.958+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:24:17.972+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.972+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T12:24:17.992+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:24:17.992+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T12:24:18.018+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.699 seconds
[2024-12-14T12:27:26.851+0530] {processor.py:186} INFO - Started process (PID=48041) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:27:26.852+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T12:27:26.855+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:26.855+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:27:27.013+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:27.013+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T12:27:27.029+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:27.029+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 06:57:26.982616+00:00: manual__2024-12-14T06:57:26.982616+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:27:27.060+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:27.059+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T12:27:27.060+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:27.060+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T06:57:26.982616+00:00 [scheduled]>
[2024-12-14T12:27:32.175+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.174+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T12:27:32.413+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:27:32,412] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:57:26.982616+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:57:26.982616+00:00'
[2024-12-14T12:27:32.413+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.412+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:57:26.982616+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:57:26.982616+00:00'
[2024-12-14T12:27:32.416+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:27:32.416+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:27:32.417+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T12:27:32.417+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:27:32.417+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.417+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:27:32.447+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:27:32,447] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:27:32.448+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.447+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:27:32.448+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:27:32,448] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:27:32.449+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.448+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:27:32.458+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:27:32,456] {subprocess.py:99} INFO - Output:
[2024-12-14T12:27:32.459+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.456+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:27:32.459+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:27:32,459] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:27:32.460+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.459+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:27:32.460+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:27:32,460] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:27:32.460+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.460+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:27:32.514+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.514+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:27:32.515+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.515+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T06:57:26.982616+00:00, execution_date=20241214T065726, start_date=, end_date=20241214T065732
[2024-12-14T12:27:32.527+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T12:27:32.528+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T12:27:32.528+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T12:27:32.528+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T12:27:32.529+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.528+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T12:27:32.547+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.546+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T12:27:32.547+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.547+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:57:26.982616+00:00 [scheduled]>
[2024-12-14T12:27:32.580+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:27:32,580] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:57:26.982616+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:57:26.982616+00:00'
[2024-12-14T12:27:32.581+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.580+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T06:57:26.982616+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T06:57:26.982616+00:00'
[2024-12-14T12:27:32.581+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:27:32.581+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:27:32.581+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T12:27:32.581+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:27:32.582+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.582+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:27:32.582+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:27:32,582] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:27:32.583+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.582+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:27:32.583+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:27:32,583] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:27:32.584+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.583+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:27:32.594+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:27:32,593] {subprocess.py:99} INFO - Output:
[2024-12-14T12:27:32.597+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.593+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:27:32.644+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:27:32,644] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpj5d8omrk/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:27:32.645+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.644+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpj5d8omrk/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:27:32.650+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:27:32,650] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:27:32.651+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.650+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:27:32.661+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:27:32,659] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:27:32.662+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.659+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:27:32.664+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T12:27:32.665+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 06:57:32.664117+00:00 duration:None
[2024-12-14T12:27:32.665+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 06:57:26.982616+00:00: manual__2024-12-14T06:57:26.982616+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:27:32.665+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:27:32.666+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.665+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T06:57:26.982616+00:00, execution_date=20241214T065726, start_date=, end_date=20241214T065732
[2024-12-14T12:27:32.678+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.677+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:27:32.681+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.678+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T06:57:26.982616+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:27:32.685+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.685+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 06:57:26.982616+00:00: manual__2024-12-14T06:57:26.982616+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T12:27:32.685+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T12:27:32.686+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T06:57:26.982616+00:00 external trigger: False
[2024-12-14T12:27:32.686+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T12:27:32.687+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.687+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 06:57:26.982616+00:00, run_id=manual__2024-12-14T06:57:26.982616+00:00, run_start_date=2024-12-14 06:57:26.982616+00:00, run_end_date=2024-12-14 06:57:32.685778+00:00, run_duration=5.703162, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 06:57:26.982616+00:00, data_interval_end=2024-12-14 06:57:26.982616+00:00, dag_hash=None
[2024-12-14T12:27:32.697+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:27:32.712+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.711+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T12:27:32.738+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:27:32.738+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T12:27:32.758+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.911 seconds
[2024-12-14T12:30:29.364+0530] {processor.py:186} INFO - Started process (PID=48262) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:30:29.365+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T12:30:29.366+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:29.366+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:30:29.512+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:29.512+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T12:30:29.526+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:29.526+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 07:00:29.483498+00:00: manual__2024-12-14T07:00:29.483498+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:30:29.555+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:29.554+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T12:30:29.555+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:29.555+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T07:00:29.483498+00:00 [scheduled]>
[2024-12-14T12:30:34.582+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.582+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T12:30:34.714+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:30:34,714] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:00:29.483498+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:00:29.483498+00:00'
[2024-12-14T12:30:34.715+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.714+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:00:29.483498+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:00:29.483498+00:00'
[2024-12-14T12:30:34.717+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:30:34.718+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:30:34.718+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T12:30:34.718+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:30:34.719+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.718+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:30:34.748+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:30:34,748] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:30:34.749+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.748+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:30:34.749+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:30:34,749] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:30:34.750+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.749+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:30:34.759+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:30:34,757] {subprocess.py:99} INFO - Output:
[2024-12-14T12:30:34.760+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.757+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:30:34.761+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:30:34,761] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:30:34.761+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.761+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:30:34.762+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:30:34,762] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:30:34.762+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.762+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:30:34.782+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.782+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:30:34.783+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.783+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T07:00:29.483498+00:00, execution_date=20241214T070029, start_date=, end_date=20241214T070034
[2024-12-14T12:30:34.794+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T12:30:34.794+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T12:30:34.794+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T12:30:34.795+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T12:30:34.795+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.795+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T12:30:34.812+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.812+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T12:30:34.813+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.812+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:00:29.483498+00:00 [scheduled]>
[2024-12-14T12:30:34.841+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:30:34,841] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:00:29.483498+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:00:29.483498+00:00'
[2024-12-14T12:30:34.841+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.841+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:00:29.483498+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:00:29.483498+00:00'
[2024-12-14T12:30:34.842+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:30:34.842+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:30:34.843+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T12:30:34.843+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:30:34.843+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.843+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:30:34.844+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:30:34,844] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:30:34.844+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.844+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:30:34.845+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:30:34,845] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:30:34.845+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.845+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:30:34.855+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:30:34,854] {subprocess.py:99} INFO - Output:
[2024-12-14T12:30:34.857+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.854+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:30:34.896+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:30:34,896] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmphv2qfypo/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:30:34.897+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.896+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmphv2qfypo/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:30:34.902+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:30:34,901] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:30:34.902+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.901+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:30:34.912+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:30:34,910] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:30:34.912+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.910+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:30:34.915+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T12:30:34.915+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 07:00:34.914283+00:00 duration:None
[2024-12-14T12:30:34.915+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 07:00:29.483498+00:00: manual__2024-12-14T07:00:29.483498+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:30:34.915+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:30:34.916+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.916+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T07:00:29.483498+00:00, execution_date=20241214T070029, start_date=, end_date=20241214T070034
[2024-12-14T12:30:34.927+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.927+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:30:34.930+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.928+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:00:29.483498+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:30:34.935+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.934+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 07:00:29.483498+00:00: manual__2024-12-14T07:00:29.483498+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T12:30:34.935+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T12:30:34.935+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T07:00:29.483498+00:00 external trigger: False
[2024-12-14T12:30:34.935+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T12:30:34.936+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.935+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 07:00:29.483498+00:00, run_id=manual__2024-12-14T07:00:29.483498+00:00, run_start_date=2024-12-14 07:00:29.483498+00:00, run_end_date=2024-12-14 07:00:34.935237+00:00, run_duration=5.451739, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 07:00:29.483498+00:00, data_interval_end=2024-12-14 07:00:29.483498+00:00, dag_hash=None
[2024-12-14T12:30:34.945+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:30:34.957+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.957+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T12:30:34.974+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:30:34.974+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T12:30:34.994+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.634 seconds
[2024-12-14T12:33:22.391+0530] {processor.py:186} INFO - Started process (PID=48458) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:33:22.392+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T12:33:22.393+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:22.393+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:33:22.553+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:22.553+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T12:33:22.566+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:22.566+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 07:03:22.508830+00:00: manual__2024-12-14T07:03:22.508830+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:33:22.594+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:22.594+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T12:33:22.595+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:22.595+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T07:03:22.508830+00:00 [scheduled]>
[2024-12-14T12:33:27.620+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:27.620+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T12:33:27.768+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:33:27,768] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:03:22.508830+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:03:22.508830+00:00'
[2024-12-14T12:33:27.769+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:27.768+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:03:22.508830+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:03:22.508830+00:00'
[2024-12-14T12:33:27.772+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:33:27.773+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:33:27.773+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T12:33:27.773+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:33:27.773+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:27.773+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:33:27.808+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:33:27,808] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:33:27.808+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:27.808+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:33:27.809+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:33:27,809] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:33:27.809+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:27.809+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:33:27.817+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:33:27,816] {subprocess.py:99} INFO - Output:
[2024-12-14T12:33:27.819+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:27.816+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:33:27.820+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:33:27,820] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:33:27.821+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:27.820+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:33:27.821+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:33:27,821] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:33:27.822+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:27.821+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:33:27.841+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:27.841+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:33:27.842+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:27.842+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T07:03:22.508830+00:00, execution_date=20241214T070322, start_date=, end_date=20241214T070327
[2024-12-14T12:33:27.857+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T12:33:27.857+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T12:33:27.858+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T12:33:27.858+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T12:33:27.858+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:27.858+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T12:33:27.876+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:27.875+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T12:33:27.876+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:27.876+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:03:22.508830+00:00 [scheduled]>
[2024-12-14T12:33:27.906+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:33:27,906] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:03:22.508830+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:03:22.508830+00:00'
[2024-12-14T12:33:27.906+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:27.906+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:03:22.508830+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:03:22.508830+00:00'
[2024-12-14T12:33:27.907+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:33:27.907+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:33:27.907+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T12:33:27.907+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:33:27.908+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:27.908+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:33:27.908+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:33:27,908] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:33:27.909+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:27.908+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:33:27.909+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:33:27,909] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:33:27.910+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:27.909+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:33:27.919+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:33:27,917] {subprocess.py:99} INFO - Output:
[2024-12-14T12:33:27.925+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:27.917+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:33:27.986+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:33:27,985] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp8uew50u4/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:33:27.986+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:27.985+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp8uew50u4/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:33:27.993+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:33:27,993] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:33:27.993+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:27.993+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:33:28.006+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:33:28,003] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:33:28.006+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:28.003+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:33:28.009+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T12:33:28.009+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 07:03:28.008786+00:00 duration:None
[2024-12-14T12:33:28.010+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 07:03:22.508830+00:00: manual__2024-12-14T07:03:22.508830+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:33:28.010+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:33:28.011+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:28.010+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T07:03:22.508830+00:00, execution_date=20241214T070322, start_date=, end_date=20241214T070328
[2024-12-14T12:33:28.025+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:28.025+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:33:28.029+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:28.025+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:03:22.508830+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:33:28.034+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:28.034+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 07:03:22.508830+00:00: manual__2024-12-14T07:03:22.508830+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T12:33:28.035+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T12:33:28.035+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T07:03:22.508830+00:00 external trigger: False
[2024-12-14T12:33:28.036+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T12:33:28.036+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:28.036+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 07:03:22.508830+00:00, run_id=manual__2024-12-14T07:03:22.508830+00:00, run_start_date=2024-12-14 07:03:22.508830+00:00, run_end_date=2024-12-14 07:03:28.035235+00:00, run_duration=5.526405, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 07:03:22.508830+00:00, data_interval_end=2024-12-14 07:03:22.508830+00:00, dag_hash=None
[2024-12-14T12:33:28.051+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:33:28.071+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:28.071+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T12:33:28.096+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:33:28.096+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T12:33:28.122+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.736 seconds
[2024-12-14T12:36:15.435+0530] {processor.py:186} INFO - Started process (PID=48664) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:36:15.436+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T12:36:15.438+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:15.437+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:36:15.595+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:15.595+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T12:36:15.609+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:15.609+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 07:06:15.565317+00:00: manual__2024-12-14T07:06:15.565317+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:36:15.637+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:15.637+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T12:36:15.637+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:15.637+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T07:06:15.565317+00:00 [scheduled]>
[2024-12-14T12:36:20.663+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:20.663+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T12:36:20.794+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:36:20,794] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:06:15.565317+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:06:15.565317+00:00'
[2024-12-14T12:36:20.794+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:20.794+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:06:15.565317+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:06:15.565317+00:00'
[2024-12-14T12:36:20.797+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:36:20.797+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:36:20.798+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T12:36:20.798+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:36:20.799+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:20.798+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:36:20.829+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:36:20,829] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:36:20.830+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:20.829+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:36:20.831+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:36:20,830] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:36:20.831+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:20.830+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:36:20.840+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:36:20,838] {subprocess.py:99} INFO - Output:
[2024-12-14T12:36:20.842+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:20.838+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:36:20.843+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:36:20,842] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:36:20.843+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:20.842+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:36:20.843+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:36:20,843] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:36:20.844+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:20.843+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:36:20.863+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:20.863+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:36:20.864+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:20.864+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T07:06:15.565317+00:00, execution_date=20241214T070615, start_date=, end_date=20241214T070620
[2024-12-14T12:36:20.873+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T12:36:20.874+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T12:36:20.874+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T12:36:20.874+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T12:36:20.875+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:20.875+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T12:36:20.891+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:20.891+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T12:36:20.892+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:20.892+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:06:15.565317+00:00 [scheduled]>
[2024-12-14T12:36:20.919+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:36:20,919] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:06:15.565317+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:06:15.565317+00:00'
[2024-12-14T12:36:20.920+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:20.919+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:06:15.565317+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:06:15.565317+00:00'
[2024-12-14T12:36:20.920+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:36:20.921+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:36:20.921+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T12:36:20.921+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:36:20.921+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:20.921+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:36:20.922+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:36:20,922] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:36:20.923+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:20.922+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:36:20.923+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:36:20,923] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:36:20.923+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:20.923+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:36:20.933+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:36:20,930] {subprocess.py:99} INFO - Output:
[2024-12-14T12:36:20.934+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:20.930+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:36:20.976+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:36:20,976] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpc5glim1f/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:36:20.977+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:20.976+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpc5glim1f/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:36:20.982+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:36:20,981] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:36:20.982+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:20.981+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:36:20.992+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:36:20,989] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:36:20.992+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:20.989+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:36:20.994+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T12:36:20.994+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 07:06:20.993924+00:00 duration:None
[2024-12-14T12:36:20.995+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 07:06:15.565317+00:00: manual__2024-12-14T07:06:15.565317+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:36:20.995+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:36:20.996+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:20.995+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T07:06:15.565317+00:00, execution_date=20241214T070615, start_date=, end_date=20241214T070620
[2024-12-14T12:36:21.007+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:21.007+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:36:21.010+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:21.007+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:06:15.565317+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:36:21.014+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:21.014+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 07:06:15.565317+00:00: manual__2024-12-14T07:06:15.565317+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T12:36:21.014+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T12:36:21.015+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T07:06:15.565317+00:00 external trigger: False
[2024-12-14T12:36:21.015+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T12:36:21.015+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:21.015+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 07:06:15.565317+00:00, run_id=manual__2024-12-14T07:06:15.565317+00:00, run_start_date=2024-12-14 07:06:15.565317+00:00, run_end_date=2024-12-14 07:06:21.014876+00:00, run_duration=5.449559, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 07:06:15.565317+00:00, data_interval_end=2024-12-14 07:06:15.565317+00:00, dag_hash=None
[2024-12-14T12:36:21.025+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:36:21.037+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:21.037+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T12:36:21.056+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:36:21.056+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T12:36:21.076+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.644 seconds
[2024-12-14T12:39:06.584+0530] {processor.py:186} INFO - Started process (PID=48860) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:39:06.585+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T12:39:06.586+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:06.586+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:39:06.731+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:06.731+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T12:39:06.746+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:06.745+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 07:09:06.703431+00:00: manual__2024-12-14T07:09:06.703431+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:39:06.774+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:06.774+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T12:39:06.774+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:06.774+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T07:09:06.703431+00:00 [scheduled]>
[2024-12-14T12:39:11.801+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:11.801+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T12:39:11.952+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:39:11,952] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:09:06.703431+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:09:06.703431+00:00'
[2024-12-14T12:39:11.953+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:11.952+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:09:06.703431+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:09:06.703431+00:00'
[2024-12-14T12:39:11.956+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:39:11.957+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:39:11.957+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T12:39:11.957+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:39:11.958+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:11.958+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:39:11.989+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:39:11,989] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:39:11.990+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:11.989+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:39:11.991+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:39:11,990] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:39:11.991+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:11.990+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:39:12.000+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:39:11,999] {subprocess.py:99} INFO - Output:
[2024-12-14T12:39:12.002+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:11.999+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:39:12.002+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:39:12,002] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:39:12.003+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:12.002+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:39:12.003+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:39:12,003] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:39:12.003+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:12.003+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:39:12.024+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:12.023+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:39:12.024+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:12.024+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T07:09:06.703431+00:00, execution_date=20241214T070906, start_date=, end_date=20241214T070912
[2024-12-14T12:39:12.034+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T12:39:12.035+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T12:39:12.035+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T12:39:12.035+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T12:39:12.036+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:12.036+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T12:39:12.053+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:12.053+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T12:39:12.053+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:12.053+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:09:06.703431+00:00 [scheduled]>
[2024-12-14T12:39:12.087+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:39:12,087] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:09:06.703431+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:09:06.703431+00:00'
[2024-12-14T12:39:12.087+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:12.087+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:09:06.703431+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:09:06.703431+00:00'
[2024-12-14T12:39:12.088+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:39:12.088+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:39:12.088+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T12:39:12.088+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:39:12.089+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:12.088+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:39:12.090+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:39:12,090] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:39:12.091+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:12.090+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:39:12.092+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:39:12,092] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:39:12.093+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:12.092+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:39:12.102+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:39:12,100] {subprocess.py:99} INFO - Output:
[2024-12-14T12:39:12.103+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:12.100+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:39:12.148+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:39:12,148] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp8gljgn_2/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:39:12.149+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:12.148+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp8gljgn_2/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:39:12.153+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:39:12,153] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:39:12.154+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:12.153+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:39:12.163+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:39:12,161] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:39:12.164+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:12.161+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:39:12.166+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T12:39:12.167+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 07:09:12.166242+00:00 duration:None
[2024-12-14T12:39:12.167+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 07:09:06.703431+00:00: manual__2024-12-14T07:09:06.703431+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:39:12.167+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:39:12.168+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:12.167+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T07:09:06.703431+00:00, execution_date=20241214T070906, start_date=, end_date=20241214T070912
[2024-12-14T12:39:12.180+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:12.179+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:39:12.183+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:12.180+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:09:06.703431+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:39:12.187+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:12.187+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 07:09:06.703431+00:00: manual__2024-12-14T07:09:06.703431+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T12:39:12.187+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T12:39:12.188+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T07:09:06.703431+00:00 external trigger: False
[2024-12-14T12:39:12.188+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T12:39:12.189+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:12.188+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 07:09:06.703431+00:00, run_id=manual__2024-12-14T07:09:06.703431+00:00, run_start_date=2024-12-14 07:09:06.703431+00:00, run_end_date=2024-12-14 07:09:12.187900+00:00, run_duration=5.484469, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 07:09:06.703431+00:00, data_interval_end=2024-12-14 07:09:06.703431+00:00, dag_hash=None
[2024-12-14T12:39:12.199+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:39:12.212+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:12.212+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T12:39:12.235+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:39:12.234+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T12:39:12.257+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.677 seconds
[2024-12-14T12:41:58.767+0530] {processor.py:186} INFO - Started process (PID=49066) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:41:58.769+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T12:41:58.770+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:41:58.769+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:41:58.920+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:41:58.919+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T12:41:58.935+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:41:58.934+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 07:11:58.890536+00:00: manual__2024-12-14T07:11:58.890536+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:41:58.964+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:41:58.964+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T12:41:58.965+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:41:58.964+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T07:11:58.890536+00:00 [scheduled]>
[2024-12-14T12:42:03.991+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:03.990+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T12:42:04.129+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:42:04,129] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:11:58.890536+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:11:58.890536+00:00'
[2024-12-14T12:42:04.130+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.129+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:11:58.890536+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:11:58.890536+00:00'
[2024-12-14T12:42:04.132+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:42:04.132+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:42:04.133+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T12:42:04.133+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:42:04.133+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.133+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:42:04.164+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:42:04,164] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:42:04.165+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.164+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:42:04.165+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:42:04,165] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:42:04.166+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.165+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:42:04.174+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:42:04,173] {subprocess.py:99} INFO - Output:
[2024-12-14T12:42:04.176+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.173+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:42:04.177+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:42:04,177] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:42:04.177+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.177+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:42:04.178+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:42:04,178] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:42:04.178+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.178+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:42:04.199+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.198+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:42:04.199+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.199+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T07:11:58.890536+00:00, execution_date=20241214T071158, start_date=, end_date=20241214T071204
[2024-12-14T12:42:04.210+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T12:42:04.210+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T12:42:04.210+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T12:42:04.210+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T12:42:04.211+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.211+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T12:42:04.228+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.228+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T12:42:04.228+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.228+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:11:58.890536+00:00 [scheduled]>
[2024-12-14T12:42:04.256+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:42:04,256] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:11:58.890536+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:11:58.890536+00:00'
[2024-12-14T12:42:04.256+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.256+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:11:58.890536+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:11:58.890536+00:00'
[2024-12-14T12:42:04.257+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:42:04.257+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:42:04.257+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T12:42:04.257+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:42:04.258+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.258+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:42:04.259+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:42:04,259] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:42:04.259+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.259+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:42:04.260+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:42:04,260] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:42:04.260+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.260+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:42:04.269+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:42:04,267] {subprocess.py:99} INFO - Output:
[2024-12-14T12:42:04.270+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.267+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:42:04.312+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:42:04,311] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp_2jyom9j/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:42:04.312+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.311+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp_2jyom9j/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:42:04.317+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:42:04,317] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:42:04.318+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.317+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:42:04.327+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:42:04,325] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:42:04.328+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.325+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:42:04.330+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T12:42:04.330+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 07:12:04.329444+00:00 duration:None
[2024-12-14T12:42:04.330+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 07:11:58.890536+00:00: manual__2024-12-14T07:11:58.890536+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:42:04.331+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:42:04.331+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.331+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T07:11:58.890536+00:00, execution_date=20241214T071158, start_date=, end_date=20241214T071204
[2024-12-14T12:42:04.342+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.342+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:42:04.345+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.343+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:11:58.890536+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:42:04.350+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.350+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 07:11:58.890536+00:00: manual__2024-12-14T07:11:58.890536+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T12:42:04.350+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T12:42:04.350+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T07:11:58.890536+00:00 external trigger: False
[2024-12-14T12:42:04.351+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T12:42:04.351+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.351+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 07:11:58.890536+00:00, run_id=manual__2024-12-14T07:11:58.890536+00:00, run_start_date=2024-12-14 07:11:58.890536+00:00, run_end_date=2024-12-14 07:12:04.350656+00:00, run_duration=5.46012, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 07:11:58.890536+00:00, data_interval_end=2024-12-14 07:11:58.890536+00:00, dag_hash=None
[2024-12-14T12:42:04.361+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:42:04.373+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.373+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T12:42:04.392+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:42:04.391+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T12:42:04.414+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.650 seconds
[2024-12-14T12:44:49.722+0530] {processor.py:186} INFO - Started process (PID=49260) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:44:49.724+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T12:44:49.725+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:49.725+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:44:49.873+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:49.872+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T12:44:49.887+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:49.887+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 07:14:49.842156+00:00: manual__2024-12-14T07:14:49.842156+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:44:49.916+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:49.916+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T12:44:49.917+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:49.916+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T07:14:49.842156+00:00 [scheduled]>
[2024-12-14T12:44:54.944+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:54.944+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T12:44:55.082+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:44:55,082] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:14:49.842156+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:14:49.842156+00:00'
[2024-12-14T12:44:55.082+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.082+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:14:49.842156+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:14:49.842156+00:00'
[2024-12-14T12:44:55.085+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:44:55.085+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:44:55.086+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T12:44:55.086+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:44:55.086+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.086+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:44:55.116+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:44:55,116] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:44:55.117+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.116+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:44:55.117+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:44:55,117] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:44:55.118+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.117+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:44:55.127+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:44:55,125] {subprocess.py:99} INFO - Output:
[2024-12-14T12:44:55.129+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.125+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:44:55.129+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:44:55,129] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:44:55.129+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.129+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:44:55.130+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:44:55,130] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:44:55.130+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.130+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:44:55.150+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.150+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:44:55.151+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.151+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T07:14:49.842156+00:00, execution_date=20241214T071449, start_date=, end_date=20241214T071455
[2024-12-14T12:44:55.162+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T12:44:55.162+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T12:44:55.162+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T12:44:55.162+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T12:44:55.163+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.163+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T12:44:55.180+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.180+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T12:44:55.180+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.180+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:14:49.842156+00:00 [scheduled]>
[2024-12-14T12:44:55.209+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:44:55,208] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:14:49.842156+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:14:49.842156+00:00'
[2024-12-14T12:44:55.209+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.208+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:14:49.842156+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:14:49.842156+00:00'
[2024-12-14T12:44:55.210+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:44:55.210+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:44:55.210+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T12:44:55.210+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:44:55.211+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.211+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:44:55.211+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:44:55,211] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:44:55.212+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.211+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:44:55.213+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:44:55,213] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:44:55.213+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.213+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:44:55.222+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:44:55,221] {subprocess.py:99} INFO - Output:
[2024-12-14T12:44:55.224+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.221+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:44:55.264+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:44:55,264] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpk_o1pz_p/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:44:55.265+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.264+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpk_o1pz_p/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:44:55.269+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:44:55,269] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:44:55.270+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.269+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:44:55.278+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:44:55,276] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:44:55.279+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.276+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:44:55.281+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T12:44:55.281+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 07:14:55.280854+00:00 duration:None
[2024-12-14T12:44:55.281+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 07:14:49.842156+00:00: manual__2024-12-14T07:14:49.842156+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:44:55.282+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:44:55.282+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.282+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T07:14:49.842156+00:00, execution_date=20241214T071449, start_date=, end_date=20241214T071455
[2024-12-14T12:44:55.293+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.293+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:44:55.296+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.293+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:14:49.842156+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:44:55.301+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.301+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 07:14:49.842156+00:00: manual__2024-12-14T07:14:49.842156+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T12:44:55.301+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T12:44:55.301+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T07:14:49.842156+00:00 external trigger: False
[2024-12-14T12:44:55.302+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T12:44:55.302+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.302+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 07:14:49.842156+00:00, run_id=manual__2024-12-14T07:14:49.842156+00:00, run_start_date=2024-12-14 07:14:49.842156+00:00, run_end_date=2024-12-14 07:14:55.301682+00:00, run_duration=5.459526, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 07:14:49.842156+00:00, data_interval_end=2024-12-14 07:14:49.842156+00:00, dag_hash=None
[2024-12-14T12:44:55.311+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:44:55.324+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.324+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T12:44:55.343+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:44:55.343+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T12:44:55.365+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.647 seconds
[2024-12-14T12:47:44.676+0530] {processor.py:186} INFO - Started process (PID=49459) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:47:44.679+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T12:47:44.680+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:44.680+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:47:44.825+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:44.824+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T12:47:44.839+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:44.838+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 07:17:44.794985+00:00: manual__2024-12-14T07:17:44.794985+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:47:44.871+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:44.871+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T12:47:44.872+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:44.871+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T07:17:44.794985+00:00 [scheduled]>
[2024-12-14T12:47:49.903+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:49.903+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T12:47:50.050+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:47:50,049] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:17:44.794985+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:17:44.794985+00:00'
[2024-12-14T12:47:50.050+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.049+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:17:44.794985+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:17:44.794985+00:00'
[2024-12-14T12:47:50.063+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:47:50.063+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:47:50.064+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T12:47:50.064+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:47:50.065+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.065+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:47:50.106+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:47:50,106] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:47:50.106+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.106+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:47:50.107+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:47:50,107] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:47:50.107+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.107+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:47:50.120+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:47:50,118] {subprocess.py:99} INFO - Output:
[2024-12-14T12:47:50.123+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.118+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:47:50.127+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:47:50,127] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:47:50.127+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.127+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:47:50.128+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:47:50,128] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:47:50.128+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.128+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:47:50.148+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.147+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:47:50.148+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.148+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T07:17:44.794985+00:00, execution_date=20241214T071744, start_date=, end_date=20241214T071750
[2024-12-14T12:47:50.158+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T12:47:50.159+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T12:47:50.159+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T12:47:50.159+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T12:47:50.160+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.159+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T12:47:50.176+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.176+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T12:47:50.176+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.176+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:17:44.794985+00:00 [scheduled]>
[2024-12-14T12:47:50.205+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:47:50,205] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:17:44.794985+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:17:44.794985+00:00'
[2024-12-14T12:47:50.206+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.205+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:17:44.794985+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:17:44.794985+00:00'
[2024-12-14T12:47:50.206+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:47:50.206+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:47:50.207+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T12:47:50.207+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:47:50.207+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.207+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:47:50.208+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:47:50,208] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:47:50.208+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.208+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:47:50.209+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:47:50,208] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:47:50.209+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.208+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:47:50.219+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:47:50,218] {subprocess.py:99} INFO - Output:
[2024-12-14T12:47:50.221+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.218+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:47:50.288+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:47:50,288] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpo6_47zih/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:47:50.289+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.288+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpo6_47zih/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:47:50.297+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:47:50,296] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:47:50.298+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.296+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:47:50.312+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:47:50,305] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:47:50.312+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.305+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:47:50.315+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T12:47:50.315+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 07:17:50.314772+00:00 duration:None
[2024-12-14T12:47:50.316+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 07:17:44.794985+00:00: manual__2024-12-14T07:17:44.794985+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:47:50.316+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:47:50.316+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.316+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T07:17:44.794985+00:00, execution_date=20241214T071744, start_date=, end_date=20241214T071750
[2024-12-14T12:47:50.328+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.328+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:47:50.337+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.329+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:17:44.794985+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:47:50.342+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.342+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 07:17:44.794985+00:00: manual__2024-12-14T07:17:44.794985+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T12:47:50.343+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T12:47:50.343+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T07:17:44.794985+00:00 external trigger: False
[2024-12-14T12:47:50.343+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T12:47:50.343+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.343+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 07:17:44.794985+00:00, run_id=manual__2024-12-14T07:17:44.794985+00:00, run_start_date=2024-12-14 07:17:44.794985+00:00, run_end_date=2024-12-14 07:17:50.343034+00:00, run_duration=5.548049, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 07:17:44.794985+00:00, data_interval_end=2024-12-14 07:17:44.794985+00:00, dag_hash=None
[2024-12-14T12:47:50.355+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:47:50.369+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.369+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T12:47:50.391+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:47:50.390+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T12:47:50.413+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.741 seconds
[2024-12-14T12:50:37.796+0530] {processor.py:186} INFO - Started process (PID=49677) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:50:37.798+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T12:50:37.800+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:37.799+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:50:37.947+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:37.947+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T12:50:37.962+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:37.961+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 07:20:37.918158+00:00: manual__2024-12-14T07:20:37.918158+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:50:37.995+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:37.995+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T12:50:37.996+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:37.995+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T07:20:37.918158+00:00 [scheduled]>
[2024-12-14T12:50:43.028+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.028+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T12:50:43.182+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:50:43,182] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:20:37.918158+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:20:37.918158+00:00'
[2024-12-14T12:50:43.183+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.182+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:20:37.918158+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:20:37.918158+00:00'
[2024-12-14T12:50:43.195+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:50:43.195+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:50:43.195+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T12:50:43.196+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:50:43.196+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.196+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:50:43.227+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:50:43,227] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:50:43.228+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.227+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:50:43.228+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:50:43,228] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:50:43.229+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.228+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:50:43.238+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:50:43,236] {subprocess.py:99} INFO - Output:
[2024-12-14T12:50:43.239+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.236+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:50:43.240+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:50:43,240] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:50:43.241+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.240+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:50:43.241+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:50:43,241] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:50:43.242+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.241+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:50:43.262+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.262+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:50:43.263+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.263+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T07:20:37.918158+00:00, execution_date=20241214T072037, start_date=, end_date=20241214T072043
[2024-12-14T12:50:43.273+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T12:50:43.274+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T12:50:43.274+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T12:50:43.274+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T12:50:43.275+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.275+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T12:50:43.292+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.292+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T12:50:43.293+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.293+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:20:37.918158+00:00 [scheduled]>
[2024-12-14T12:50:43.322+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:50:43,322] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:20:37.918158+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:20:37.918158+00:00'
[2024-12-14T12:50:43.322+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.322+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:20:37.918158+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:20:37.918158+00:00'
[2024-12-14T12:50:43.323+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:50:43.323+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:50:43.323+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T12:50:43.323+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:50:43.324+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.323+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:50:43.324+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:50:43,324] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:50:43.325+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.324+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:50:43.325+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:50:43,325] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:50:43.325+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.325+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:50:43.335+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:50:43,333] {subprocess.py:99} INFO - Output:
[2024-12-14T12:50:43.336+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.333+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:50:43.377+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:50:43,377] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmph2qe14ca/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:50:43.378+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.377+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmph2qe14ca/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:50:43.383+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:50:43,382] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:50:43.383+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.382+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:50:43.397+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:50:43,390] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:50:43.397+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.390+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:50:43.399+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T12:50:43.399+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 07:20:43.398879+00:00 duration:None
[2024-12-14T12:50:43.399+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 07:20:37.918158+00:00: manual__2024-12-14T07:20:37.918158+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:50:43.400+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:50:43.400+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.400+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T07:20:37.918158+00:00, execution_date=20241214T072037, start_date=, end_date=20241214T072043
[2024-12-14T12:50:43.415+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.415+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:50:43.423+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.416+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:20:37.918158+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:50:43.428+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.428+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 07:20:37.918158+00:00: manual__2024-12-14T07:20:37.918158+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T12:50:43.429+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T12:50:43.429+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T07:20:37.918158+00:00 external trigger: False
[2024-12-14T12:50:43.429+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T12:50:43.430+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.429+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 07:20:37.918158+00:00, run_id=manual__2024-12-14T07:20:37.918158+00:00, run_start_date=2024-12-14 07:20:37.918158+00:00, run_end_date=2024-12-14 07:20:43.429067+00:00, run_duration=5.510909, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 07:20:37.918158+00:00, data_interval_end=2024-12-14 07:20:37.918158+00:00, dag_hash=None
[2024-12-14T12:50:43.439+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:50:43.452+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.452+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T12:50:43.471+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:50:43.471+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T12:50:43.492+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.700 seconds
[2024-12-14T12:53:30.591+0530] {processor.py:186} INFO - Started process (PID=49872) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:53:30.592+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T12:53:30.594+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:30.594+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:53:30.739+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:30.739+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T12:53:30.753+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:30.753+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 07:23:30.710084+00:00: manual__2024-12-14T07:23:30.710084+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:53:30.782+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:30.782+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T12:53:30.782+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:30.782+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T07:23:30.710084+00:00 [scheduled]>
[2024-12-14T12:53:35.810+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:35.810+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T12:53:35.946+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:53:35,945] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:23:30.710084+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:23:30.710084+00:00'
[2024-12-14T12:53:35.946+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:35.945+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:23:30.710084+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:23:30.710084+00:00'
[2024-12-14T12:53:35.950+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:53:35.951+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:53:35.951+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T12:53:35.951+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:53:35.951+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:35.951+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:53:35.981+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:53:35,980] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:53:35.981+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:35.980+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:53:35.982+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:53:35,982] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:53:35.982+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:35.982+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:53:35.991+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:53:35,989] {subprocess.py:99} INFO - Output:
[2024-12-14T12:53:35.993+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:35.989+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:53:35.993+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:53:35,993] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:53:35.993+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:35.993+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:53:35.994+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:53:35,994] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:53:35.995+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:35.994+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:53:36.015+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:36.015+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:53:36.015+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:36.015+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T07:23:30.710084+00:00, execution_date=20241214T072330, start_date=, end_date=20241214T072336
[2024-12-14T12:53:36.025+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T12:53:36.026+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T12:53:36.026+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T12:53:36.026+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T12:53:36.027+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:36.026+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T12:53:36.043+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:36.043+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T12:53:36.043+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:36.043+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:23:30.710084+00:00 [scheduled]>
[2024-12-14T12:53:36.072+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:53:36,072] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:23:30.710084+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:23:30.710084+00:00'
[2024-12-14T12:53:36.073+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:36.072+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:23:30.710084+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:23:30.710084+00:00'
[2024-12-14T12:53:36.074+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:53:36.074+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:53:36.075+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T12:53:36.075+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:53:36.076+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:36.075+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:53:36.077+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:53:36,077] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:53:36.078+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:36.077+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:53:36.079+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:53:36,079] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:53:36.080+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:36.079+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:53:36.089+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:53:36,088] {subprocess.py:99} INFO - Output:
[2024-12-14T12:53:36.091+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:36.088+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:53:36.132+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:53:36,131] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp2fe5qa87/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:53:36.132+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:36.131+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp2fe5qa87/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:53:36.137+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:53:36,137] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:53:36.137+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:36.137+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:53:36.146+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:53:36,144] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:53:36.146+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:36.144+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:53:36.149+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T12:53:36.149+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 07:23:36.148642+00:00 duration:None
[2024-12-14T12:53:36.149+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 07:23:30.710084+00:00: manual__2024-12-14T07:23:30.710084+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:53:36.149+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:53:36.150+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:36.150+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T07:23:30.710084+00:00, execution_date=20241214T072330, start_date=, end_date=20241214T072336
[2024-12-14T12:53:36.161+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:36.161+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:53:36.164+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:36.162+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:23:30.710084+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:53:36.169+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:36.169+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 07:23:30.710084+00:00: manual__2024-12-14T07:23:30.710084+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T12:53:36.169+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T12:53:36.170+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T07:23:30.710084+00:00 external trigger: False
[2024-12-14T12:53:36.170+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T12:53:36.170+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:36.170+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 07:23:30.710084+00:00, run_id=manual__2024-12-14T07:23:30.710084+00:00, run_start_date=2024-12-14 07:23:30.710084+00:00, run_end_date=2024-12-14 07:23:36.169888+00:00, run_duration=5.459804, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 07:23:30.710084+00:00, data_interval_end=2024-12-14 07:23:30.710084+00:00, dag_hash=None
[2024-12-14T12:53:36.179+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:53:36.192+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:36.192+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T12:53:36.209+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:53:36.209+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T12:53:36.231+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.643 seconds
[2024-12-14T12:56:23.254+0530] {processor.py:186} INFO - Started process (PID=50080) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:56:23.255+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T12:56:23.257+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:23.256+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:56:23.404+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:23.404+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T12:56:23.417+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:23.417+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 07:26:23.375263+00:00: manual__2024-12-14T07:26:23.375263+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:56:23.446+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:23.446+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T12:56:23.447+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:23.446+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T07:26:23.375263+00:00 [scheduled]>
[2024-12-14T12:56:28.479+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.479+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T12:56:28.619+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:56:28,619] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:26:23.375263+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:26:23.375263+00:00'
[2024-12-14T12:56:28.620+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.619+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:26:23.375263+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:26:23.375263+00:00'
[2024-12-14T12:56:28.622+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:56:28.622+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:56:28.622+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T12:56:28.623+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:56:28.623+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.623+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:56:28.653+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:56:28,653] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:56:28.654+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.653+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:56:28.654+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:56:28,654] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:56:28.655+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.654+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:56:28.664+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:56:28,662] {subprocess.py:99} INFO - Output:
[2024-12-14T12:56:28.666+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.662+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:56:28.666+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:56:28,666] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:56:28.666+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.666+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:56:28.667+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:56:28,667] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:56:28.667+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.667+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:56:28.687+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.687+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:56:28.688+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.688+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T07:26:23.375263+00:00, execution_date=20241214T072623, start_date=, end_date=20241214T072628
[2024-12-14T12:56:28.698+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T12:56:28.698+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T12:56:28.699+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T12:56:28.699+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T12:56:28.700+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.699+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T12:56:28.716+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.716+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T12:56:28.716+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.716+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:26:23.375263+00:00 [scheduled]>
[2024-12-14T12:56:28.744+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:56:28,744] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:26:23.375263+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:26:23.375263+00:00'
[2024-12-14T12:56:28.744+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.744+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:26:23.375263+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:26:23.375263+00:00'
[2024-12-14T12:56:28.745+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:56:28.745+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:56:28.745+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T12:56:28.745+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:56:28.746+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.745+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:56:28.746+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:56:28,746] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:56:28.747+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.746+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:56:28.747+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:56:28,747] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:56:28.747+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.747+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:56:28.757+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:56:28,755] {subprocess.py:99} INFO - Output:
[2024-12-14T12:56:28.758+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.755+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:56:28.801+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:56:28,801] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpyhxyswd9/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:56:28.802+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.801+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpyhxyswd9/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:56:28.807+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:56:28,807] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:56:28.807+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.807+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:56:28.816+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:56:28,814] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:56:28.816+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.814+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:56:28.819+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T12:56:28.819+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 07:26:28.818681+00:00 duration:None
[2024-12-14T12:56:28.820+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 07:26:23.375263+00:00: manual__2024-12-14T07:26:23.375263+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:56:28.820+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:56:28.820+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.820+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T07:26:23.375263+00:00, execution_date=20241214T072623, start_date=, end_date=20241214T072628
[2024-12-14T12:56:28.831+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.831+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:56:28.834+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.831+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:26:23.375263+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:56:28.838+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.838+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 07:26:23.375263+00:00: manual__2024-12-14T07:26:23.375263+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T12:56:28.839+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T12:56:28.839+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T07:26:23.375263+00:00 external trigger: False
[2024-12-14T12:56:28.839+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T12:56:28.839+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.839+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 07:26:23.375263+00:00, run_id=manual__2024-12-14T07:26:23.375263+00:00, run_start_date=2024-12-14 07:26:23.375263+00:00, run_end_date=2024-12-14 07:26:28.839078+00:00, run_duration=5.463815, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 07:26:23.375263+00:00, data_interval_end=2024-12-14 07:26:23.375263+00:00, dag_hash=None
[2024-12-14T12:56:28.849+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:56:28.861+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.861+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T12:56:28.878+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:56:28.878+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T12:56:28.898+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.648 seconds
[2024-12-14T12:59:17.347+0530] {processor.py:186} INFO - Started process (PID=50286) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:59:17.351+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T12:59:17.354+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:17.354+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:59:17.514+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:17.514+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T12:59:17.529+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:17.529+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 07:29:17.486053+00:00: manual__2024-12-14T07:29:17.486053+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:59:17.564+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:17.564+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T12:59:17.565+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:17.564+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T07:29:17.486053+00:00 [scheduled]>
[2024-12-14T12:59:22.593+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.592+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T12:59:22.727+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:59:22,727] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:29:17.486053+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:29:17.486053+00:00'
[2024-12-14T12:59:22.727+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.727+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:29:17.486053+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:29:17.486053+00:00'
[2024-12-14T12:59:22.740+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:59:22.741+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:59:22.741+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T12:59:22.741+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:59:22.742+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.742+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:59:22.771+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:59:22,771] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:59:22.772+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.771+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:59:22.772+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:59:22,772] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:59:22.773+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.772+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T12:59:22.782+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:59:22,781] {subprocess.py:99} INFO - Output:
[2024-12-14T12:59:22.784+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.781+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:59:22.785+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:59:22,785] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:59:22.785+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.785+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T12:59:22.786+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:59:22,785] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:59:22.786+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.785+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T12:59:22.806+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.806+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:59:22.807+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.807+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T07:29:17.486053+00:00, execution_date=20241214T072917, start_date=, end_date=20241214T072922
[2024-12-14T12:59:22.817+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T12:59:22.818+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T12:59:22.818+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T12:59:22.818+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T12:59:22.819+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.819+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T12:59:22.835+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.835+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T12:59:22.836+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.836+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:29:17.486053+00:00 [scheduled]>
[2024-12-14T12:59:22.864+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:59:22,864] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:29:17.486053+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:29:17.486053+00:00'
[2024-12-14T12:59:22.864+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.864+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:29:17.486053+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:29:17.486053+00:00'
[2024-12-14T12:59:22.865+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T12:59:22.865+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T12:59:22.865+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T12:59:22.865+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T12:59:22.866+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.866+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T12:59:22.866+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:59:22,866] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:59:22.867+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.866+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T12:59:22.867+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:59:22,867] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:59:22.868+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.867+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T12:59:22.880+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:59:22,878] {subprocess.py:99} INFO - Output:
[2024-12-14T12:59:22.881+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.878+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T12:59:22.921+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:59:22,921] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpk9wzk9gi/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:59:22.921+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.921+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpk9wzk9gi/controller.py': [Errno 2] No such file or directory
[2024-12-14T12:59:22.926+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:59:22,926] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:59:22.927+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.926+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T12:59:22.943+0530] {logging_mixin.py:190} INFO - [2024-12-14 12:59:22,935] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:59:22.943+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.935+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:59:22.945+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T12:59:22.945+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 07:29:22.945019+00:00 duration:None
[2024-12-14T12:59:22.946+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 07:29:17.486053+00:00: manual__2024-12-14T07:29:17.486053+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T12:59:22.946+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:59:22.946+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.946+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T07:29:17.486053+00:00, execution_date=20241214T072917, start_date=, end_date=20241214T072922
[2024-12-14T12:59:22.959+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.958+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T12:59:22.965+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.959+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:29:17.486053+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T12:59:22.969+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.969+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 07:29:17.486053+00:00: manual__2024-12-14T07:29:17.486053+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T12:59:22.969+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T12:59:22.970+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T07:29:17.486053+00:00 external trigger: False
[2024-12-14T12:59:22.970+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T12:59:22.970+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.970+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 07:29:17.486053+00:00, run_id=manual__2024-12-14T07:29:17.486053+00:00, run_start_date=2024-12-14 07:29:17.486053+00:00, run_end_date=2024-12-14 07:29:22.969737+00:00, run_duration=5.483684, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 07:29:17.486053+00:00, data_interval_end=2024-12-14 07:29:17.486053+00:00, dag_hash=None
[2024-12-14T12:59:22.978+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T12:59:22.992+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:22.992+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T12:59:23.010+0530] {logging_mixin.py:190} INFO - [2024-12-14T12:59:23.010+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T12:59:23.031+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.687 seconds
[2024-12-14T13:02:11.831+0530] {processor.py:186} INFO - Started process (PID=50494) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:02:11.834+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T13:02:11.836+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:11.835+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:02:11.986+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:11.985+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T13:02:12.000+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:12.000+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 07:32:11.955182+00:00: manual__2024-12-14T07:32:11.955182+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:02:12.033+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:12.033+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T13:02:12.034+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:12.034+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T07:32:11.955182+00:00 [scheduled]>
[2024-12-14T13:02:17.068+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.068+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T13:02:17.216+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:02:17,215] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:32:11.955182+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:32:11.955182+00:00'
[2024-12-14T13:02:17.216+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.215+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:32:11.955182+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:32:11.955182+00:00'
[2024-12-14T13:02:17.229+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:02:17.230+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:02:17.230+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T13:02:17.230+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:02:17.231+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.231+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:02:17.267+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:02:17,267] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:02:17.267+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.267+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:02:17.268+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:02:17,268] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:02:17.268+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.268+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:02:17.277+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:02:17,275] {subprocess.py:99} INFO - Output:
[2024-12-14T13:02:17.278+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.275+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:02:17.280+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:02:17,280] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:02:17.280+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.280+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:02:17.281+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:02:17,281] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:02:17.281+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.281+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:02:17.300+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.300+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:02:17.301+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.301+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T07:32:11.955182+00:00, execution_date=20241214T073211, start_date=, end_date=20241214T073217
[2024-12-14T13:02:17.311+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T13:02:17.312+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T13:02:17.312+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T13:02:17.312+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T13:02:17.313+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.313+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T13:02:17.330+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.330+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T13:02:17.330+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.330+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:32:11.955182+00:00 [scheduled]>
[2024-12-14T13:02:17.364+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:02:17,364] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:32:11.955182+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:32:11.955182+00:00'
[2024-12-14T13:02:17.364+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.364+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:32:11.955182+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:32:11.955182+00:00'
[2024-12-14T13:02:17.365+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:02:17.365+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:02:17.365+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T13:02:17.366+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:02:17.366+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.366+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:02:17.367+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:02:17,367] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:02:17.368+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.367+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:02:17.368+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:02:17,368] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:02:17.369+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.368+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:02:17.380+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:02:17,378] {subprocess.py:99} INFO - Output:
[2024-12-14T13:02:17.382+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.378+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:02:17.431+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:02:17,430] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpsl9fvcxl/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:02:17.431+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.430+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpsl9fvcxl/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:02:17.436+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:02:17,436] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:02:17.437+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.436+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:02:17.455+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:02:17,444] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:02:17.455+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.444+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:02:17.458+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T13:02:17.458+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 07:32:17.457575+00:00 duration:None
[2024-12-14T13:02:17.458+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 07:32:11.955182+00:00: manual__2024-12-14T07:32:11.955182+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:02:17.458+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:02:17.459+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.459+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T07:32:11.955182+00:00, execution_date=20241214T073211, start_date=, end_date=20241214T073217
[2024-12-14T13:02:17.471+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.470+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:02:17.477+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.471+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:32:11.955182+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:02:17.482+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.482+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 07:32:11.955182+00:00: manual__2024-12-14T07:32:11.955182+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T13:02:17.482+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T13:02:17.483+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T07:32:11.955182+00:00 external trigger: False
[2024-12-14T13:02:17.483+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T13:02:17.483+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.483+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 07:32:11.955182+00:00, run_id=manual__2024-12-14T07:32:11.955182+00:00, run_start_date=2024-12-14 07:32:11.955182+00:00, run_end_date=2024-12-14 07:32:17.482750+00:00, run_duration=5.527568, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 07:32:11.955182+00:00, data_interval_end=2024-12-14 07:32:11.955182+00:00, dag_hash=None
[2024-12-14T13:02:17.493+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:02:17.507+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.507+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T13:02:17.528+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:02:17.528+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T13:02:17.548+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.721 seconds
[2024-12-14T13:05:05.869+0530] {processor.py:186} INFO - Started process (PID=50690) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:05:05.871+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T13:05:05.873+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:05.872+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:05:06.017+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:06.016+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T13:05:06.031+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:06.030+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 07:35:05.988009+00:00: manual__2024-12-14T07:35:05.988009+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:05:06.063+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:06.063+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T13:05:06.064+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:06.063+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T07:35:05.988009+00:00 [scheduled]>
[2024-12-14T13:05:11.091+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.091+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T13:05:11.229+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:05:11,229] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:35:05.988009+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:35:05.988009+00:00'
[2024-12-14T13:05:11.230+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.229+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:35:05.988009+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:35:05.988009+00:00'
[2024-12-14T13:05:11.242+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:05:11.243+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:05:11.243+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T13:05:11.243+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:05:11.244+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.244+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:05:11.278+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:05:11,278] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:05:11.279+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.278+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:05:11.280+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:05:11,279] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:05:11.280+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.279+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:05:11.291+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:05:11,290] {subprocess.py:99} INFO - Output:
[2024-12-14T13:05:11.292+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.290+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:05:11.301+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:05:11,300] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:05:11.302+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.300+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:05:11.302+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:05:11,302] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:05:11.302+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.302+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:05:11.321+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.321+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:05:11.322+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.322+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T07:35:05.988009+00:00, execution_date=20241214T073505, start_date=, end_date=20241214T073511
[2024-12-14T13:05:11.333+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T13:05:11.333+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T13:05:11.333+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T13:05:11.334+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T13:05:11.334+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.334+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T13:05:11.350+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.350+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T13:05:11.351+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.350+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:35:05.988009+00:00 [scheduled]>
[2024-12-14T13:05:11.379+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:05:11,379] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:35:05.988009+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:35:05.988009+00:00'
[2024-12-14T13:05:11.380+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.379+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:35:05.988009+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:35:05.988009+00:00'
[2024-12-14T13:05:11.380+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:05:11.380+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:05:11.381+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T13:05:11.381+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:05:11.381+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.381+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:05:11.382+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:05:11,382] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:05:11.382+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.382+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:05:11.383+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:05:11,383] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:05:11.383+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.383+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:05:11.392+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:05:11,391] {subprocess.py:99} INFO - Output:
[2024-12-14T13:05:11.393+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.391+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:05:11.444+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:05:11,443] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp9mt6q4i7/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:05:11.444+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.443+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp9mt6q4i7/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:05:11.449+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:05:11,449] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:05:11.449+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.449+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:05:11.466+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:05:11,456] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:05:11.467+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.456+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:05:11.469+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T13:05:11.469+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 07:35:11.468749+00:00 duration:None
[2024-12-14T13:05:11.469+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 07:35:05.988009+00:00: manual__2024-12-14T07:35:05.988009+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:05:11.469+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:05:11.470+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.470+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T07:35:05.988009+00:00, execution_date=20241214T073505, start_date=, end_date=20241214T073511
[2024-12-14T13:05:11.481+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.481+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:05:11.492+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.481+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:35:05.988009+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:05:11.496+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.496+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 07:35:05.988009+00:00: manual__2024-12-14T07:35:05.988009+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T13:05:11.497+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T13:05:11.497+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T07:35:05.988009+00:00 external trigger: False
[2024-12-14T13:05:11.497+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T13:05:11.497+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.497+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 07:35:05.988009+00:00, run_id=manual__2024-12-14T07:35:05.988009+00:00, run_start_date=2024-12-14 07:35:05.988009+00:00, run_end_date=2024-12-14 07:35:11.497073+00:00, run_duration=5.509064, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 07:35:05.988009+00:00, data_interval_end=2024-12-14 07:35:05.988009+00:00, dag_hash=None
[2024-12-14T13:05:11.507+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:05:11.520+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.520+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T13:05:11.538+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:05:11.538+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T13:05:11.558+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.693 seconds
[2024-12-14T13:07:57.754+0530] {processor.py:186} INFO - Started process (PID=50915) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:07:57.757+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T13:07:57.759+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:07:57.758+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:07:57.905+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:07:57.905+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T13:07:57.919+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:07:57.918+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 07:37:57.874975+00:00: manual__2024-12-14T07:37:57.874975+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:07:57.952+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:07:57.951+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T13:07:57.953+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:07:57.952+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T07:37:57.874975+00:00 [scheduled]>
[2024-12-14T13:08:02.978+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:02.978+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T13:08:03.117+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:08:03,117] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:37:57.874975+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:37:57.874975+00:00'
[2024-12-14T13:08:03.118+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.117+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:37:57.874975+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:37:57.874975+00:00'
[2024-12-14T13:08:03.131+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:08:03.132+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:08:03.132+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T13:08:03.132+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:08:03.133+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.133+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:08:03.164+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:08:03,164] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:08:03.165+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.164+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:08:03.165+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:08:03,165] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:08:03.166+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.165+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:08:03.175+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:08:03,174] {subprocess.py:99} INFO - Output:
[2024-12-14T13:08:03.177+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.174+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:08:03.177+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:08:03,177] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:08:03.178+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.177+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:08:03.178+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:08:03,178] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:08:03.178+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.178+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:08:03.198+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.198+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:08:03.199+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.198+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T07:37:57.874975+00:00, execution_date=20241214T073757, start_date=, end_date=20241214T073803
[2024-12-14T13:08:03.209+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T13:08:03.209+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T13:08:03.210+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T13:08:03.210+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T13:08:03.210+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.210+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T13:08:03.227+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.227+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T13:08:03.228+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.228+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:37:57.874975+00:00 [scheduled]>
[2024-12-14T13:08:03.256+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:08:03,256] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:37:57.874975+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:37:57.874975+00:00'
[2024-12-14T13:08:03.257+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.256+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:37:57.874975+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:37:57.874975+00:00'
[2024-12-14T13:08:03.257+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:08:03.257+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:08:03.257+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T13:08:03.258+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:08:03.258+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.258+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:08:03.259+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:08:03,259] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:08:03.259+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.259+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:08:03.259+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:08:03,259] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:08:03.260+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.259+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:08:03.268+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:08:03,267] {subprocess.py:99} INFO - Output:
[2024-12-14T13:08:03.270+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.267+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:08:03.310+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:08:03,309] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpgsplh40e/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:08:03.310+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.309+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpgsplh40e/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:08:03.315+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:08:03,315] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:08:03.315+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.315+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:08:03.331+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:08:03,322] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:08:03.331+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.322+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:08:03.334+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T13:08:03.334+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 07:38:03.333658+00:00 duration:None
[2024-12-14T13:08:03.335+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 07:37:57.874975+00:00: manual__2024-12-14T07:37:57.874975+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:08:03.335+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:08:03.335+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.335+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T07:37:57.874975+00:00, execution_date=20241214T073757, start_date=, end_date=20241214T073803
[2024-12-14T13:08:03.346+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.346+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:08:03.352+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.347+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:37:57.874975+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:08:03.356+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.356+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 07:37:57.874975+00:00: manual__2024-12-14T07:37:57.874975+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T13:08:03.356+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T13:08:03.357+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T07:37:57.874975+00:00 external trigger: False
[2024-12-14T13:08:03.357+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T13:08:03.357+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.357+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 07:37:57.874975+00:00, run_id=manual__2024-12-14T07:37:57.874975+00:00, run_start_date=2024-12-14 07:37:57.874975+00:00, run_end_date=2024-12-14 07:38:03.356920+00:00, run_duration=5.481945, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 07:37:57.874975+00:00, data_interval_end=2024-12-14 07:37:57.874975+00:00, dag_hash=None
[2024-12-14T13:08:03.372+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:08:03.385+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.385+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T13:08:03.403+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:08:03.403+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T13:08:03.597+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.847 seconds
[2024-12-14T13:10:49.669+0530] {processor.py:186} INFO - Started process (PID=51111) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:10:49.672+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T13:10:49.673+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:49.673+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:10:49.816+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:49.815+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T13:10:49.829+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:49.829+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 07:40:49.787690+00:00: manual__2024-12-14T07:40:49.787690+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:10:49.861+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:49.860+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T13:10:49.861+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:49.861+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T07:40:49.787690+00:00 [scheduled]>
[2024-12-14T13:10:54.896+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:54.895+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T13:10:55.035+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:10:55,035] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:40:49.787690+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:40:49.787690+00:00'
[2024-12-14T13:10:55.035+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.035+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:40:49.787690+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:40:49.787690+00:00'
[2024-12-14T13:10:55.048+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:10:55.049+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:10:55.049+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T13:10:55.049+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:10:55.050+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.050+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:10:55.092+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:10:55,092] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:10:55.092+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.092+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:10:55.093+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:10:55,093] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:10:55.093+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.093+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:10:55.102+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:10:55,101] {subprocess.py:99} INFO - Output:
[2024-12-14T13:10:55.104+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.101+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:10:55.105+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:10:55,104] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:10:55.105+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.104+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:10:55.105+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:10:55,105] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:10:55.106+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.105+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:10:55.126+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.126+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:10:55.127+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.127+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T07:40:49.787690+00:00, execution_date=20241214T074049, start_date=, end_date=20241214T074055
[2024-12-14T13:10:55.137+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T13:10:55.138+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T13:10:55.138+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T13:10:55.138+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T13:10:55.138+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.138+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T13:10:55.156+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.156+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T13:10:55.156+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.156+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:40:49.787690+00:00 [scheduled]>
[2024-12-14T13:10:55.186+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:10:55,186] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:40:49.787690+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:40:49.787690+00:00'
[2024-12-14T13:10:55.187+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.186+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:40:49.787690+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:40:49.787690+00:00'
[2024-12-14T13:10:55.187+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:10:55.187+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:10:55.188+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T13:10:55.188+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:10:55.188+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.188+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:10:55.189+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:10:55,189] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:10:55.189+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.189+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:10:55.190+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:10:55,190] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:10:55.190+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.190+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:10:55.200+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:10:55,198] {subprocess.py:99} INFO - Output:
[2024-12-14T13:10:55.202+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.198+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:10:55.242+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:10:55,242] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmps0cueg47/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:10:55.243+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.242+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmps0cueg47/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:10:55.247+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:10:55,247] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:10:55.248+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.247+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:10:55.261+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:10:55,255] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:10:55.262+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.255+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:10:55.263+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T13:10:55.264+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 07:40:55.263491+00:00 duration:None
[2024-12-14T13:10:55.264+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 07:40:49.787690+00:00: manual__2024-12-14T07:40:49.787690+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:10:55.264+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:10:55.265+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.264+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T07:40:49.787690+00:00, execution_date=20241214T074049, start_date=, end_date=20241214T074055
[2024-12-14T13:10:55.277+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.277+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:10:55.284+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.277+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:40:49.787690+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:10:55.288+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.288+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 07:40:49.787690+00:00: manual__2024-12-14T07:40:49.787690+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T13:10:55.289+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T13:10:55.289+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T07:40:49.787690+00:00 external trigger: False
[2024-12-14T13:10:55.289+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T13:10:55.289+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.289+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 07:40:49.787690+00:00, run_id=manual__2024-12-14T07:40:49.787690+00:00, run_start_date=2024-12-14 07:40:49.787690+00:00, run_end_date=2024-12-14 07:40:55.288935+00:00, run_duration=5.501245, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 07:40:49.787690+00:00, data_interval_end=2024-12-14 07:40:49.787690+00:00, dag_hash=None
[2024-12-14T13:10:55.300+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:10:55.313+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.312+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T13:10:55.330+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:10:55.330+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T13:10:55.353+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.687 seconds
[2024-12-14T13:13:42.729+0530] {processor.py:186} INFO - Started process (PID=51307) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:13:42.731+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T13:13:42.733+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:42.733+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:13:42.880+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:42.880+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T13:13:42.894+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:42.893+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 07:43:42.850568+00:00: manual__2024-12-14T07:43:42.850568+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:13:42.928+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:42.928+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T13:13:42.929+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:42.928+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T07:43:42.850568+00:00 [scheduled]>
[2024-12-14T13:13:47.976+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:47.976+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T13:13:48.133+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:13:48,132] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:43:42.850568+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:43:42.850568+00:00'
[2024-12-14T13:13:48.133+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.132+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:43:42.850568+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:43:42.850568+00:00'
[2024-12-14T13:13:48.147+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:13:48.147+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:13:48.148+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T13:13:48.148+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:13:48.148+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.148+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:13:48.192+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:13:48,192] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:13:48.192+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.192+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:13:48.194+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:13:48,193] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:13:48.194+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.193+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:13:48.204+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:13:48,203] {subprocess.py:99} INFO - Output:
[2024-12-14T13:13:48.206+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.203+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:13:48.212+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:13:48,211] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:13:48.212+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.211+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:13:48.213+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:13:48,213] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:13:48.213+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.213+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:13:48.233+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.232+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:13:48.233+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.233+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T07:43:42.850568+00:00, execution_date=20241214T074342, start_date=, end_date=20241214T074348
[2024-12-14T13:13:48.244+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T13:13:48.244+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T13:13:48.244+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T13:13:48.244+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T13:13:48.245+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.245+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T13:13:48.261+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.260+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T13:13:48.261+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.261+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:43:42.850568+00:00 [scheduled]>
[2024-12-14T13:13:48.290+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:13:48,289] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:43:42.850568+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:43:42.850568+00:00'
[2024-12-14T13:13:48.290+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.289+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:43:42.850568+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:43:42.850568+00:00'
[2024-12-14T13:13:48.290+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:13:48.290+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:13:48.291+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T13:13:48.291+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:13:48.291+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.291+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:13:48.292+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:13:48,292] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:13:48.292+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.292+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:13:48.293+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:13:48,293] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:13:48.294+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.293+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:13:48.302+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:13:48,301] {subprocess.py:99} INFO - Output:
[2024-12-14T13:13:48.304+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.301+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:13:48.355+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:13:48,355] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp9alh8ao9/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:13:48.355+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.355+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp9alh8ao9/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:13:48.361+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:13:48,360] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:13:48.361+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.360+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:13:48.375+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:13:48,368] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:13:48.376+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.368+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:13:48.378+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T13:13:48.378+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 07:43:48.377753+00:00 duration:None
[2024-12-14T13:13:48.378+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 07:43:42.850568+00:00: manual__2024-12-14T07:43:42.850568+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:13:48.378+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:13:48.379+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.379+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T07:43:42.850568+00:00, execution_date=20241214T074342, start_date=, end_date=20241214T074348
[2024-12-14T13:13:48.390+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.389+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:13:48.399+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.390+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:43:42.850568+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:13:48.403+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.403+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 07:43:42.850568+00:00: manual__2024-12-14T07:43:42.850568+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T13:13:48.404+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T13:13:48.404+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T07:43:42.850568+00:00 external trigger: False
[2024-12-14T13:13:48.404+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T13:13:48.404+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.404+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 07:43:42.850568+00:00, run_id=manual__2024-12-14T07:43:42.850568+00:00, run_start_date=2024-12-14 07:43:42.850568+00:00, run_end_date=2024-12-14 07:43:48.403940+00:00, run_duration=5.553372, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 07:43:42.850568+00:00, data_interval_end=2024-12-14 07:43:42.850568+00:00, dag_hash=None
[2024-12-14T13:13:48.414+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:13:48.427+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.426+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T13:13:48.446+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:13:48.446+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T13:13:48.466+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.742 seconds
[2024-12-14T13:16:38.067+0530] {processor.py:186} INFO - Started process (PID=51515) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:16:38.070+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T13:16:38.071+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:38.071+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:16:38.214+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:38.214+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T13:16:38.228+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:38.228+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 07:46:38.186438+00:00: manual__2024-12-14T07:46:38.186438+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:16:38.263+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:38.262+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T13:16:38.263+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:38.263+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T07:46:38.186438+00:00 [scheduled]>
[2024-12-14T13:16:43.295+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.294+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T13:16:43.433+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:16:43,433] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:46:38.186438+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:46:38.186438+00:00'
[2024-12-14T13:16:43.434+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.433+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:46:38.186438+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:46:38.186438+00:00'
[2024-12-14T13:16:43.447+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:16:43.447+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:16:43.448+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T13:16:43.448+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:16:43.449+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.449+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:16:43.484+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:16:43,484] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:16:43.484+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.484+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:16:43.487+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:16:43,487] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:16:43.488+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.487+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:16:43.498+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:16:43,496] {subprocess.py:99} INFO - Output:
[2024-12-14T13:16:43.500+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.496+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:16:43.500+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:16:43,500] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:16:43.501+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.500+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:16:43.501+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:16:43,501] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:16:43.501+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.501+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:16:43.520+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.520+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:16:43.521+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.521+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T07:46:38.186438+00:00, execution_date=20241214T074638, start_date=, end_date=20241214T074643
[2024-12-14T13:16:43.531+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T13:16:43.532+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T13:16:43.532+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T13:16:43.532+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T13:16:43.533+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.532+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T13:16:43.548+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.548+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T13:16:43.549+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.549+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:46:38.186438+00:00 [scheduled]>
[2024-12-14T13:16:43.575+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:16:43,575] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:46:38.186438+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:46:38.186438+00:00'
[2024-12-14T13:16:43.576+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.575+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:46:38.186438+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:46:38.186438+00:00'
[2024-12-14T13:16:43.576+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:16:43.577+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:16:43.577+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T13:16:43.577+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:16:43.578+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.578+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:16:43.578+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:16:43,578] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:16:43.579+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.578+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:16:43.579+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:16:43,579] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:16:43.580+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.579+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:16:43.589+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:16:43,587] {subprocess.py:99} INFO - Output:
[2024-12-14T13:16:43.590+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.587+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:16:43.630+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:16:43,629] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmprkb_d3f0/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:16:43.630+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.629+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmprkb_d3f0/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:16:43.635+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:16:43,635] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:16:43.635+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.635+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:16:43.649+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:16:43,642] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:16:43.650+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.642+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:16:43.651+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T13:16:43.652+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 07:46:43.651359+00:00 duration:None
[2024-12-14T13:16:43.652+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 07:46:38.186438+00:00: manual__2024-12-14T07:46:38.186438+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:16:43.652+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:16:43.653+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.652+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T07:46:38.186438+00:00, execution_date=20241214T074638, start_date=, end_date=20241214T074643
[2024-12-14T13:16:43.664+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.663+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:16:43.673+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.664+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:46:38.186438+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:16:43.678+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.678+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 07:46:38.186438+00:00: manual__2024-12-14T07:46:38.186438+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T13:16:43.678+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T13:16:43.678+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T07:46:38.186438+00:00 external trigger: False
[2024-12-14T13:16:43.679+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T13:16:43.679+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.679+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 07:46:38.186438+00:00, run_id=manual__2024-12-14T07:46:38.186438+00:00, run_start_date=2024-12-14 07:46:38.186438+00:00, run_end_date=2024-12-14 07:46:43.678700+00:00, run_duration=5.492262, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 07:46:38.186438+00:00, data_interval_end=2024-12-14 07:46:38.186438+00:00, dag_hash=None
[2024-12-14T13:16:43.688+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:16:43.705+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.705+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T13:16:43.723+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:16:43.723+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T13:16:43.741+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.678 seconds
[2024-12-14T13:19:32.530+0530] {processor.py:186} INFO - Started process (PID=51711) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:19:32.533+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T13:19:32.534+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:32.534+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:19:32.682+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:32.682+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T13:19:32.696+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:32.696+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 07:49:32.653406+00:00: manual__2024-12-14T07:49:32.653406+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:19:32.730+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:32.729+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T13:19:32.730+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:32.730+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T07:49:32.653406+00:00 [scheduled]>
[2024-12-14T13:19:37.763+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:37.763+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T13:19:37.920+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:19:37,919] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:49:32.653406+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:49:32.653406+00:00'
[2024-12-14T13:19:37.920+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:37.919+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:49:32.653406+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:49:32.653406+00:00'
[2024-12-14T13:19:37.932+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:19:37.933+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:19:37.933+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T13:19:37.933+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:19:37.934+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:37.933+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:19:37.965+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:19:37,965] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:19:37.965+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:37.965+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:19:37.966+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:19:37,966] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:19:37.967+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:37.966+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:19:37.976+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:19:37,974] {subprocess.py:99} INFO - Output:
[2024-12-14T13:19:37.977+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:37.974+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:19:37.979+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:19:37,978] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:19:37.979+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:37.978+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:19:37.979+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:19:37,979] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:19:37.980+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:37.979+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:19:37.999+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:37.999+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:19:38.000+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:37.999+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T07:49:32.653406+00:00, execution_date=20241214T074932, start_date=, end_date=20241214T074937
[2024-12-14T13:19:38.010+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T13:19:38.010+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T13:19:38.011+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T13:19:38.011+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T13:19:38.011+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:38.011+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T13:19:38.027+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:38.027+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T13:19:38.027+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:38.027+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:49:32.653406+00:00 [scheduled]>
[2024-12-14T13:19:38.054+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:19:38,054] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:49:32.653406+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:49:32.653406+00:00'
[2024-12-14T13:19:38.055+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:38.054+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:49:32.653406+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:49:32.653406+00:00'
[2024-12-14T13:19:38.055+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:19:38.055+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:19:38.056+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T13:19:38.056+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:19:38.056+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:38.056+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:19:38.057+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:19:38,057] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:19:38.057+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:38.057+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:19:38.058+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:19:38,058] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:19:38.058+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:38.058+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:19:38.068+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:19:38,066] {subprocess.py:99} INFO - Output:
[2024-12-14T13:19:38.069+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:38.066+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:19:38.110+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:19:38,109] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp1oz8gj7h/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:19:38.110+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:38.109+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp1oz8gj7h/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:19:38.115+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:19:38,115] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:19:38.115+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:38.115+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:19:38.130+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:19:38,122] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:19:38.130+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:38.122+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:19:38.133+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T13:19:38.133+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 07:49:38.132476+00:00 duration:None
[2024-12-14T13:19:38.133+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 07:49:32.653406+00:00: manual__2024-12-14T07:49:32.653406+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:19:38.133+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:19:38.134+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:38.134+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T07:49:32.653406+00:00, execution_date=20241214T074932, start_date=, end_date=20241214T074938
[2024-12-14T13:19:38.145+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:38.145+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:19:38.151+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:38.146+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:49:32.653406+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:19:38.156+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:38.155+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 07:49:32.653406+00:00: manual__2024-12-14T07:49:32.653406+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T13:19:38.156+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T13:19:38.156+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T07:49:32.653406+00:00 external trigger: False
[2024-12-14T13:19:38.156+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T13:19:38.157+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:38.157+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 07:49:32.653406+00:00, run_id=manual__2024-12-14T07:49:32.653406+00:00, run_start_date=2024-12-14 07:49:32.653406+00:00, run_end_date=2024-12-14 07:49:38.156462+00:00, run_duration=5.503056, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 07:49:32.653406+00:00, data_interval_end=2024-12-14 07:49:32.653406+00:00, dag_hash=None
[2024-12-14T13:19:38.166+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:19:38.179+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:38.178+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T13:19:38.197+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:19:38.197+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T13:19:38.217+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.690 seconds
[2024-12-14T13:22:26.637+0530] {processor.py:186} INFO - Started process (PID=51929) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:22:26.640+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T13:22:26.641+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:26.641+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:22:26.787+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:26.787+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T13:22:26.802+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:26.801+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 07:52:26.758097+00:00: manual__2024-12-14T07:52:26.758097+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:22:26.837+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:26.837+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T13:22:26.837+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:26.837+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T07:52:26.758097+00:00 [scheduled]>
[2024-12-14T13:22:31.863+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:31.863+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T13:22:32.000+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:22:32,000] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:52:26.758097+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:52:26.758097+00:00'
[2024-12-14T13:22:32.000+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.000+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:52:26.758097+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:52:26.758097+00:00'
[2024-12-14T13:22:32.014+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:22:32.015+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:22:32.015+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T13:22:32.015+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:22:32.016+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.016+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:22:32.046+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:22:32,046] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:22:32.047+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.046+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:22:32.048+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:22:32,047] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:22:32.048+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.047+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:22:32.057+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:22:32,055] {subprocess.py:99} INFO - Output:
[2024-12-14T13:22:32.059+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.055+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:22:32.060+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:22:32,060] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:22:32.061+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.060+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:22:32.061+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:22:32,061] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:22:32.061+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.061+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:22:32.081+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.081+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:22:32.082+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.082+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T07:52:26.758097+00:00, execution_date=20241214T075226, start_date=, end_date=20241214T075232
[2024-12-14T13:22:32.092+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T13:22:32.093+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T13:22:32.093+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T13:22:32.093+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T13:22:32.094+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.093+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T13:22:32.111+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.111+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T13:22:32.111+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.111+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:52:26.758097+00:00 [scheduled]>
[2024-12-14T13:22:32.139+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:22:32,139] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:52:26.758097+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:52:26.758097+00:00'
[2024-12-14T13:22:32.139+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.139+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:52:26.758097+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:52:26.758097+00:00'
[2024-12-14T13:22:32.139+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:22:32.140+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:22:32.140+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T13:22:32.140+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:22:32.140+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.140+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:22:32.141+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:22:32,141] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:22:32.141+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.141+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:22:32.143+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:22:32,142] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:22:32.143+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.142+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:22:32.153+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:22:32,151] {subprocess.py:99} INFO - Output:
[2024-12-14T13:22:32.154+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.151+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:22:32.196+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:22:32,196] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmplpaz70cl/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:22:32.196+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.196+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmplpaz70cl/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:22:32.201+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:22:32,201] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:22:32.202+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.201+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:22:32.215+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:22:32,209] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:22:32.216+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.209+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:22:32.217+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T13:22:32.218+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 07:52:32.217414+00:00 duration:None
[2024-12-14T13:22:32.218+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 07:52:26.758097+00:00: manual__2024-12-14T07:52:26.758097+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:22:32.218+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:22:32.219+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.218+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T07:52:26.758097+00:00, execution_date=20241214T075226, start_date=, end_date=20241214T075232
[2024-12-14T13:22:32.231+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.230+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:22:32.239+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.231+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:52:26.758097+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:22:32.244+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.243+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 07:52:26.758097+00:00: manual__2024-12-14T07:52:26.758097+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T13:22:32.244+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T13:22:32.244+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T07:52:26.758097+00:00 external trigger: False
[2024-12-14T13:22:32.244+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T13:22:32.245+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.244+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 07:52:26.758097+00:00, run_id=manual__2024-12-14T07:52:26.758097+00:00, run_start_date=2024-12-14 07:52:26.758097+00:00, run_end_date=2024-12-14 07:52:32.244252+00:00, run_duration=5.486155, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 07:52:26.758097+00:00, data_interval_end=2024-12-14 07:52:26.758097+00:00, dag_hash=None
[2024-12-14T13:22:32.258+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:22:32.272+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.272+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T13:22:32.292+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:22:32.292+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T13:22:32.312+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.679 seconds
[2024-12-14T13:25:20.609+0530] {processor.py:186} INFO - Started process (PID=52128) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:25:20.612+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T13:25:20.613+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:20.613+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:25:20.757+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:20.757+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T13:25:20.771+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:20.771+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 07:55:20.729800+00:00: manual__2024-12-14T07:55:20.729800+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:25:20.803+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:20.803+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T13:25:20.804+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:20.803+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T07:55:20.729800+00:00 [scheduled]>
[2024-12-14T13:25:25.831+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:25.831+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T13:25:25.965+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:25:25,965] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:55:20.729800+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:55:20.729800+00:00'
[2024-12-14T13:25:25.965+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:25.965+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:55:20.729800+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:55:20.729800+00:00'
[2024-12-14T13:25:25.977+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:25:25.978+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:25:25.979+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T13:25:25.979+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:25:25.979+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:25.979+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:25:26.010+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:25:26,010] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:25:26.011+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:26.010+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:25:26.011+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:25:26,011] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:25:26.012+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:26.011+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:25:26.021+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:25:26,019] {subprocess.py:99} INFO - Output:
[2024-12-14T13:25:26.022+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:26.019+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:25:26.024+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:25:26,024] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:25:26.025+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:26.024+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:25:26.025+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:25:26,025] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:25:26.026+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:26.025+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:25:26.047+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:26.046+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:25:26.047+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:26.047+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T07:55:20.729800+00:00, execution_date=20241214T075520, start_date=, end_date=20241214T075526
[2024-12-14T13:25:26.057+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T13:25:26.058+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T13:25:26.058+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T13:25:26.058+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T13:25:26.059+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:26.058+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T13:25:26.075+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:26.074+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T13:25:26.075+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:26.075+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:55:20.729800+00:00 [scheduled]>
[2024-12-14T13:25:26.103+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:25:26,103] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:55:20.729800+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:55:20.729800+00:00'
[2024-12-14T13:25:26.103+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:26.103+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:55:20.729800+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:55:20.729800+00:00'
[2024-12-14T13:25:26.104+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:25:26.104+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:25:26.104+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T13:25:26.104+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:25:26.105+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:26.104+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:25:26.105+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:25:26,105] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:25:26.106+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:26.105+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:25:26.106+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:25:26,106] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:25:26.106+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:26.106+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:25:26.117+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:25:26,115] {subprocess.py:99} INFO - Output:
[2024-12-14T13:25:26.118+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:26.115+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:25:26.158+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:25:26,158] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpbx88ov6b/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:25:26.159+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:26.158+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpbx88ov6b/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:25:26.164+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:25:26,163] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:25:26.164+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:26.163+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:25:26.183+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:25:26,171] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:25:26.184+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:26.171+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:25:26.186+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T13:25:26.187+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 07:55:26.185983+00:00 duration:None
[2024-12-14T13:25:26.187+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 07:55:20.729800+00:00: manual__2024-12-14T07:55:20.729800+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:25:26.187+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:25:26.188+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:26.187+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T07:55:20.729800+00:00, execution_date=20241214T075520, start_date=, end_date=20241214T075526
[2024-12-14T13:25:26.199+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:26.199+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:25:26.204+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:26.199+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:55:20.729800+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:25:26.208+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:26.208+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 07:55:20.729800+00:00: manual__2024-12-14T07:55:20.729800+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T13:25:26.209+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T13:25:26.209+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T07:55:20.729800+00:00 external trigger: False
[2024-12-14T13:25:26.209+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T13:25:26.209+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:26.209+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 07:55:20.729800+00:00, run_id=manual__2024-12-14T07:55:20.729800+00:00, run_start_date=2024-12-14 07:55:20.729800+00:00, run_end_date=2024-12-14 07:55:26.209079+00:00, run_duration=5.479279, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 07:55:20.729800+00:00, data_interval_end=2024-12-14 07:55:20.729800+00:00, dag_hash=None
[2024-12-14T13:25:26.219+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:25:26.232+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:26.231+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T13:25:26.250+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:25:26.249+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T13:25:26.270+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.664 seconds
[2024-12-14T13:28:12.846+0530] {processor.py:186} INFO - Started process (PID=52334) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:28:12.847+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T13:28:12.848+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:12.848+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:28:12.996+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:12.996+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T13:28:13.009+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:13.009+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 07:58:12.968066+00:00: manual__2024-12-14T07:58:12.968066+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:28:13.045+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:13.044+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T13:28:13.045+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:13.045+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T07:58:12.968066+00:00 [scheduled]>
[2024-12-14T13:28:18.080+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.079+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T13:28:18.217+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:28:18,217] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:58:12.968066+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:58:12.968066+00:00'
[2024-12-14T13:28:18.217+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.217+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:58:12.968066+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:58:12.968066+00:00'
[2024-12-14T13:28:18.228+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:28:18.228+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:28:18.229+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T13:28:18.229+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:28:18.230+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.229+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:28:18.260+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:28:18,259] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:28:18.260+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.259+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:28:18.261+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:28:18,261] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:28:18.261+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.261+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:28:18.271+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:28:18,269] {subprocess.py:99} INFO - Output:
[2024-12-14T13:28:18.274+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.269+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:28:18.275+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:28:18,274] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:28:18.275+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.274+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:28:18.276+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:28:18,276] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:28:18.276+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.276+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:28:18.301+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.301+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:28:18.302+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.302+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T07:58:12.968066+00:00, execution_date=20241214T075812, start_date=, end_date=20241214T075818
[2024-12-14T13:28:18.312+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T13:28:18.312+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T13:28:18.313+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T13:28:18.313+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T13:28:18.313+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.313+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T13:28:18.329+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.329+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T13:28:18.330+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.329+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:58:12.968066+00:00 [scheduled]>
[2024-12-14T13:28:18.357+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:28:18,357] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:58:12.968066+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:58:12.968066+00:00'
[2024-12-14T13:28:18.358+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.357+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T07:58:12.968066+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T07:58:12.968066+00:00'
[2024-12-14T13:28:18.358+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:28:18.359+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:28:18.359+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T13:28:18.359+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:28:18.359+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.359+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:28:18.360+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:28:18,360] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:28:18.360+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.360+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:28:18.361+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:28:18,361] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:28:18.361+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.361+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:28:18.370+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:28:18,368] {subprocess.py:99} INFO - Output:
[2024-12-14T13:28:18.371+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.368+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:28:18.413+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:28:18,413] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpqf9n0_ql/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:28:18.414+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.413+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpqf9n0_ql/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:28:18.419+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:28:18,419] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:28:18.419+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.419+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:28:18.433+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:28:18,426] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:28:18.433+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.426+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:28:18.435+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T13:28:18.435+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 07:58:18.435184+00:00 duration:None
[2024-12-14T13:28:18.436+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 07:58:12.968066+00:00: manual__2024-12-14T07:58:12.968066+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:28:18.436+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:28:18.436+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.436+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T07:58:12.968066+00:00, execution_date=20241214T075812, start_date=, end_date=20241214T075818
[2024-12-14T13:28:18.447+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.446+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:28:18.451+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.447+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T07:58:12.968066+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:28:18.455+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.455+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 07:58:12.968066+00:00: manual__2024-12-14T07:58:12.968066+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T13:28:18.456+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T13:28:18.456+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T07:58:12.968066+00:00 external trigger: False
[2024-12-14T13:28:18.456+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T13:28:18.456+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.456+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 07:58:12.968066+00:00, run_id=manual__2024-12-14T07:58:12.968066+00:00, run_start_date=2024-12-14 07:58:12.968066+00:00, run_end_date=2024-12-14 07:58:18.456120+00:00, run_duration=5.488054, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 07:58:12.968066+00:00, data_interval_end=2024-12-14 07:58:12.968066+00:00, dag_hash=None
[2024-12-14T13:28:18.466+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:28:18.479+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.478+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T13:28:18.496+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:28:18.496+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T13:28:18.517+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.675 seconds
[2024-12-14T13:31:05.761+0530] {processor.py:186} INFO - Started process (PID=52531) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:31:05.764+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T13:31:05.765+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:05.765+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:31:05.911+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:05.911+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T13:31:05.925+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:05.924+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 08:01:05.882860+00:00: manual__2024-12-14T08:01:05.882860+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:31:05.958+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:05.958+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T13:31:05.958+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:05.958+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T08:01:05.882860+00:00 [scheduled]>
[2024-12-14T13:31:10.988+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:10.987+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T13:31:11.126+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:31:11,126] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:01:05.882860+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:01:05.882860+00:00'
[2024-12-14T13:31:11.126+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.126+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:01:05.882860+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:01:05.882860+00:00'
[2024-12-14T13:31:11.139+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:31:11.139+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:31:11.140+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T13:31:11.140+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:31:11.140+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.140+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:31:11.170+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:31:11,170] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:31:11.171+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.170+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:31:11.172+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:31:11,172] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:31:11.172+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.172+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:31:11.182+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:31:11,180] {subprocess.py:99} INFO - Output:
[2024-12-14T13:31:11.183+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.180+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:31:11.184+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:31:11,183] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:31:11.184+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.183+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:31:11.184+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:31:11,184] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:31:11.185+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.184+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:31:11.208+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.207+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:31:11.208+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.208+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T08:01:05.882860+00:00, execution_date=20241214T080105, start_date=, end_date=20241214T080111
[2024-12-14T13:31:11.220+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T13:31:11.221+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T13:31:11.221+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T13:31:11.221+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T13:31:11.222+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.221+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T13:31:11.239+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.238+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T13:31:11.239+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.239+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:01:05.882860+00:00 [scheduled]>
[2024-12-14T13:31:11.268+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:31:11,268] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:01:05.882860+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:01:05.882860+00:00'
[2024-12-14T13:31:11.268+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.268+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:01:05.882860+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:01:05.882860+00:00'
[2024-12-14T13:31:11.269+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:31:11.269+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:31:11.269+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T13:31:11.269+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:31:11.270+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.270+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:31:11.271+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:31:11,271] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:31:11.271+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.271+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:31:11.272+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:31:11,272] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:31:11.272+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.272+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:31:11.282+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:31:11,280] {subprocess.py:99} INFO - Output:
[2024-12-14T13:31:11.283+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.280+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:31:11.323+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:31:11,323] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp5z1hakob/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:31:11.323+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.323+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp5z1hakob/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:31:11.328+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:31:11,328] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:31:11.329+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.328+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:31:11.347+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:31:11,336] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:31:11.347+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.336+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:31:11.350+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T13:31:11.350+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 08:01:11.349712+00:00 duration:None
[2024-12-14T13:31:11.351+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 08:01:05.882860+00:00: manual__2024-12-14T08:01:05.882860+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:31:11.351+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:31:11.351+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.351+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T08:01:05.882860+00:00, execution_date=20241214T080105, start_date=, end_date=20241214T080111
[2024-12-14T13:31:11.363+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.362+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:31:11.368+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.363+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:01:05.882860+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:31:11.373+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.372+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 08:01:05.882860+00:00: manual__2024-12-14T08:01:05.882860+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T13:31:11.373+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T13:31:11.373+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T08:01:05.882860+00:00 external trigger: False
[2024-12-14T13:31:11.373+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T13:31:11.374+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.374+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 08:01:05.882860+00:00, run_id=manual__2024-12-14T08:01:05.882860+00:00, run_start_date=2024-12-14 08:01:05.882860+00:00, run_end_date=2024-12-14 08:01:11.373377+00:00, run_duration=5.490517, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 08:01:05.882860+00:00, data_interval_end=2024-12-14 08:01:05.882860+00:00, dag_hash=None
[2024-12-14T13:31:11.383+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:31:11.396+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.396+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T13:31:11.415+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:31:11.415+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T13:31:11.437+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.679 seconds
[2024-12-14T13:33:58.628+0530] {processor.py:186} INFO - Started process (PID=52738) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:33:58.631+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T13:33:58.634+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:33:58.633+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:33:58.785+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:33:58.784+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T13:33:58.798+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:33:58.798+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 08:03:58.755628+00:00: manual__2024-12-14T08:03:58.755628+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:33:58.831+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:33:58.830+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T13:33:58.831+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:33:58.831+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T08:03:58.755628+00:00 [scheduled]>
[2024-12-14T13:34:03.860+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:03.859+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T13:34:03.995+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:34:03,995] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:03:58.755628+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:03:58.755628+00:00'
[2024-12-14T13:34:03.995+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:03.995+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:03:58.755628+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:03:58.755628+00:00'
[2024-12-14T13:34:04.008+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:34:04.008+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:34:04.009+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T13:34:04.009+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:34:04.010+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:04.010+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:34:04.039+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:34:04,039] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:34:04.040+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:04.039+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:34:04.040+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:34:04,040] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:34:04.041+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:04.040+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:34:04.050+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:34:04,049] {subprocess.py:99} INFO - Output:
[2024-12-14T13:34:04.052+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:04.049+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:34:04.053+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:34:04,053] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:34:04.053+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:04.053+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:34:04.053+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:34:04,053] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:34:04.054+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:04.053+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:34:04.074+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:04.074+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:34:04.074+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:04.074+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T08:03:58.755628+00:00, execution_date=20241214T080358, start_date=, end_date=20241214T080404
[2024-12-14T13:34:04.085+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T13:34:04.086+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T13:34:04.086+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T13:34:04.086+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T13:34:04.087+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:04.087+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T13:34:04.103+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:04.103+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T13:34:04.104+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:04.104+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:03:58.755628+00:00 [scheduled]>
[2024-12-14T13:34:04.132+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:34:04,131] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:03:58.755628+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:03:58.755628+00:00'
[2024-12-14T13:34:04.132+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:04.131+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:03:58.755628+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:03:58.755628+00:00'
[2024-12-14T13:34:04.132+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:34:04.132+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:34:04.133+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T13:34:04.133+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:34:04.133+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:04.133+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:34:04.134+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:34:04,134] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:34:04.134+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:04.134+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:34:04.135+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:34:04,135] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:34:04.135+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:04.135+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:34:04.145+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:34:04,144] {subprocess.py:99} INFO - Output:
[2024-12-14T13:34:04.147+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:04.144+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:34:04.186+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:34:04,186] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp_sztp5s6/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:34:04.187+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:04.186+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp_sztp5s6/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:34:04.191+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:34:04,191] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:34:04.192+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:04.191+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:34:04.210+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:34:04,199] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:34:04.210+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:04.199+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:34:04.212+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T13:34:04.213+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 08:04:04.212457+00:00 duration:None
[2024-12-14T13:34:04.213+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 08:03:58.755628+00:00: manual__2024-12-14T08:03:58.755628+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:34:04.213+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:34:04.214+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:04.213+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T08:03:58.755628+00:00, execution_date=20241214T080358, start_date=, end_date=20241214T080404
[2024-12-14T13:34:04.224+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:04.224+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:34:04.231+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:04.225+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:03:58.755628+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:34:04.235+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:04.235+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 08:03:58.755628+00:00: manual__2024-12-14T08:03:58.755628+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T13:34:04.235+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T13:34:04.236+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T08:03:58.755628+00:00 external trigger: False
[2024-12-14T13:34:04.236+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T13:34:04.236+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:04.236+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 08:03:58.755628+00:00, run_id=manual__2024-12-14T08:03:58.755628+00:00, run_start_date=2024-12-14 08:03:58.755628+00:00, run_end_date=2024-12-14 08:04:04.235738+00:00, run_duration=5.48011, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 08:03:58.755628+00:00, data_interval_end=2024-12-14 08:03:58.755628+00:00, dag_hash=None
[2024-12-14T13:34:04.246+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:34:04.258+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:04.258+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T13:34:04.276+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:34:04.276+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T13:34:04.295+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.670 seconds
[2024-12-14T13:36:51.868+0530] {processor.py:186} INFO - Started process (PID=52936) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:36:51.872+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T13:36:51.874+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:51.874+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:36:52.017+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:52.017+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T13:36:52.031+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:52.030+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 08:06:51.989788+00:00: manual__2024-12-14T08:06:51.989788+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:36:52.066+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:52.066+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T13:36:52.067+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:52.067+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T08:06:51.989788+00:00 [scheduled]>
[2024-12-14T13:36:57.102+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.102+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T13:36:57.245+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:36:57,245] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:06:51.989788+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:06:51.989788+00:00'
[2024-12-14T13:36:57.245+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.245+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:06:51.989788+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:06:51.989788+00:00'
[2024-12-14T13:36:57.259+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:36:57.259+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:36:57.259+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T13:36:57.260+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:36:57.260+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.260+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:36:57.293+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:36:57,293] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:36:57.294+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.293+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:36:57.295+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:36:57,294] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:36:57.295+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.294+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:36:57.305+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:36:57,303] {subprocess.py:99} INFO - Output:
[2024-12-14T13:36:57.307+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.303+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:36:57.308+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:36:57,307] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:36:57.308+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.307+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:36:57.309+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:36:57,308] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:36:57.309+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.308+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:36:57.329+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.329+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:36:57.330+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.329+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T08:06:51.989788+00:00, execution_date=20241214T080651, start_date=, end_date=20241214T080657
[2024-12-14T13:36:57.340+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T13:36:57.340+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T13:36:57.341+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T13:36:57.341+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T13:36:57.341+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.341+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T13:36:57.359+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.358+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T13:36:57.359+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.359+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:06:51.989788+00:00 [scheduled]>
[2024-12-14T13:36:57.386+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:36:57,386] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:06:51.989788+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:06:51.989788+00:00'
[2024-12-14T13:36:57.387+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.386+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:06:51.989788+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:06:51.989788+00:00'
[2024-12-14T13:36:57.387+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:36:57.387+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:36:57.388+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T13:36:57.388+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:36:57.388+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.388+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:36:57.389+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:36:57,389] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:36:57.389+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.389+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:36:57.390+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:36:57,389] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:36:57.390+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.389+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:36:57.401+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:36:57,397] {subprocess.py:99} INFO - Output:
[2024-12-14T13:36:57.402+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.397+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:36:57.442+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:36:57,442] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp5y2cqniz/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:36:57.443+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.442+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp5y2cqniz/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:36:57.448+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:36:57,447] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:36:57.448+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.447+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:36:57.462+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:36:57,454] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:36:57.462+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.454+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:36:57.464+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T13:36:57.465+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 08:06:57.464026+00:00 duration:None
[2024-12-14T13:36:57.465+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 08:06:51.989788+00:00: manual__2024-12-14T08:06:51.989788+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:36:57.465+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:36:57.466+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.465+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T08:06:51.989788+00:00, execution_date=20241214T080651, start_date=, end_date=20241214T080657
[2024-12-14T13:36:57.476+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.476+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:36:57.487+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.477+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:06:51.989788+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:36:57.491+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.491+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 08:06:51.989788+00:00: manual__2024-12-14T08:06:51.989788+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T13:36:57.492+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T13:36:57.492+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T08:06:51.989788+00:00 external trigger: False
[2024-12-14T13:36:57.492+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T13:36:57.492+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.492+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 08:06:51.989788+00:00, run_id=manual__2024-12-14T08:06:51.989788+00:00, run_start_date=2024-12-14 08:06:51.989788+00:00, run_end_date=2024-12-14 08:06:57.492008+00:00, run_duration=5.50222, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 08:06:51.989788+00:00, data_interval_end=2024-12-14 08:06:51.989788+00:00, dag_hash=None
[2024-12-14T13:36:57.501+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:36:57.514+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.513+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T13:36:57.532+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:36:57.531+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T13:36:57.552+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.687 seconds
[2024-12-14T13:39:45.588+0530] {processor.py:186} INFO - Started process (PID=53132) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:39:45.591+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T13:39:45.592+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:45.592+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:39:45.757+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:45.756+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T13:39:45.771+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:45.770+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 08:09:45.721928+00:00: manual__2024-12-14T08:09:45.721928+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:39:45.803+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:45.803+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T13:39:45.804+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:45.804+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T08:09:45.721928+00:00 [scheduled]>
[2024-12-14T13:39:50.834+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:50.833+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T13:39:50.974+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:39:50,974] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:09:45.721928+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:09:45.721928+00:00'
[2024-12-14T13:39:50.974+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:50.974+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:09:45.721928+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:09:45.721928+00:00'
[2024-12-14T13:39:50.986+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:39:50.987+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:39:50.987+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T13:39:50.987+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:39:50.988+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:50.988+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:39:51.020+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:39:51,020] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:39:51.020+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:51.020+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:39:51.021+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:39:51,021] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:39:51.021+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:51.021+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:39:51.030+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:39:51,029] {subprocess.py:99} INFO - Output:
[2024-12-14T13:39:51.031+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:51.029+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:39:51.035+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:39:51,034] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:39:51.035+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:51.034+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:39:51.035+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:39:51,035] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:39:51.036+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:51.035+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:39:51.057+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:51.057+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:39:51.057+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:51.057+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T08:09:45.721928+00:00, execution_date=20241214T080945, start_date=, end_date=20241214T080951
[2024-12-14T13:39:51.068+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T13:39:51.068+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T13:39:51.068+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T13:39:51.068+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T13:39:51.069+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:51.069+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T13:39:51.084+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:51.084+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T13:39:51.084+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:51.084+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:09:45.721928+00:00 [scheduled]>
[2024-12-14T13:39:51.111+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:39:51,111] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:09:45.721928+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:09:45.721928+00:00'
[2024-12-14T13:39:51.111+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:51.111+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:09:45.721928+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:09:45.721928+00:00'
[2024-12-14T13:39:51.112+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:39:51.112+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:39:51.112+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T13:39:51.112+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:39:51.113+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:51.112+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:39:51.113+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:39:51,113] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:39:51.114+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:51.113+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:39:51.114+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:39:51,114] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:39:51.115+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:51.114+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:39:51.125+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:39:51,123] {subprocess.py:99} INFO - Output:
[2024-12-14T13:39:51.126+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:51.123+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:39:51.170+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:39:51,169] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpsar_rxdt/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:39:51.170+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:51.169+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpsar_rxdt/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:39:51.175+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:39:51,175] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:39:51.175+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:51.175+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:39:51.193+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:39:51,182] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:39:51.194+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:51.182+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:39:51.198+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T13:39:51.199+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 08:09:51.197536+00:00 duration:None
[2024-12-14T13:39:51.199+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 08:09:45.721928+00:00: manual__2024-12-14T08:09:45.721928+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:39:51.199+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:39:51.200+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:51.200+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T08:09:45.721928+00:00, execution_date=20241214T080945, start_date=, end_date=20241214T080951
[2024-12-14T13:39:51.212+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:51.212+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:39:51.220+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:51.212+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:09:45.721928+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:39:51.225+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:51.224+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 08:09:45.721928+00:00: manual__2024-12-14T08:09:45.721928+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T13:39:51.225+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T13:39:51.225+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T08:09:45.721928+00:00 external trigger: False
[2024-12-14T13:39:51.225+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T13:39:51.226+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:51.226+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 08:09:45.721928+00:00, run_id=manual__2024-12-14T08:09:45.721928+00:00, run_start_date=2024-12-14 08:09:45.721928+00:00, run_end_date=2024-12-14 08:09:51.225436+00:00, run_duration=5.503508, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 08:09:45.721928+00:00, data_interval_end=2024-12-14 08:09:45.721928+00:00, dag_hash=None
[2024-12-14T13:39:51.234+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:39:51.247+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:51.247+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T13:39:51.265+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:39:51.265+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T13:39:51.284+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.699 seconds
[2024-12-14T13:42:38.779+0530] {processor.py:186} INFO - Started process (PID=53339) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:42:38.781+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T13:42:38.783+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:38.782+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:42:38.931+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:38.930+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T13:42:38.944+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:38.944+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 08:12:38.903285+00:00: manual__2024-12-14T08:12:38.903285+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:42:38.979+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:38.979+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T13:42:38.980+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:38.979+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T08:12:38.903285+00:00 [scheduled]>
[2024-12-14T13:42:44.015+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.014+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T13:42:44.163+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:42:44,163] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:12:38.903285+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:12:38.903285+00:00'
[2024-12-14T13:42:44.164+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.163+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:12:38.903285+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:12:38.903285+00:00'
[2024-12-14T13:42:44.176+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:42:44.176+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:42:44.176+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T13:42:44.177+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:42:44.177+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.177+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:42:44.209+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:42:44,209] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:42:44.209+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.209+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:42:44.210+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:42:44,210] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:42:44.210+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.210+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:42:44.219+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:42:44,217] {subprocess.py:99} INFO - Output:
[2024-12-14T13:42:44.221+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.217+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:42:44.222+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:42:44,222] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:42:44.222+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.222+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:42:44.222+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:42:44,222] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:42:44.223+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.222+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:42:44.243+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.242+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:42:44.243+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.243+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T08:12:38.903285+00:00, execution_date=20241214T081238, start_date=, end_date=20241214T081244
[2024-12-14T13:42:44.254+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T13:42:44.254+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T13:42:44.254+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T13:42:44.255+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T13:42:44.255+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.255+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T13:42:44.272+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.272+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T13:42:44.272+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.272+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:12:38.903285+00:00 [scheduled]>
[2024-12-14T13:42:44.299+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:42:44,299] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:12:38.903285+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:12:38.903285+00:00'
[2024-12-14T13:42:44.299+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.299+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:12:38.903285+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:12:38.903285+00:00'
[2024-12-14T13:42:44.300+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:42:44.300+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:42:44.300+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T13:42:44.300+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:42:44.301+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.301+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:42:44.302+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:42:44,302] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:42:44.302+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.302+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:42:44.303+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:42:44,303] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:42:44.303+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.303+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:42:44.313+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:42:44,311] {subprocess.py:99} INFO - Output:
[2024-12-14T13:42:44.314+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.311+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:42:44.354+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:42:44,354] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmptn9zhua5/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:42:44.355+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.354+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmptn9zhua5/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:42:44.359+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:42:44,359] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:42:44.360+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.359+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:42:44.376+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:42:44,366] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:42:44.377+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.366+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:42:44.379+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T13:42:44.379+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 08:12:44.379088+00:00 duration:None
[2024-12-14T13:42:44.380+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 08:12:38.903285+00:00: manual__2024-12-14T08:12:38.903285+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:42:44.380+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:42:44.380+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.380+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T08:12:38.903285+00:00, execution_date=20241214T081238, start_date=, end_date=20241214T081244
[2024-12-14T13:42:44.392+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.392+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:42:44.397+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.392+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:12:38.903285+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:42:44.402+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.401+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 08:12:38.903285+00:00: manual__2024-12-14T08:12:38.903285+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T13:42:44.402+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T13:42:44.402+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T08:12:38.903285+00:00 external trigger: False
[2024-12-14T13:42:44.402+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T13:42:44.403+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.403+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 08:12:38.903285+00:00, run_id=manual__2024-12-14T08:12:38.903285+00:00, run_start_date=2024-12-14 08:12:38.903285+00:00, run_end_date=2024-12-14 08:12:44.402453+00:00, run_duration=5.499168, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 08:12:38.903285+00:00, data_interval_end=2024-12-14 08:12:38.903285+00:00, dag_hash=None
[2024-12-14T13:42:44.412+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:42:44.425+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.425+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T13:42:44.443+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:42:44.443+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T13:42:44.464+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.689 seconds
[2024-12-14T13:45:32.650+0530] {processor.py:186} INFO - Started process (PID=53538) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:45:32.652+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T13:45:32.653+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:32.653+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:45:32.800+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:32.800+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T13:45:32.815+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:32.814+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 08:15:32.771773+00:00: manual__2024-12-14T08:15:32.771773+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:45:32.843+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:32.843+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T13:45:32.844+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:32.844+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T08:15:32.771773+00:00 [scheduled]>
[2024-12-14T13:45:37.872+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:37.872+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T13:45:38.004+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:45:38,004] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:15:32.771773+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:15:32.771773+00:00'
[2024-12-14T13:45:38.005+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.004+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:15:32.771773+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:15:32.771773+00:00'
[2024-12-14T13:45:38.008+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:45:38.008+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:45:38.009+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T13:45:38.009+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:45:38.010+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.009+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:45:38.041+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:45:38,041] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:45:38.042+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.041+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:45:38.042+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:45:38,042] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:45:38.043+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.042+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:45:38.052+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:45:38,050] {subprocess.py:99} INFO - Output:
[2024-12-14T13:45:38.053+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.050+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:45:38.053+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:45:38,053] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:45:38.054+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.053+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:45:38.054+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:45:38,054] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:45:38.054+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.054+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:45:38.075+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.074+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:45:38.075+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.075+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T08:15:32.771773+00:00, execution_date=20241214T081532, start_date=, end_date=20241214T081538
[2024-12-14T13:45:38.085+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T13:45:38.086+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T13:45:38.086+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T13:45:38.086+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T13:45:38.087+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.087+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T13:45:38.104+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.103+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T13:45:38.104+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.104+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:15:32.771773+00:00 [scheduled]>
[2024-12-14T13:45:38.131+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:45:38,131] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:15:32.771773+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:15:32.771773+00:00'
[2024-12-14T13:45:38.132+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.131+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:15:32.771773+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:15:32.771773+00:00'
[2024-12-14T13:45:38.132+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:45:38.132+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:45:38.132+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T13:45:38.133+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:45:38.133+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.133+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:45:38.134+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:45:38,133] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:45:38.134+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.133+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:45:38.134+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:45:38,134] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:45:38.135+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.134+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:45:38.144+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:45:38,143] {subprocess.py:99} INFO - Output:
[2024-12-14T13:45:38.146+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.143+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:45:38.187+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:45:38,186] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpjm66ngd9/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:45:38.187+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.186+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpjm66ngd9/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:45:38.192+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:45:38,192] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:45:38.193+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.192+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:45:38.202+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:45:38,199] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:45:38.202+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.199+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:45:38.204+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T13:45:38.204+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 08:15:38.203717+00:00 duration:None
[2024-12-14T13:45:38.204+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 08:15:32.771773+00:00: manual__2024-12-14T08:15:32.771773+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:45:38.205+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:45:38.205+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.205+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T08:15:32.771773+00:00, execution_date=20241214T081532, start_date=, end_date=20241214T081538
[2024-12-14T13:45:38.217+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.217+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:45:38.220+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.218+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:15:32.771773+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:45:38.225+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.225+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 08:15:32.771773+00:00: manual__2024-12-14T08:15:32.771773+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T13:45:38.225+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T13:45:38.225+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T08:15:32.771773+00:00 external trigger: False
[2024-12-14T13:45:38.226+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T13:45:38.226+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.226+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 08:15:32.771773+00:00, run_id=manual__2024-12-14T08:15:32.771773+00:00, run_start_date=2024-12-14 08:15:32.771773+00:00, run_end_date=2024-12-14 08:15:38.225713+00:00, run_duration=5.45394, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 08:15:32.771773+00:00, data_interval_end=2024-12-14 08:15:32.771773+00:00, dag_hash=None
[2024-12-14T13:45:38.235+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:45:38.247+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.247+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T13:45:38.265+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:45:38.265+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T13:45:38.284+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.637 seconds
[2024-12-14T13:48:26.893+0530] {processor.py:186} INFO - Started process (PID=53745) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:48:26.896+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T13:48:26.897+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:26.897+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:48:27.049+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:27.049+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T13:48:27.063+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:27.062+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 08:18:27.020612+00:00: manual__2024-12-14T08:18:27.020612+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:48:27.099+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:27.099+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T13:48:27.100+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:27.099+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T08:18:27.020612+00:00 [scheduled]>
[2024-12-14T13:48:32.135+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.135+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T13:48:32.279+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:48:32,279] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:18:27.020612+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:18:27.020612+00:00'
[2024-12-14T13:48:32.279+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.279+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:18:27.020612+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:18:27.020612+00:00'
[2024-12-14T13:48:32.292+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:48:32.293+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:48:32.293+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T13:48:32.293+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:48:32.294+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.294+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:48:32.326+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:48:32,325] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:48:32.326+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.325+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:48:32.327+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:48:32,326] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:48:32.327+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.326+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:48:32.336+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:48:32,335] {subprocess.py:99} INFO - Output:
[2024-12-14T13:48:32.338+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.335+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:48:32.339+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:48:32,339] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:48:32.339+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.339+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:48:32.339+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:48:32,339] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:48:32.340+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.339+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:48:32.361+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.361+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:48:32.362+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.362+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T08:18:27.020612+00:00, execution_date=20241214T081827, start_date=, end_date=20241214T081832
[2024-12-14T13:48:32.373+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T13:48:32.373+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T13:48:32.373+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T13:48:32.374+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T13:48:32.374+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.374+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T13:48:32.391+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.391+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T13:48:32.391+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.391+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:18:27.020612+00:00 [scheduled]>
[2024-12-14T13:48:32.421+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:48:32,421] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:18:27.020612+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:18:27.020612+00:00'
[2024-12-14T13:48:32.422+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.421+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:18:27.020612+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:18:27.020612+00:00'
[2024-12-14T13:48:32.422+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:48:32.422+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:48:32.422+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T13:48:32.423+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:48:32.423+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.423+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:48:32.424+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:48:32,424] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:48:32.424+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.424+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:48:32.424+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:48:32,424] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:48:32.425+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.424+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:48:32.436+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:48:32,434] {subprocess.py:99} INFO - Output:
[2024-12-14T13:48:32.437+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.434+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:48:32.477+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:48:32,476] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpxc7he_ks/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:48:32.478+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.476+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpxc7he_ks/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:48:32.482+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:48:32,482] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:48:32.483+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.482+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:48:32.500+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:48:32,489] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:48:32.501+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.489+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:48:32.503+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T13:48:32.504+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 08:18:32.503264+00:00 duration:None
[2024-12-14T13:48:32.504+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 08:18:27.020612+00:00: manual__2024-12-14T08:18:27.020612+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:48:32.504+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:48:32.505+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.504+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T08:18:27.020612+00:00, execution_date=20241214T081827, start_date=, end_date=20241214T081832
[2024-12-14T13:48:32.516+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.516+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:48:32.522+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.517+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:18:27.020612+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:48:32.526+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.526+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 08:18:27.020612+00:00: manual__2024-12-14T08:18:27.020612+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T13:48:32.526+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T13:48:32.527+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T08:18:27.020612+00:00 external trigger: False
[2024-12-14T13:48:32.527+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T13:48:32.527+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.527+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 08:18:27.020612+00:00, run_id=manual__2024-12-14T08:18:27.020612+00:00, run_start_date=2024-12-14 08:18:27.020612+00:00, run_end_date=2024-12-14 08:18:32.526921+00:00, run_duration=5.506309, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 08:18:27.020612+00:00, data_interval_end=2024-12-14 08:18:27.020612+00:00, dag_hash=None
[2024-12-14T13:48:32.537+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:48:32.550+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.550+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T13:48:32.568+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:48:32.568+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T13:48:32.588+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.698 seconds
[2024-12-14T13:51:21.879+0530] {processor.py:186} INFO - Started process (PID=53949) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:51:21.881+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T13:51:21.883+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:21.883+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:51:22.035+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:22.034+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T13:51:22.048+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:22.047+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 08:21:22.006122+00:00: manual__2024-12-14T08:21:22.006122+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:51:22.081+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:22.081+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T13:51:22.082+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:22.082+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T08:21:22.006122+00:00 [scheduled]>
[2024-12-14T13:51:27.109+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.108+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T13:51:27.245+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:51:27,245] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:21:22.006122+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:21:22.006122+00:00'
[2024-12-14T13:51:27.246+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.245+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:21:22.006122+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:21:22.006122+00:00'
[2024-12-14T13:51:27.259+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:51:27.259+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:51:27.260+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T13:51:27.260+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:51:27.261+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.260+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:51:27.291+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:51:27,291] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:51:27.291+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.291+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:51:27.292+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:51:27,292] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:51:27.292+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.292+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:51:27.302+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:51:27,300] {subprocess.py:99} INFO - Output:
[2024-12-14T13:51:27.303+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.300+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:51:27.304+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:51:27,304] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:51:27.305+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.304+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:51:27.305+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:51:27,305] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:51:27.305+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.305+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:51:27.326+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.326+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:51:27.326+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.326+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T08:21:22.006122+00:00, execution_date=20241214T082122, start_date=, end_date=20241214T082127
[2024-12-14T13:51:27.337+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T13:51:27.337+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T13:51:27.337+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T13:51:27.337+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T13:51:27.338+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.338+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T13:51:27.354+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.354+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T13:51:27.355+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.354+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:21:22.006122+00:00 [scheduled]>
[2024-12-14T13:51:27.382+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:51:27,382] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:21:22.006122+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:21:22.006122+00:00'
[2024-12-14T13:51:27.382+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.382+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:21:22.006122+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:21:22.006122+00:00'
[2024-12-14T13:51:27.382+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:51:27.383+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:51:27.383+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T13:51:27.383+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:51:27.383+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.383+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:51:27.384+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:51:27,384] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:51:27.385+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.384+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:51:27.385+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:51:27,385] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:51:27.385+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.385+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:51:27.396+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:51:27,394] {subprocess.py:99} INFO - Output:
[2024-12-14T13:51:27.397+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.394+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:51:27.438+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:51:27,438] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmptp65ackm/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:51:27.439+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.438+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmptp65ackm/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:51:27.444+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:51:27,444] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:51:27.444+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.444+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:51:27.463+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:51:27,452] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:51:27.464+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.452+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:51:27.466+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T13:51:27.466+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 08:21:27.465701+00:00 duration:None
[2024-12-14T13:51:27.467+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 08:21:22.006122+00:00: manual__2024-12-14T08:21:22.006122+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:51:27.467+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:51:27.468+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.467+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T08:21:22.006122+00:00, execution_date=20241214T082122, start_date=, end_date=20241214T082127
[2024-12-14T13:51:27.478+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.478+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:51:27.484+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.478+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:21:22.006122+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:51:27.489+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.488+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 08:21:22.006122+00:00: manual__2024-12-14T08:21:22.006122+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T13:51:27.489+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T13:51:27.489+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T08:21:22.006122+00:00 external trigger: False
[2024-12-14T13:51:27.489+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T13:51:27.490+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.489+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 08:21:22.006122+00:00, run_id=manual__2024-12-14T08:21:22.006122+00:00, run_start_date=2024-12-14 08:21:22.006122+00:00, run_end_date=2024-12-14 08:21:27.489245+00:00, run_duration=5.483123, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 08:21:22.006122+00:00, data_interval_end=2024-12-14 08:21:22.006122+00:00, dag_hash=None
[2024-12-14T13:51:27.499+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:51:27.512+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.512+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T13:51:27.529+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:51:27.529+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T13:51:27.550+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.675 seconds
[2024-12-14T13:54:13.715+0530] {processor.py:186} INFO - Started process (PID=54156) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:54:13.716+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T13:54:13.717+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:13.717+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:54:13.862+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:13.862+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T13:54:13.875+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:13.874+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 08:24:13.832528+00:00: manual__2024-12-14T08:24:13.832528+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:54:13.903+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:13.903+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T13:54:13.903+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:13.903+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T08:24:13.832528+00:00 [scheduled]>
[2024-12-14T13:54:18.939+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:18.938+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T13:54:19.082+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:54:19,081] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:24:13.832528+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:24:13.832528+00:00'
[2024-12-14T13:54:19.082+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.081+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:24:13.832528+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:24:13.832528+00:00'
[2024-12-14T13:54:19.094+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:54:19.094+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:54:19.094+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T13:54:19.095+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:54:19.096+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.095+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:54:19.125+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:54:19,125] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:54:19.125+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.125+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:54:19.126+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:54:19,126] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:54:19.126+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.126+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:54:19.136+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:54:19,134] {subprocess.py:99} INFO - Output:
[2024-12-14T13:54:19.137+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.134+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:54:19.138+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:54:19,138] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:54:19.139+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.138+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:54:19.139+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:54:19,139] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:54:19.139+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.139+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:54:19.159+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.158+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:54:19.159+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.159+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T08:24:13.832528+00:00, execution_date=20241214T082413, start_date=, end_date=20241214T082419
[2024-12-14T13:54:19.170+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T13:54:19.170+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T13:54:19.171+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T13:54:19.171+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T13:54:19.171+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.171+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T13:54:19.190+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.190+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T13:54:19.190+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.190+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:24:13.832528+00:00 [scheduled]>
[2024-12-14T13:54:19.218+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:54:19,218] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:24:13.832528+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:24:13.832528+00:00'
[2024-12-14T13:54:19.219+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.218+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:24:13.832528+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:24:13.832528+00:00'
[2024-12-14T13:54:19.219+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:54:19.220+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:54:19.220+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T13:54:19.220+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:54:19.221+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.221+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:54:19.222+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:54:19,222] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:54:19.222+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.222+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:54:19.223+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:54:19,223] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:54:19.223+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.223+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:54:19.233+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:54:19,232] {subprocess.py:99} INFO - Output:
[2024-12-14T13:54:19.234+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.232+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:54:19.287+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:54:19,286] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpnofo7iqy/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:54:19.287+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.286+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpnofo7iqy/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:54:19.292+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:54:19,292] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:54:19.293+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.292+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:54:19.309+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:54:19,300] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:54:19.310+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.300+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:54:19.312+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T13:54:19.313+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 08:24:19.312123+00:00 duration:None
[2024-12-14T13:54:19.313+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 08:24:13.832528+00:00: manual__2024-12-14T08:24:13.832528+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:54:19.313+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:54:19.314+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.314+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T08:24:13.832528+00:00, execution_date=20241214T082413, start_date=, end_date=20241214T082419
[2024-12-14T13:54:19.331+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.330+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:54:19.337+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.331+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:24:13.832528+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:54:19.342+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.341+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 08:24:13.832528+00:00: manual__2024-12-14T08:24:13.832528+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T13:54:19.342+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T13:54:19.342+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T08:24:13.832528+00:00 external trigger: False
[2024-12-14T13:54:19.342+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T13:54:19.343+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.343+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 08:24:13.832528+00:00, run_id=manual__2024-12-14T08:24:13.832528+00:00, run_start_date=2024-12-14 08:24:13.832528+00:00, run_end_date=2024-12-14 08:24:19.342344+00:00, run_duration=5.509816, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 08:24:13.832528+00:00, data_interval_end=2024-12-14 08:24:13.832528+00:00, dag_hash=None
[2024-12-14T13:54:19.352+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:54:19.366+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.365+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T13:54:19.385+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:54:19.385+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T13:54:19.404+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.690 seconds
[2024-12-14T13:57:07.263+0530] {processor.py:186} INFO - Started process (PID=54360) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:57:07.264+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T13:57:07.266+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:07.265+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:57:07.415+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:07.415+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T13:57:07.430+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:07.429+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 08:27:07.385898+00:00: manual__2024-12-14T08:27:07.385898+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:57:07.459+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:07.458+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T13:57:07.459+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:07.459+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T08:27:07.385898+00:00 [scheduled]>
[2024-12-14T13:57:12.491+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.490+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T13:57:12.633+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:57:12,633] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:27:07.385898+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:27:07.385898+00:00'
[2024-12-14T13:57:12.634+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.633+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:27:07.385898+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:27:07.385898+00:00'
[2024-12-14T13:57:12.646+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:57:12.647+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:57:12.647+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T13:57:12.647+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:57:12.648+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.647+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:57:12.678+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:57:12,678] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:57:12.679+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.678+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:57:12.681+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:57:12,681] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:57:12.682+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.681+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T13:57:12.692+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:57:12,691] {subprocess.py:99} INFO - Output:
[2024-12-14T13:57:12.693+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.691+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:57:12.698+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:57:12,698] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:57:12.699+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.698+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T13:57:12.699+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:57:12,699] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:57:12.700+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.699+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T13:57:12.720+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.720+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:57:12.721+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.720+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T08:27:07.385898+00:00, execution_date=20241214T082707, start_date=, end_date=20241214T082712
[2024-12-14T13:57:12.732+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T13:57:12.732+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T13:57:12.732+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T13:57:12.732+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T13:57:12.733+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.733+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T13:57:12.750+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.749+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T13:57:12.750+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.750+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:27:07.385898+00:00 [scheduled]>
[2024-12-14T13:57:12.779+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:57:12,778] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:27:07.385898+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:27:07.385898+00:00'
[2024-12-14T13:57:12.779+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.778+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:27:07.385898+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:27:07.385898+00:00'
[2024-12-14T13:57:12.779+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T13:57:12.780+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T13:57:12.780+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T13:57:12.781+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T13:57:12.781+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.781+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T13:57:12.782+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:57:12,782] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:57:12.782+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.782+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T13:57:12.783+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:57:12,782] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:57:12.783+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.782+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T13:57:12.792+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:57:12,791] {subprocess.py:99} INFO - Output:
[2024-12-14T13:57:12.794+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.791+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T13:57:12.840+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:57:12,840] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpi33l55wp/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:57:12.841+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.840+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpi33l55wp/controller.py': [Errno 2] No such file or directory
[2024-12-14T13:57:12.845+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:57:12,845] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:57:12.846+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.845+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T13:57:12.859+0530] {logging_mixin.py:190} INFO - [2024-12-14 13:57:12,853] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:57:12.860+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.853+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:57:12.862+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T13:57:12.862+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 08:27:12.861684+00:00 duration:None
[2024-12-14T13:57:12.862+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 08:27:07.385898+00:00: manual__2024-12-14T08:27:07.385898+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T13:57:12.862+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:57:12.863+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.863+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T08:27:07.385898+00:00, execution_date=20241214T082707, start_date=, end_date=20241214T082712
[2024-12-14T13:57:12.874+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.874+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T13:57:12.881+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.875+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:27:07.385898+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T13:57:12.885+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.885+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 08:27:07.385898+00:00: manual__2024-12-14T08:27:07.385898+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T13:57:12.885+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T13:57:12.886+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T08:27:07.385898+00:00 external trigger: False
[2024-12-14T13:57:12.886+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T13:57:12.886+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.886+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 08:27:07.385898+00:00, run_id=manual__2024-12-14T08:27:07.385898+00:00, run_start_date=2024-12-14 08:27:07.385898+00:00, run_end_date=2024-12-14 08:27:12.885923+00:00, run_duration=5.500025, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 08:27:07.385898+00:00, data_interval_end=2024-12-14 08:27:07.385898+00:00, dag_hash=None
[2024-12-14T13:57:12.896+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T13:57:12.910+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.910+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T13:57:12.929+0530] {logging_mixin.py:190} INFO - [2024-12-14T13:57:12.929+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T13:57:12.948+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.688 seconds
[2024-12-14T14:00:00.290+0530] {processor.py:186} INFO - Started process (PID=54566) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:00:00.292+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T14:00:00.294+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:00.294+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:00:00.442+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:00.441+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T14:00:00.456+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:00.455+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 08:30:00.413670+00:00: manual__2024-12-14T08:30:00.413670+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T14:00:00.491+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:00.491+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T14:00:00.492+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:00.491+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T08:30:00.413670+00:00 [scheduled]>
[2024-12-14T14:00:05.522+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.522+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T14:00:05.658+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:00:05,658] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:30:00.413670+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:30:00.413670+00:00'
[2024-12-14T14:00:05.658+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.658+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:30:00.413670+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:30:00.413670+00:00'
[2024-12-14T14:00:05.672+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T14:00:05.672+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T14:00:05.673+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T14:00:05.673+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T14:00:05.673+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.673+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T14:00:05.703+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:00:05,703] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:00:05.703+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.703+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:00:05.704+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:00:05,704] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T14:00:05.704+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.704+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T14:00:05.714+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:00:05,713] {subprocess.py:99} INFO - Output:
[2024-12-14T14:00:05.716+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.713+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T14:00:05.719+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:00:05,719] {subprocess.py:106} INFO - scraping started
[2024-12-14T14:00:05.720+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.719+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T14:00:05.720+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:00:05,720] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T14:00:05.720+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.720+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T14:00:05.739+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.739+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T14:00:05.740+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.740+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T08:30:00.413670+00:00, execution_date=20241214T083000, start_date=, end_date=20241214T083005
[2024-12-14T14:00:05.750+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T14:00:05.751+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T14:00:05.751+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T14:00:05.751+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T14:00:05.752+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.752+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T14:00:05.769+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.769+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T14:00:05.770+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.769+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:30:00.413670+00:00 [scheduled]>
[2024-12-14T14:00:05.796+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:00:05,796] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:30:00.413670+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:30:00.413670+00:00'
[2024-12-14T14:00:05.797+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.796+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:30:00.413670+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:30:00.413670+00:00'
[2024-12-14T14:00:05.797+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T14:00:05.797+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T14:00:05.797+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T14:00:05.797+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T14:00:05.798+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.798+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T14:00:05.798+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:00:05,798] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:00:05.799+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.798+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:00:05.800+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:00:05,799] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T14:00:05.800+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.799+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T14:00:05.809+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:00:05,808] {subprocess.py:99} INFO - Output:
[2024-12-14T14:00:05.812+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.808+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T14:00:05.854+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:00:05,854] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpuxngdamn/controller.py': [Errno 2] No such file or directory
[2024-12-14T14:00:05.854+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.854+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpuxngdamn/controller.py': [Errno 2] No such file or directory
[2024-12-14T14:00:05.859+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:00:05,858] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T14:00:05.859+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.858+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T14:00:05.871+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:00:05,866] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:00:05.872+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.866+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:00:05.874+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T14:00:05.874+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 08:30:05.873840+00:00 duration:None
[2024-12-14T14:00:05.874+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 08:30:00.413670+00:00: manual__2024-12-14T08:30:00.413670+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T14:00:05.875+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:00:05.875+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.875+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T08:30:00.413670+00:00, execution_date=20241214T083000, start_date=, end_date=20241214T083005
[2024-12-14T14:00:05.888+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.887+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T14:00:05.895+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.888+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:30:00.413670+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:00:05.900+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.899+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 08:30:00.413670+00:00: manual__2024-12-14T08:30:00.413670+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T14:00:05.900+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T14:00:05.900+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T08:30:00.413670+00:00 external trigger: False
[2024-12-14T14:00:05.900+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T14:00:05.901+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.900+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 08:30:00.413670+00:00, run_id=manual__2024-12-14T08:30:00.413670+00:00, run_start_date=2024-12-14 08:30:00.413670+00:00, run_end_date=2024-12-14 08:30:05.900305+00:00, run_duration=5.486635, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 08:30:00.413670+00:00, data_interval_end=2024-12-14 08:30:00.413670+00:00, dag_hash=None
[2024-12-14T14:00:05.909+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:00:05.922+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.922+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T14:00:05.941+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:00:05.941+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T14:00:05.962+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.676 seconds
[2024-12-14T14:02:58.386+0530] {processor.py:186} INFO - Started process (PID=54766) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:02:58.390+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T14:02:58.391+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:02:58.391+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:02:58.611+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:02:58.611+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T14:02:58.635+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:02:58.634+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 08:32:58.580336+00:00: manual__2024-12-14T08:32:58.580336+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T14:02:58.669+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:02:58.669+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T14:02:58.670+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:02:58.670+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T08:32:58.580336+00:00 [scheduled]>
[2024-12-14T14:03:03.720+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:03.719+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T14:03:04.348+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:03:04,348] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:32:58.580336+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:32:58.580336+00:00'
[2024-12-14T14:03:04.353+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:04.348+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:32:58.580336+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:32:58.580336+00:00'
[2024-12-14T14:03:04.378+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T14:03:04.378+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T14:03:04.379+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T14:03:04.379+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T14:03:04.380+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:04.379+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T14:03:04.727+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:03:04,727] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:03:04.728+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:04.727+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:03:04.739+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:03:04,739] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T14:03:04.751+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:04.739+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T14:03:04.794+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:03:04,789] {subprocess.py:99} INFO - Output:
[2024-12-14T14:03:04.795+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:04.789+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T14:03:04.797+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:03:04,796] {subprocess.py:106} INFO - scraping started
[2024-12-14T14:03:04.798+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:04.796+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T14:03:04.800+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:03:04,799] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T14:03:04.801+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:04.799+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T14:03:04.842+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:04.842+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T14:03:04.843+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:04.842+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T08:32:58.580336+00:00, execution_date=20241214T083258, start_date=, end_date=20241214T083304
[2024-12-14T14:03:04.863+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T14:03:04.865+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T14:03:04.866+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T14:03:04.867+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T14:03:04.867+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:04.867+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T14:03:04.895+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:04.895+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T14:03:04.896+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:04.895+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:32:58.580336+00:00 [scheduled]>
[2024-12-14T14:03:04.955+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:03:04,955] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:32:58.580336+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:32:58.580336+00:00'
[2024-12-14T14:03:04.956+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:04.955+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:32:58.580336+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:32:58.580336+00:00'
[2024-12-14T14:03:04.957+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T14:03:04.957+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T14:03:04.957+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T14:03:04.958+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T14:03:04.959+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:04.958+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T14:03:04.960+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:03:04,960] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:03:04.961+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:04.960+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:03:04.962+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:03:04,961] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T14:03:04.962+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:04.961+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T14:03:04.994+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:03:04,992] {subprocess.py:99} INFO - Output:
[2024-12-14T14:03:05.000+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:04.992+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T14:03:05.126+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:03:05,126] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmppl_5fda4/controller.py': [Errno 2] No such file or directory
[2024-12-14T14:03:05.127+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:05.126+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmppl_5fda4/controller.py': [Errno 2] No such file or directory
[2024-12-14T14:03:05.133+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:03:05,133] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T14:03:05.134+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:05.133+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T14:03:05.149+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:03:05,141] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:03:05.150+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:05.141+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:03:05.152+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T14:03:05.152+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 08:33:05.151554+00:00 duration:None
[2024-12-14T14:03:05.153+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 08:32:58.580336+00:00: manual__2024-12-14T08:32:58.580336+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T14:03:05.153+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:03:05.154+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:05.153+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T08:32:58.580336+00:00, execution_date=20241214T083258, start_date=, end_date=20241214T083305
[2024-12-14T14:03:05.168+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:05.168+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T14:03:05.175+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:05.169+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:32:58.580336+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:03:05.183+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:05.179+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 08:32:58.580336+00:00: manual__2024-12-14T08:32:58.580336+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T14:03:05.184+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T14:03:05.184+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T08:32:58.580336+00:00 external trigger: False
[2024-12-14T14:03:05.184+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T14:03:05.185+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:05.184+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 08:32:58.580336+00:00, run_id=manual__2024-12-14T08:32:58.580336+00:00, run_start_date=2024-12-14 08:32:58.580336+00:00, run_end_date=2024-12-14 08:33:05.184036+00:00, run_duration=6.6037, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 08:32:58.580336+00:00, data_interval_end=2024-12-14 08:32:58.580336+00:00, dag_hash=None
[2024-12-14T14:03:05.195+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:03:05.223+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:05.222+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T14:03:05.252+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:03:05.251+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T14:03:05.279+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 6.904 seconds
[2024-12-14T14:07:44.215+0530] {processor.py:186} INFO - Started process (PID=55051) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:07:44.218+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T14:07:44.220+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:44.220+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:07:44.428+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:44.427+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T14:07:44.450+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:44.449+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 08:37:44.387230+00:00: manual__2024-12-14T08:37:44.387230+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T14:07:44.493+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:44.492+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T14:07:44.494+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:44.493+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T08:37:44.387230+00:00 [scheduled]>
[2024-12-14T14:07:49.534+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:49.534+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T14:07:49.738+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:07:49,738] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:37:44.387230+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:37:44.387230+00:00'
[2024-12-14T14:07:49.738+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:49.738+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:37:44.387230+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:37:44.387230+00:00'
[2024-12-14T14:07:49.752+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T14:07:49.752+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T14:07:49.753+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T14:07:49.753+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T14:07:49.753+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:49.753+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T14:07:49.795+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:07:49,795] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:07:49.796+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:49.795+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:07:49.797+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:07:49,796] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T14:07:49.798+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:49.796+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T14:07:49.809+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:07:49,807] {subprocess.py:99} INFO - Output:
[2024-12-14T14:07:49.811+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:49.807+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T14:07:49.812+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:07:49,812] {subprocess.py:106} INFO - scraping started
[2024-12-14T14:07:49.812+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:49.812+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T14:07:49.813+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:07:49,812] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T14:07:49.813+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:49.812+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T14:07:49.846+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:49.846+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T14:07:49.847+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:49.846+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T08:37:44.387230+00:00, execution_date=20241214T083744, start_date=, end_date=20241214T083749
[2024-12-14T14:07:49.860+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T14:07:49.860+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T14:07:49.860+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T14:07:49.861+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T14:07:49.861+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:49.861+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T14:07:49.885+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:49.885+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T14:07:49.886+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:49.885+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:37:44.387230+00:00 [scheduled]>
[2024-12-14T14:07:49.926+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:07:49,925] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:37:44.387230+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:37:44.387230+00:00'
[2024-12-14T14:07:49.926+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:49.925+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:37:44.387230+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:37:44.387230+00:00'
[2024-12-14T14:07:49.926+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T14:07:49.926+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T14:07:49.927+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T14:07:49.927+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T14:07:49.927+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:49.927+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T14:07:49.928+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:07:49,928] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:07:49.928+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:49.928+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:07:49.929+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:07:49,929] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T14:07:49.929+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:49.929+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T14:07:49.942+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:07:49,937] {subprocess.py:99} INFO - Output:
[2024-12-14T14:07:49.944+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:49.937+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T14:07:50.011+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:07:50,011] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpffxaa6n1/controller.py': [Errno 2] No such file or directory
[2024-12-14T14:07:50.012+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:50.011+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpffxaa6n1/controller.py': [Errno 2] No such file or directory
[2024-12-14T14:07:50.017+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:07:50,017] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T14:07:50.017+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:50.017+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T14:07:50.037+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:07:50,032] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:07:50.038+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:50.032+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:07:50.046+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T14:07:50.047+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 08:37:50.046192+00:00 duration:None
[2024-12-14T14:07:50.047+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 08:37:44.387230+00:00: manual__2024-12-14T08:37:44.387230+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T14:07:50.047+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:07:50.048+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:50.048+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T08:37:44.387230+00:00, execution_date=20241214T083744, start_date=, end_date=20241214T083750
[2024-12-14T14:07:50.065+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:50.065+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T14:07:50.071+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:50.066+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:37:44.387230+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:07:50.085+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:50.084+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 08:37:44.387230+00:00: manual__2024-12-14T08:37:44.387230+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T14:07:50.085+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T14:07:50.085+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T08:37:44.387230+00:00 external trigger: False
[2024-12-14T14:07:50.085+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T14:07:50.086+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:50.086+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 08:37:44.387230+00:00, run_id=manual__2024-12-14T08:37:44.387230+00:00, run_start_date=2024-12-14 08:37:44.387230+00:00, run_end_date=2024-12-14 08:37:50.085341+00:00, run_duration=5.698111, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 08:37:44.387230+00:00, data_interval_end=2024-12-14 08:37:44.387230+00:00, dag_hash=None
[2024-12-14T14:07:50.096+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:07:50.114+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:50.114+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T14:07:50.147+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:07:50.146+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T14:07:50.201+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.989 seconds
[2024-12-14T14:11:55.025+0530] {processor.py:186} INFO - Started process (PID=55307) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:11:55.028+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T14:11:55.029+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:11:55.029+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:11:55.280+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:11:55.279+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T14:11:55.303+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:11:55.300+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 08:41:55.230438+00:00: manual__2024-12-14T08:41:55.230438+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T14:11:55.349+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:11:55.349+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T14:11:55.349+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:11:55.349+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T08:41:55.230438+00:00 [scheduled]>
[2024-12-14T14:12:00.389+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:00.389+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T14:12:00.605+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:12:00,605] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:41:55.230438+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:41:55.230438+00:00'
[2024-12-14T14:12:00.606+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:00.605+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:41:55.230438+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:41:55.230438+00:00'
[2024-12-14T14:12:00.622+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T14:12:00.622+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T14:12:00.623+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T14:12:00.623+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T14:12:00.624+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:00.623+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T14:12:00.724+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:12:00,723] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:12:00.724+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:00.723+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:12:00.725+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:12:00,725] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T14:12:00.725+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:00.725+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T14:12:00.745+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:12:00,743] {subprocess.py:99} INFO - Output:
[2024-12-14T14:12:00.747+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:00.743+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T14:12:00.760+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:12:00,760] {subprocess.py:106} INFO - scraping started
[2024-12-14T14:12:00.761+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:00.760+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T14:12:00.761+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:12:00,761] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T14:12:00.761+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:00.761+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T14:12:00.791+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:00.790+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T14:12:00.794+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:00.794+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T08:41:55.230438+00:00, execution_date=20241214T084155, start_date=, end_date=20241214T084200
[2024-12-14T14:12:00.807+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T14:12:00.807+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T14:12:00.808+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T14:12:00.808+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T14:12:00.808+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:00.808+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T14:12:00.831+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:00.831+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T14:12:00.832+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:00.831+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:41:55.230438+00:00 [scheduled]>
[2024-12-14T14:12:00.891+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:12:00,891] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:41:55.230438+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:41:55.230438+00:00'
[2024-12-14T14:12:00.893+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:00.891+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:41:55.230438+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:41:55.230438+00:00'
[2024-12-14T14:12:00.893+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T14:12:00.894+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T14:12:00.894+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T14:12:00.895+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T14:12:00.896+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:00.895+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T14:12:00.897+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:12:00,897] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:12:00.897+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:00.897+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:12:00.898+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:12:00,898] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T14:12:00.898+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:00.898+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T14:12:00.916+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:12:00,914] {subprocess.py:99} INFO - Output:
[2024-12-14T14:12:00.920+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:00.914+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T14:12:01.031+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:12:01,031] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp3mp87yy3/controller.py': [Errno 2] No such file or directory
[2024-12-14T14:12:01.032+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:01.031+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp3mp87yy3/controller.py': [Errno 2] No such file or directory
[2024-12-14T14:12:01.046+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:12:01,046] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T14:12:01.047+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:01.046+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T14:12:01.062+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:12:01,057] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:12:01.063+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:01.057+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:12:01.065+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T14:12:01.066+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 08:42:01.064561+00:00 duration:None
[2024-12-14T14:12:01.066+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 08:41:55.230438+00:00: manual__2024-12-14T08:41:55.230438+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T14:12:01.066+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:12:01.066+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:01.066+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T08:41:55.230438+00:00, execution_date=20241214T084155, start_date=, end_date=20241214T084201
[2024-12-14T14:12:01.083+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:01.082+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T14:12:01.096+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:01.084+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:41:55.230438+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:12:01.104+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:01.103+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 08:41:55.230438+00:00: manual__2024-12-14T08:41:55.230438+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T14:12:01.104+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T14:12:01.104+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T08:41:55.230438+00:00 external trigger: False
[2024-12-14T14:12:01.104+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T14:12:01.105+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:01.105+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 08:41:55.230438+00:00, run_id=manual__2024-12-14T08:41:55.230438+00:00, run_start_date=2024-12-14 08:41:55.230438+00:00, run_end_date=2024-12-14 08:42:01.104281+00:00, run_duration=5.873843, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 08:41:55.230438+00:00, data_interval_end=2024-12-14 08:41:55.230438+00:00, dag_hash=None
[2024-12-14T14:12:01.115+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:12:01.143+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:01.143+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T14:12:01.170+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:12:01.170+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T14:12:01.197+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 6.181 seconds
[2024-12-14T14:15:59.926+0530] {processor.py:186} INFO - Started process (PID=55553) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:15:59.929+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T14:15:59.931+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:15:59.930+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:16:00.097+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:00.097+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T14:16:00.112+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:00.112+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 08:46:00.065947+00:00: manual__2024-12-14T08:46:00.065947+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T14:16:00.148+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:00.148+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T14:16:00.149+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:00.148+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T08:46:00.065947+00:00 [scheduled]>
[2024-12-14T14:16:05.178+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.177+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T14:16:05.324+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:16:05,324] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:46:00.065947+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:46:00.065947+00:00'
[2024-12-14T14:16:05.325+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.324+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:46:00.065947+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:46:00.065947+00:00'
[2024-12-14T14:16:05.339+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T14:16:05.339+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T14:16:05.339+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T14:16:05.340+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T14:16:05.340+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.340+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T14:16:05.373+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:16:05,373] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:16:05.373+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.373+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:16:05.374+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:16:05,374] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T14:16:05.374+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.374+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T14:16:05.383+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:16:05,381] {subprocess.py:99} INFO - Output:
[2024-12-14T14:16:05.385+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.381+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T14:16:05.388+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:16:05,387] {subprocess.py:106} INFO - scraping started
[2024-12-14T14:16:05.388+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.387+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T14:16:05.388+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:16:05,388] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T14:16:05.389+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.388+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T14:16:05.409+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.409+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T14:16:05.410+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.410+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T08:46:00.065947+00:00, execution_date=20241214T084600, start_date=, end_date=20241214T084605
[2024-12-14T14:16:05.420+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T14:16:05.421+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T14:16:05.421+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T14:16:05.421+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T14:16:05.422+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.422+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T14:16:05.439+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.439+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T14:16:05.440+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.439+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:46:00.065947+00:00 [scheduled]>
[2024-12-14T14:16:05.472+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:16:05,472] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:46:00.065947+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:46:00.065947+00:00'
[2024-12-14T14:16:05.472+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.472+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:46:00.065947+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:46:00.065947+00:00'
[2024-12-14T14:16:05.473+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T14:16:05.473+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T14:16:05.473+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T14:16:05.473+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T14:16:05.474+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.473+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T14:16:05.474+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:16:05,474] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:16:05.475+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.474+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:16:05.475+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:16:05,475] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T14:16:05.476+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.475+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T14:16:05.485+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:16:05,482] {subprocess.py:99} INFO - Output:
[2024-12-14T14:16:05.487+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.482+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T14:16:05.529+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:16:05,529] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpzf0_r0nq/controller.py': [Errno 2] No such file or directory
[2024-12-14T14:16:05.529+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.529+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpzf0_r0nq/controller.py': [Errno 2] No such file or directory
[2024-12-14T14:16:05.534+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:16:05,533] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T14:16:05.534+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.533+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T14:16:05.548+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:16:05,541] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:16:05.548+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.541+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:16:05.550+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T14:16:05.551+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 08:46:05.550309+00:00 duration:None
[2024-12-14T14:16:05.551+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 08:46:00.065947+00:00: manual__2024-12-14T08:46:00.065947+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T14:16:05.551+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:16:05.552+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.551+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T08:46:00.065947+00:00, execution_date=20241214T084600, start_date=, end_date=20241214T084605
[2024-12-14T14:16:05.564+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.564+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T14:16:05.575+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.564+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:46:00.065947+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:16:05.580+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.579+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 08:46:00.065947+00:00: manual__2024-12-14T08:46:00.065947+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T14:16:05.580+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T14:16:05.580+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T08:46:00.065947+00:00 external trigger: False
[2024-12-14T14:16:05.580+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T14:16:05.581+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.581+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 08:46:00.065947+00:00, run_id=manual__2024-12-14T08:46:00.065947+00:00, run_start_date=2024-12-14 08:46:00.065947+00:00, run_end_date=2024-12-14 08:46:05.580460+00:00, run_duration=5.514513, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 08:46:00.065947+00:00, data_interval_end=2024-12-14 08:46:00.065947+00:00, dag_hash=None
[2024-12-14T14:16:05.591+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:16:05.605+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.605+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T14:16:05.626+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:16:05.626+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T14:16:05.646+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.723 seconds
[2024-12-14T14:19:06.261+0530] {processor.py:186} INFO - Started process (PID=55752) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:19:06.263+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T14:19:06.265+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:06.265+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:19:06.425+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:06.424+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T14:19:06.439+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:06.439+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 08:49:06.393061+00:00: manual__2024-12-14T08:49:06.393061+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T14:19:06.476+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:06.476+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T14:19:06.477+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:06.477+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T08:49:06.393061+00:00 [scheduled]>
[2024-12-14T14:19:11.505+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.505+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T14:19:11.648+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:19:11,648] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:49:06.393061+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:49:06.393061+00:00'
[2024-12-14T14:19:11.649+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.648+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:49:06.393061+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:49:06.393061+00:00'
[2024-12-14T14:19:11.663+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T14:19:11.663+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T14:19:11.663+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T14:19:11.664+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T14:19:11.664+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.664+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T14:19:11.695+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:19:11,695] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:19:11.696+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.695+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:19:11.697+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:19:11,696] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T14:19:11.697+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.696+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T14:19:11.706+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:19:11,705] {subprocess.py:99} INFO - Output:
[2024-12-14T14:19:11.708+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.705+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T14:19:11.710+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:19:11,709] {subprocess.py:106} INFO - scraping started
[2024-12-14T14:19:11.710+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.709+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T14:19:11.710+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:19:11,710] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T14:19:11.711+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.710+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T14:19:11.731+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.731+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T14:19:11.732+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.731+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T08:49:06.393061+00:00, execution_date=20241214T084906, start_date=, end_date=20241214T084911
[2024-12-14T14:19:11.743+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T14:19:11.743+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T14:19:11.744+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T14:19:11.744+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T14:19:11.744+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.744+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T14:19:11.761+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.761+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T14:19:11.762+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.761+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:49:06.393061+00:00 [scheduled]>
[2024-12-14T14:19:11.792+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:19:11,791] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:49:06.393061+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:49:06.393061+00:00'
[2024-12-14T14:19:11.792+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.791+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:49:06.393061+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:49:06.393061+00:00'
[2024-12-14T14:19:11.793+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T14:19:11.793+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T14:19:11.793+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T14:19:11.793+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T14:19:11.794+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.793+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T14:19:11.794+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:19:11,794] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:19:11.795+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.794+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:19:11.795+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:19:11,795] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T14:19:11.796+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.795+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T14:19:11.806+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:19:11,804] {subprocess.py:99} INFO - Output:
[2024-12-14T14:19:11.807+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.804+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T14:19:11.849+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:19:11,849] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpogpzym4s/controller.py': [Errno 2] No such file or directory
[2024-12-14T14:19:11.850+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.849+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpogpzym4s/controller.py': [Errno 2] No such file or directory
[2024-12-14T14:19:11.855+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:19:11,855] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T14:19:11.856+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.855+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T14:19:11.874+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:19:11,862] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:19:11.874+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.862+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:19:11.876+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T14:19:11.877+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 08:49:11.876362+00:00 duration:None
[2024-12-14T14:19:11.877+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 08:49:06.393061+00:00: manual__2024-12-14T08:49:06.393061+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T14:19:11.877+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:19:11.878+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.877+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T08:49:06.393061+00:00, execution_date=20241214T084906, start_date=, end_date=20241214T084911
[2024-12-14T14:19:11.889+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.889+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T14:19:11.895+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.889+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:49:06.393061+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:19:11.900+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.899+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 08:49:06.393061+00:00: manual__2024-12-14T08:49:06.393061+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T14:19:11.900+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T14:19:11.900+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T08:49:06.393061+00:00 external trigger: False
[2024-12-14T14:19:11.900+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T14:19:11.901+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.900+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 08:49:06.393061+00:00, run_id=manual__2024-12-14T08:49:06.393061+00:00, run_start_date=2024-12-14 08:49:06.393061+00:00, run_end_date=2024-12-14 08:49:11.900319+00:00, run_duration=5.507258, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 08:49:06.393061+00:00, data_interval_end=2024-12-14 08:49:06.393061+00:00, dag_hash=None
[2024-12-14T14:19:11.910+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:19:11.924+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.923+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T14:19:11.945+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:19:11.944+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T14:19:11.965+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.708 seconds
[2024-12-14T14:22:12.170+0530] {processor.py:186} INFO - Started process (PID=55972) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:22:12.171+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T14:22:12.173+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:12.173+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:22:12.327+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:12.327+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T14:22:12.343+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:12.342+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 08:52:12.296852+00:00: manual__2024-12-14T08:52:12.296852+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T14:22:12.378+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:12.378+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T14:22:12.379+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:12.378+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T08:52:12.296852+00:00 [scheduled]>
[2024-12-14T14:22:17.401+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.401+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T14:22:17.547+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:22:17,547] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:52:12.296852+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:52:12.296852+00:00'
[2024-12-14T14:22:17.548+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.547+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:52:12.296852+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:52:12.296852+00:00'
[2024-12-14T14:22:17.561+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T14:22:17.561+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T14:22:17.562+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T14:22:17.562+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T14:22:17.563+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.562+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T14:22:17.594+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:22:17,594] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:22:17.595+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.594+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:22:17.595+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:22:17,595] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T14:22:17.596+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.595+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T14:22:17.606+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:22:17,603] {subprocess.py:99} INFO - Output:
[2024-12-14T14:22:17.607+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.603+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T14:22:17.612+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:22:17,612] {subprocess.py:106} INFO - scraping started
[2024-12-14T14:22:17.613+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.612+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T14:22:17.613+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:22:17,613] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T14:22:17.613+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.613+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T14:22:17.634+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.634+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T14:22:17.635+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.635+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T08:52:12.296852+00:00, execution_date=20241214T085212, start_date=, end_date=20241214T085217
[2024-12-14T14:22:17.646+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T14:22:17.647+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T14:22:17.647+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T14:22:17.647+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T14:22:17.647+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.647+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T14:22:17.666+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.666+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T14:22:17.666+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.666+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:52:12.296852+00:00 [scheduled]>
[2024-12-14T14:22:17.698+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:22:17,698] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:52:12.296852+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:52:12.296852+00:00'
[2024-12-14T14:22:17.698+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.698+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:52:12.296852+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:52:12.296852+00:00'
[2024-12-14T14:22:17.698+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T14:22:17.699+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T14:22:17.699+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T14:22:17.699+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T14:22:17.699+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.699+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T14:22:17.700+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:22:17,700] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:22:17.700+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.700+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:22:17.701+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:22:17,701] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T14:22:17.701+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.701+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T14:22:17.711+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:22:17,709] {subprocess.py:99} INFO - Output:
[2024-12-14T14:22:17.712+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.709+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T14:22:17.756+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:22:17,756] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpmzrnv3tt/controller.py': [Errno 2] No such file or directory
[2024-12-14T14:22:17.757+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.756+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpmzrnv3tt/controller.py': [Errno 2] No such file or directory
[2024-12-14T14:22:17.761+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:22:17,761] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T14:22:17.762+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.761+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T14:22:17.778+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:22:17,769] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:22:17.779+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.769+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:22:17.781+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T14:22:17.781+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 08:52:17.780588+00:00 duration:None
[2024-12-14T14:22:17.781+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 08:52:12.296852+00:00: manual__2024-12-14T08:52:12.296852+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T14:22:17.781+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:22:17.782+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.782+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T08:52:12.296852+00:00, execution_date=20241214T085212, start_date=, end_date=20241214T085217
[2024-12-14T14:22:17.813+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.812+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T14:22:17.821+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.814+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:52:12.296852+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:22:17.828+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.828+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 08:52:12.296852+00:00: manual__2024-12-14T08:52:12.296852+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T14:22:17.829+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T14:22:17.829+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T08:52:12.296852+00:00 external trigger: False
[2024-12-14T14:22:17.829+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T14:22:17.829+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.829+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 08:52:12.296852+00:00, run_id=manual__2024-12-14T08:52:12.296852+00:00, run_start_date=2024-12-14 08:52:12.296852+00:00, run_end_date=2024-12-14 08:52:17.828943+00:00, run_duration=5.532091, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 08:52:12.296852+00:00, data_interval_end=2024-12-14 08:52:12.296852+00:00, dag_hash=None
[2024-12-14T14:22:17.842+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:22:17.861+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.860+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T14:22:17.885+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:22:17.885+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T14:22:17.923+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.757 seconds
[2024-12-14T14:25:40.743+0530] {processor.py:186} INFO - Started process (PID=56188) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:25:40.746+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T14:25:40.752+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:40.751+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:25:40.961+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:40.961+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T14:25:40.987+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:40.987+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 08:55:40.924445+00:00: manual__2024-12-14T08:55:40.924445+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T14:25:41.029+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:41.028+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T14:25:41.030+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:41.029+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T08:55:40.924445+00:00 [scheduled]>
[2024-12-14T14:25:46.056+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:46.056+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T14:25:46.357+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:25:46,357] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:55:40.924445+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:55:40.924445+00:00'
[2024-12-14T14:25:46.358+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:46.357+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:55:40.924445+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:55:40.924445+00:00'
[2024-12-14T14:25:46.369+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T14:25:46.369+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T14:25:46.370+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T14:25:46.370+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T14:25:46.370+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:46.370+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T14:25:46.495+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:25:46,495] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:25:46.496+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:46.495+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:25:46.502+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:25:46,501] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T14:25:46.507+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:46.501+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T14:25:46.710+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:25:46,707] {subprocess.py:99} INFO - Output:
[2024-12-14T14:25:46.713+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:46.707+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T14:25:46.718+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:25:46,718] {subprocess.py:106} INFO - scraping started
[2024-12-14T14:25:46.719+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:46.718+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T14:25:46.719+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:25:46,719] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T14:25:46.720+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:46.719+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T14:25:46.790+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:46.789+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T14:25:46.791+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:46.790+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T08:55:40.924445+00:00, execution_date=20241214T085540, start_date=, end_date=20241214T085546
[2024-12-14T14:25:46.812+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T14:25:46.813+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T14:25:46.814+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T14:25:46.814+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T14:25:46.816+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:46.815+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T14:25:46.843+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:46.842+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T14:25:46.844+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:46.844+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:55:40.924445+00:00 [scheduled]>
[2024-12-14T14:25:46.953+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:25:46,953] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:55:40.924445+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:55:40.924445+00:00'
[2024-12-14T14:25:46.954+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:46.953+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:55:40.924445+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:55:40.924445+00:00'
[2024-12-14T14:25:46.954+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T14:25:46.954+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T14:25:46.955+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T14:25:46.956+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T14:25:46.957+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:46.957+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T14:25:46.958+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:25:46,958] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:25:46.959+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:46.958+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:25:46.959+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:25:46,959] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T14:25:46.960+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:46.959+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T14:25:46.976+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:25:46,974] {subprocess.py:99} INFO - Output:
[2024-12-14T14:25:46.979+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:46.974+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T14:25:47.037+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:25:47,036] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmppf5sbtek/controller.py': [Errno 2] No such file or directory
[2024-12-14T14:25:47.038+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:47.036+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmppf5sbtek/controller.py': [Errno 2] No such file or directory
[2024-12-14T14:25:47.042+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:25:47,042] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T14:25:47.043+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:47.042+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T14:25:47.059+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:25:47,053] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:25:47.059+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:47.053+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:25:47.062+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T14:25:47.063+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 08:55:47.062216+00:00 duration:None
[2024-12-14T14:25:47.064+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 08:55:40.924445+00:00: manual__2024-12-14T08:55:40.924445+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T14:25:47.065+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:25:47.066+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:47.065+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T08:55:40.924445+00:00, execution_date=20241214T085540, start_date=, end_date=20241214T085547
[2024-12-14T14:25:47.078+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:47.078+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T14:25:47.089+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:47.078+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:55:40.924445+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:25:47.094+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:47.094+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 08:55:40.924445+00:00: manual__2024-12-14T08:55:40.924445+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T14:25:47.094+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T14:25:47.095+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T08:55:40.924445+00:00 external trigger: False
[2024-12-14T14:25:47.095+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T14:25:47.095+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:47.095+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 08:55:40.924445+00:00, run_id=manual__2024-12-14T08:55:40.924445+00:00, run_start_date=2024-12-14 08:55:40.924445+00:00, run_end_date=2024-12-14 08:55:47.094811+00:00, run_duration=6.170366, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 08:55:40.924445+00:00, data_interval_end=2024-12-14 08:55:40.924445+00:00, dag_hash=None
[2024-12-14T14:25:47.114+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:25:47.129+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:47.128+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T14:25:47.160+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:25:47.160+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T14:25:47.191+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 6.452 seconds
[2024-12-14T14:29:55.865+0530] {processor.py:186} INFO - Started process (PID=56456) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:29:55.868+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T14:29:55.870+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:29:55.869+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:29:56.086+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:29:56.085+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T14:29:56.109+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:29:56.104+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 08:59:56.045385+00:00: manual__2024-12-14T08:59:56.045385+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T14:29:56.153+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:29:56.153+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T14:29:56.154+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:29:56.153+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T08:59:56.045385+00:00 [scheduled]>
[2024-12-14T14:30:01.196+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:01.195+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T14:30:01.425+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:30:01,425] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:59:56.045385+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:59:56.045385+00:00'
[2024-12-14T14:30:01.426+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:01.425+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:59:56.045385+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:59:56.045385+00:00'
[2024-12-14T14:30:01.438+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T14:30:01.452+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T14:30:01.454+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T14:30:01.455+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T14:30:01.460+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:01.459+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T14:30:01.767+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:30:01,766] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:30:01.768+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:01.766+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:30:01.770+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:30:01,769] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T14:30:01.770+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:01.769+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T14:30:01.793+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:30:01,791] {subprocess.py:99} INFO - Output:
[2024-12-14T14:30:01.794+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:01.791+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T14:30:01.797+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:30:01,797] {subprocess.py:106} INFO - scraping started
[2024-12-14T14:30:01.798+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:01.797+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T14:30:01.798+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:30:01,798] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T14:30:01.799+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:01.798+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T14:30:01.852+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:01.852+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T14:30:01.853+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:01.853+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T08:59:56.045385+00:00, execution_date=20241214T085956, start_date=, end_date=20241214T090001
[2024-12-14T14:30:01.878+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T14:30:01.878+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T14:30:01.879+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T14:30:01.880+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T14:30:01.881+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:01.881+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T14:30:01.961+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:01.961+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T14:30:01.963+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:01.962+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:59:56.045385+00:00 [scheduled]>
[2024-12-14T14:30:02.065+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:30:02,065] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:59:56.045385+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:59:56.045385+00:00'
[2024-12-14T14:30:02.066+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:02.065+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T08:59:56.045385+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T08:59:56.045385+00:00'
[2024-12-14T14:30:02.066+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T14:30:02.066+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T14:30:02.067+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T14:30:02.067+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T14:30:02.067+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:02.067+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T14:30:02.069+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:30:02,069] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:30:02.070+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:02.069+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:30:02.070+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:30:02,070] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T14:30:02.071+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:02.070+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T14:30:02.086+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:30:02,084] {subprocess.py:99} INFO - Output:
[2024-12-14T14:30:02.088+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:02.084+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T14:30:02.150+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:30:02,150] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpoz04x9xc/controller.py': [Errno 2] No such file or directory
[2024-12-14T14:30:02.151+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:02.150+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpoz04x9xc/controller.py': [Errno 2] No such file or directory
[2024-12-14T14:30:02.157+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:30:02,156] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T14:30:02.158+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:02.156+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T14:30:02.179+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:30:02,169] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:30:02.180+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:02.169+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:30:02.182+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T14:30:02.182+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 09:00:02.181908+00:00 duration:None
[2024-12-14T14:30:02.183+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 08:59:56.045385+00:00: manual__2024-12-14T08:59:56.045385+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T14:30:02.183+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:30:02.183+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:02.183+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T08:59:56.045385+00:00, execution_date=20241214T085956, start_date=, end_date=20241214T090002
[2024-12-14T14:30:02.203+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:02.203+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T14:30:02.212+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:02.204+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T08:59:56.045385+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:30:02.218+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:02.218+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 08:59:56.045385+00:00: manual__2024-12-14T08:59:56.045385+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T14:30:02.218+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T14:30:02.219+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T08:59:56.045385+00:00 external trigger: False
[2024-12-14T14:30:02.219+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T14:30:02.220+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:02.219+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 08:59:56.045385+00:00, run_id=manual__2024-12-14T08:59:56.045385+00:00, run_start_date=2024-12-14 08:59:56.045385+00:00, run_end_date=2024-12-14 09:00:02.218739+00:00, run_duration=6.173354, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 08:59:56.045385+00:00, data_interval_end=2024-12-14 08:59:56.045385+00:00, dag_hash=None
[2024-12-14T14:30:02.234+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:30:02.253+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:02.253+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T14:30:02.287+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:30:02.286+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T14:30:02.318+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 6.464 seconds
[2024-12-14T14:34:17.870+0530] {processor.py:186} INFO - Started process (PID=56710) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:34:17.873+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T14:34:17.874+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:17.874+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:34:18.105+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:18.104+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T14:34:18.124+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:18.123+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 09:04:18.061500+00:00: manual__2024-12-14T09:04:18.061500+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T14:34:18.167+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:18.167+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T14:34:18.170+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:18.168+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T09:04:18.061500+00:00 [scheduled]>
[2024-12-14T14:34:23.207+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.206+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T14:34:23.438+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:34:23,438] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T09:04:18.061500+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T09:04:18.061500+00:00'
[2024-12-14T14:34:23.438+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.438+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T09:04:18.061500+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T09:04:18.061500+00:00'
[2024-12-14T14:34:23.444+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T14:34:23.444+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T14:34:23.445+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T14:34:23.445+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T14:34:23.446+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.445+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T14:34:23.494+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:34:23,493] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:34:23.494+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.493+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:34:23.495+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:34:23,495] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T14:34:23.495+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.495+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T14:34:23.519+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:34:23,511] {subprocess.py:99} INFO - Output:
[2024-12-14T14:34:23.520+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.511+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T14:34:23.526+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:34:23,526] {subprocess.py:106} INFO - scraping started
[2024-12-14T14:34:23.526+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.526+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T14:34:23.527+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:34:23,527] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T14:34:23.527+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.527+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T14:34:23.567+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.566+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T14:34:23.568+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.568+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T09:04:18.061500+00:00, execution_date=20241214T090418, start_date=, end_date=20241214T090423
[2024-12-14T14:34:23.584+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T14:34:23.585+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T14:34:23.585+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T14:34:23.586+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T14:34:23.587+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.587+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T14:34:23.609+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.609+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T14:34:23.609+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.609+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T09:04:18.061500+00:00 [scheduled]>
[2024-12-14T14:34:23.656+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:34:23,656] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T09:04:18.061500+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T09:04:18.061500+00:00'
[2024-12-14T14:34:23.657+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.656+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T09:04:18.061500+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T09:04:18.061500+00:00'
[2024-12-14T14:34:23.657+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T14:34:23.657+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T14:34:23.657+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T14:34:23.657+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T14:34:23.658+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.658+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T14:34:23.658+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:34:23,658] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:34:23.659+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.658+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T14:34:23.659+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:34:23,659] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T14:34:23.660+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.659+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T14:34:23.677+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:34:23,675] {subprocess.py:99} INFO - Output:
[2024-12-14T14:34:23.680+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.675+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T14:34:23.756+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:34:23,755] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp2qaa54_m/controller.py': [Errno 2] No such file or directory
[2024-12-14T14:34:23.757+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.755+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp2qaa54_m/controller.py': [Errno 2] No such file or directory
[2024-12-14T14:34:23.761+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:34:23,761] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T14:34:23.761+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.761+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T14:34:23.785+0530] {logging_mixin.py:190} INFO - [2024-12-14 14:34:23,774] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:34:23.786+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.774+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:34:23.788+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T14:34:23.788+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 09:04:23.788007+00:00 duration:None
[2024-12-14T14:34:23.789+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 09:04:18.061500+00:00: manual__2024-12-14T09:04:18.061500+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T14:34:23.789+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:34:23.789+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.789+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T09:04:18.061500+00:00, execution_date=20241214T090418, start_date=, end_date=20241214T090423
[2024-12-14T14:34:23.810+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.810+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T14:34:23.822+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.811+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T09:04:18.061500+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T14:34:23.827+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.827+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 09:04:18.061500+00:00: manual__2024-12-14T09:04:18.061500+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T14:34:23.828+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T14:34:23.828+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T09:04:18.061500+00:00 external trigger: False
[2024-12-14T14:34:23.828+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T14:34:23.829+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.828+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 09:04:18.061500+00:00, run_id=manual__2024-12-14T09:04:18.061500+00:00, run_start_date=2024-12-14 09:04:18.061500+00:00, run_end_date=2024-12-14 09:04:23.828068+00:00, run_duration=5.766568, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 09:04:18.061500+00:00, data_interval_end=2024-12-14 09:04:18.061500+00:00, dag_hash=None
[2024-12-14T14:34:23.845+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T14:34:23.871+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.871+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T14:34:23.901+0530] {logging_mixin.py:190} INFO - [2024-12-14T14:34:23.901+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T14:34:23.928+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 6.068 seconds
[2024-12-14T18:39:05.630+0530] {processor.py:186} INFO - Started process (PID=1458) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T18:39:05.633+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T18:39:05.634+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:05.634+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T18:39:05.821+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:05.820+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T18:39:05.845+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:05.845+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 13:09:05.761617+00:00: manual__2024-12-14T13:09:05.761617+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T18:39:05.904+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:05.903+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T18:39:05.905+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:05.904+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T13:09:05.761617+00:00 [scheduled]>
[2024-12-14T18:39:11.011+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:11.010+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T18:39:11.678+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:39:11,678] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:09:05.761617+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:09:05.761617+00:00'
[2024-12-14T18:39:11.680+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:11.678+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:09:05.761617+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:09:05.761617+00:00'
[2024-12-14T18:39:11.694+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T18:39:11.694+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T18:39:11.695+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T18:39:11.695+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T18:39:11.696+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:11.695+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T18:39:11.837+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:39:11,836] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T18:39:11.841+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:11.836+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T18:39:11.842+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:39:11,842] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T18:39:11.845+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:11.842+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T18:39:11.882+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:39:11,876] {subprocess.py:99} INFO - Output:
[2024-12-14T18:39:11.884+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:11.876+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T18:39:11.884+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:39:11,884] {subprocess.py:106} INFO - scraping started
[2024-12-14T18:39:11.885+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:11.884+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T18:39:11.899+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:39:11,898] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T18:39:11.899+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:11.898+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T18:39:11.948+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:11.948+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T18:39:11.949+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:11.949+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T13:09:05.761617+00:00, execution_date=20241214T130905, start_date=, end_date=20241214T130911
[2024-12-14T18:39:11.961+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T18:39:11.962+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T18:39:11.962+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T18:39:11.962+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T18:39:11.963+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:11.963+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T18:39:12.004+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:12.003+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T18:39:12.004+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:12.004+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T13:09:05.761617+00:00 [scheduled]>
[2024-12-14T18:39:12.051+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:39:12,051] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:09:05.761617+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:09:05.761617+00:00'
[2024-12-14T18:39:12.051+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:12.051+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:09:05.761617+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:09:05.761617+00:00'
[2024-12-14T18:39:12.052+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T18:39:12.052+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T18:39:12.053+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T18:39:12.053+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T18:39:12.054+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:12.053+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T18:39:12.055+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:39:12,054] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T18:39:12.055+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:12.054+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T18:39:12.057+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:39:12,056] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T18:39:12.057+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:12.056+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py  2024-12-14']
[2024-12-14T18:39:12.073+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:39:12,070] {subprocess.py:99} INFO - Output:
[2024-12-14T18:39:12.074+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:12.070+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T18:39:12.207+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:39:12,207] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpdz8zwk0e/controller.py': [Errno 2] No such file or directory
[2024-12-14T18:39:12.208+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:12.207+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpdz8zwk0e/controller.py': [Errno 2] No such file or directory
[2024-12-14T18:39:12.228+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:39:12,228] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T18:39:12.228+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:12.228+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T18:39:12.267+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:39:12,253] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T18:39:12.267+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:12.253+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T18:39:12.270+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T18:39:12.271+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 13:09:12.270023+00:00 duration:None
[2024-12-14T18:39:12.271+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 13:09:05.761617+00:00: manual__2024-12-14T13:09:05.761617+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T18:39:12.272+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T18:39:12.274+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:12.272+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T13:09:05.761617+00:00, execution_date=20241214T130905, start_date=, end_date=20241214T130912
[2024-12-14T18:39:12.300+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:12.296+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T18:39:12.319+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:12.300+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T13:09:05.761617+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T18:39:12.328+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:12.328+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 13:09:05.761617+00:00: manual__2024-12-14T13:09:05.761617+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T18:39:12.328+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T18:39:12.329+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T13:09:05.761617+00:00 external trigger: False
[2024-12-14T18:39:12.329+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T18:39:12.332+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:12.329+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 13:09:05.761617+00:00, run_id=manual__2024-12-14T13:09:05.761617+00:00, run_start_date=2024-12-14 13:09:05.761617+00:00, run_end_date=2024-12-14 13:09:12.328737+00:00, run_duration=6.56712, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 13:09:05.761617+00:00, data_interval_end=2024-12-14 13:09:05.761617+00:00, dag_hash=None
[2024-12-14T18:39:12.345+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T18:39:12.378+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:12.378+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T18:39:12.428+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:39:12.428+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T18:39:12.583+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 6.900 seconds
[2024-12-14T18:43:17.269+0530] {processor.py:186} INFO - Started process (PID=1943) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T18:43:17.272+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T18:43:17.275+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:17.275+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T18:43:17.435+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:17.435+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T18:43:17.451+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:17.451+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 13:13:17.406253+00:00: manual__2024-12-14T13:13:17.406253+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T18:43:17.488+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:17.488+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T18:43:17.489+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:17.488+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T13:13:17.406253+00:00 [scheduled]>
[2024-12-14T18:43:22.517+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:22.516+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T18:43:22.677+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:43:22,676] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:13:17.406253+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:13:17.406253+00:00'
[2024-12-14T18:43:22.677+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:22.676+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:13:17.406253+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:13:17.406253+00:00'
[2024-12-14T18:43:22.689+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T18:43:22.690+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T18:43:22.690+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T18:43:22.690+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T18:43:22.691+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:22.691+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T18:43:22.725+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:43:22,725] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T18:43:22.725+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:22.725+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T18:43:22.726+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:43:22,726] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T18:43:22.727+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:22.726+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T18:43:22.735+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:43:22,733] {subprocess.py:99} INFO - Output:
[2024-12-14T18:43:22.736+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:22.733+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T18:43:22.737+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:43:22,737] {subprocess.py:106} INFO - scraping started
[2024-12-14T18:43:22.737+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:22.737+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T18:43:22.738+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:43:22,738] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T18:43:22.738+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:22.738+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T18:43:22.757+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:22.757+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T18:43:22.758+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:22.758+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T13:13:17.406253+00:00, execution_date=20241214T131317, start_date=, end_date=20241214T131322
[2024-12-14T18:43:22.769+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T18:43:22.769+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T18:43:22.770+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T18:43:22.770+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T18:43:22.771+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:22.770+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T18:43:22.790+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:22.790+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T18:43:22.790+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:22.790+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T13:13:17.406253+00:00 [scheduled]>
[2024-12-14T18:43:22.820+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:43:22,820] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:13:17.406253+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:13:17.406253+00:00'
[2024-12-14T18:43:22.821+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:22.820+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:13:17.406253+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:13:17.406253+00:00'
[2024-12-14T18:43:22.821+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T18:43:22.822+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T18:43:22.822+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T18:43:22.822+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T18:43:22.822+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:22.822+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T18:43:22.823+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:43:22,823] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T18:43:22.823+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:22.823+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T18:43:22.824+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:43:22,824] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py 2024-12-14']
[2024-12-14T18:43:22.824+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:22.824+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py 2024-12-14']
[2024-12-14T18:43:22.833+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:43:22,831] {subprocess.py:99} INFO - Output:
[2024-12-14T18:43:22.834+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:22.831+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T18:43:22.879+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:43:22,879] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp6wzfxyky/controller.py': [Errno 2] No such file or directory
[2024-12-14T18:43:22.880+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:22.879+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmp6wzfxyky/controller.py': [Errno 2] No such file or directory
[2024-12-14T18:43:22.884+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:43:22,884] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T18:43:22.885+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:22.884+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T18:43:22.904+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:43:22,891] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T18:43:22.905+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:22.891+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T18:43:22.907+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T18:43:22.908+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 13:13:22.907208+00:00 duration:None
[2024-12-14T18:43:22.908+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 13:13:17.406253+00:00: manual__2024-12-14T13:13:17.406253+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T18:43:22.908+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T18:43:22.908+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:22.908+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T13:13:17.406253+00:00, execution_date=20241214T131317, start_date=, end_date=20241214T131322
[2024-12-14T18:43:22.923+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:22.922+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T18:43:22.929+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:22.923+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T13:13:17.406253+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T18:43:22.933+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:22.933+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 13:13:17.406253+00:00: manual__2024-12-14T13:13:17.406253+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T18:43:22.934+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T18:43:22.934+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T13:13:17.406253+00:00 external trigger: False
[2024-12-14T18:43:22.934+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T18:43:22.934+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:22.934+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 13:13:17.406253+00:00, run_id=manual__2024-12-14T13:13:17.406253+00:00, run_start_date=2024-12-14 13:13:17.406253+00:00, run_end_date=2024-12-14 13:13:22.933971+00:00, run_duration=5.527718, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 13:13:17.406253+00:00, data_interval_end=2024-12-14 13:13:17.406253+00:00, dag_hash=None
[2024-12-14T18:43:22.944+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T18:43:23.087+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:23.086+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T18:43:23.107+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:43:23.107+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T18:43:23.132+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.867 seconds
[2024-12-14T18:46:31.461+0530] {processor.py:186} INFO - Started process (PID=2309) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T18:46:31.463+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T18:46:31.464+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:31.464+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T18:46:31.626+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:31.626+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T18:46:31.644+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:31.643+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 13:16:31.591193+00:00: manual__2024-12-14T13:16:31.591193+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T18:46:31.675+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:31.675+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T18:46:31.676+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:31.676+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T13:16:31.591193+00:00 [scheduled]>
[2024-12-14T18:46:36.704+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:36.704+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T18:46:36.876+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:46:36,876] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:16:31.591193+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:16:31.591193+00:00'
[2024-12-14T18:46:36.876+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:36.876+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:16:31.591193+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:16:31.591193+00:00'
[2024-12-14T18:46:36.881+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T18:46:36.888+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T18:46:36.890+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T18:46:36.890+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T18:46:36.891+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:36.891+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T18:46:36.929+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:46:36,928] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T18:46:36.929+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:36.928+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T18:46:36.934+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:46:36,933] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T18:46:36.935+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:36.933+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T18:46:36.945+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:46:36,943] {subprocess.py:99} INFO - Output:
[2024-12-14T18:46:36.954+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:36.943+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T18:46:36.955+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:46:36,955] {subprocess.py:106} INFO - scraping started
[2024-12-14T18:46:36.955+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:36.955+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T18:46:36.956+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:46:36,955] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T18:46:36.956+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:36.955+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T18:46:36.980+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:36.979+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T18:46:36.981+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:36.981+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T13:16:31.591193+00:00, execution_date=20241214T131631, start_date=, end_date=20241214T131636
[2024-12-14T18:46:36.993+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T18:46:36.993+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T18:46:36.993+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T18:46:36.994+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T18:46:36.994+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:36.994+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T18:46:37.014+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:37.014+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T18:46:37.015+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:37.015+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T13:16:31.591193+00:00 [scheduled]>
[2024-12-14T18:46:37.048+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:46:37,048] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:16:31.591193+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:16:31.591193+00:00'
[2024-12-14T18:46:37.049+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:37.048+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:16:31.591193+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:16:31.591193+00:00'
[2024-12-14T18:46:37.049+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T18:46:37.049+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T18:46:37.049+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T18:46:37.049+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T18:46:37.050+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:37.050+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T18:46:37.050+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:46:37,050] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T18:46:37.051+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:37.050+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T18:46:37.052+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:46:37,051] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python  2024-12-14']
[2024-12-14T18:46:37.052+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:37.051+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python  2024-12-14']
[2024-12-14T18:46:37.062+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:46:37,060] {subprocess.py:99} INFO - Output:
[2024-12-14T18:46:37.064+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:37.060+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T18:46:37.110+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:46:37,110] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpfi5l8ceg/2024-12-14': [Errno 2] No such file or directory
[2024-12-14T18:46:37.110+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:37.110+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpfi5l8ceg/2024-12-14': [Errno 2] No such file or directory
[2024-12-14T18:46:37.115+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:46:37,115] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T18:46:37.115+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:37.115+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T18:46:37.124+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:46:37,122] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T18:46:37.125+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:37.122+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T18:46:37.127+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T18:46:37.127+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 13:16:37.126582+00:00 duration:None
[2024-12-14T18:46:37.127+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 13:16:31.591193+00:00: manual__2024-12-14T13:16:31.591193+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T18:46:37.128+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T18:46:37.128+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:37.128+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T13:16:31.591193+00:00, execution_date=20241214T131631, start_date=, end_date=20241214T131637
[2024-12-14T18:46:37.139+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:37.139+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T18:46:37.143+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:37.140+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T13:16:31.591193+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T18:46:37.147+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:37.147+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 13:16:31.591193+00:00: manual__2024-12-14T13:16:31.591193+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T18:46:37.147+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T18:46:37.148+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T13:16:31.591193+00:00 external trigger: False
[2024-12-14T18:46:37.148+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T18:46:37.148+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:37.148+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 13:16:31.591193+00:00, run_id=manual__2024-12-14T13:16:31.591193+00:00, run_start_date=2024-12-14 13:16:31.591193+00:00, run_end_date=2024-12-14 13:16:37.147759+00:00, run_duration=5.556566, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 13:16:31.591193+00:00, data_interval_end=2024-12-14 13:16:31.591193+00:00, dag_hash=None
[2024-12-14T18:46:37.158+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T18:46:37.292+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:37.291+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T18:46:37.313+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:46:37.313+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T18:46:37.338+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.881 seconds
[2024-12-14T18:50:18.629+0530] {processor.py:186} INFO - Started process (PID=2811) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T18:50:18.632+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T18:50:18.634+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:18.633+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T18:50:18.787+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:18.787+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T18:50:18.812+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:18.811+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 13:20:18.757263+00:00: manual__2024-12-14T13:20:18.757263+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T18:50:18.844+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:18.843+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T18:50:18.844+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:18.844+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T13:20:18.757263+00:00 [scheduled]>
[2024-12-14T18:50:23.872+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:23.871+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T18:50:24.017+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,017] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:20:18.757263+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:20:18.757263+00:00'
[2024-12-14T18:50:24.018+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.017+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:20:18.757263+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:20:18.757263+00:00'
[2024-12-14T18:50:24.022+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T18:50:24.022+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T18:50:24.023+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T18:50:24.023+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T18:50:24.023+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.023+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T18:50:24.055+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,055] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T18:50:24.055+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.055+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T18:50:24.056+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,056] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T18:50:24.057+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.056+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'echo scraping started']
[2024-12-14T18:50:24.065+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,063] {subprocess.py:99} INFO - Output:
[2024-12-14T18:50:24.066+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.063+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T18:50:24.066+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,066] {subprocess.py:106} INFO - scraping started
[2024-12-14T18:50:24.067+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.066+0530] {subprocess.py:106} INFO - scraping started
[2024-12-14T18:50:24.067+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,067] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T18:50:24.068+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.067+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T18:50:24.088+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.088+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T18:50:24.089+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.089+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T13:20:18.757263+00:00, execution_date=20241214T132018, start_date=, end_date=20241214T132024
[2024-12-14T18:50:24.100+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T18:50:24.100+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T18:50:24.101+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T18:50:24.101+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T18:50:24.102+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.101+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T18:50:24.119+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.119+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T18:50:24.120+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.119+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T13:20:18.757263+00:00 [scheduled]>
[2024-12-14T18:50:24.147+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,147] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:20:18.757263+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:20:18.757263+00:00'
[2024-12-14T18:50:24.147+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.147+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:20:18.757263+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:20:18.757263+00:00'
[2024-12-14T18:50:24.148+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T18:50:24.148+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T18:50:24.148+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T18:50:24.148+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T18:50:24.149+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.148+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T18:50:24.149+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,149] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T18:50:24.150+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.149+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T18:50:24.150+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,150] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "python '/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/controller.py' 2024-12-14"]
[2024-12-14T18:50:24.150+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.150+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "python '/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/controller.py' 2024-12-14"]
[2024-12-14T18:50:24.161+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,159] {subprocess.py:99} INFO - Output:
[2024-12-14T18:50:24.163+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.159+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T18:50:24.529+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,529] {subprocess.py:106} INFO - Traceback (most recent call last):
[2024-12-14T18:50:24.529+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.529+0530] {subprocess.py:106} INFO - Traceback (most recent call last):
[2024-12-14T18:50:24.530+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,529] {subprocess.py:106} INFO -   File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/selenium/webdriver/common/driver_finder.py", line 64, in _binary_paths
[2024-12-14T18:50:24.530+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.529+0530] {subprocess.py:106} INFO -   File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/selenium/webdriver/common/driver_finder.py", line 64, in _binary_paths
[2024-12-14T18:50:24.530+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,530] {subprocess.py:106} INFO -     raise ValueError(f"The path is not a valid file: {path}")
[2024-12-14T18:50:24.531+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.530+0530] {subprocess.py:106} INFO -     raise ValueError(f"The path is not a valid file: {path}")
[2024-12-14T18:50:24.531+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,531] {subprocess.py:106} INFO - ValueError: The path is not a valid file: ./chromedriver
[2024-12-14T18:50:24.531+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.531+0530] {subprocess.py:106} INFO - ValueError: The path is not a valid file: ./chromedriver
[2024-12-14T18:50:24.532+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,532] {subprocess.py:106} INFO -
[2024-12-14T18:50:24.532+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.532+0530] {subprocess.py:106} INFO -
[2024-12-14T18:50:24.532+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,532] {subprocess.py:106} INFO - The above exception was the direct cause of the following exception:
[2024-12-14T18:50:24.533+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.532+0530] {subprocess.py:106} INFO - The above exception was the direct cause of the following exception:
[2024-12-14T18:50:24.533+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,533] {subprocess.py:106} INFO -
[2024-12-14T18:50:24.533+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.533+0530] {subprocess.py:106} INFO -
[2024-12-14T18:50:24.534+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,534] {subprocess.py:106} INFO - Traceback (most recent call last):
[2024-12-14T18:50:24.534+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.534+0530] {subprocess.py:106} INFO - Traceback (most recent call last):
[2024-12-14T18:50:24.534+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,534] {subprocess.py:106} INFO -   File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/controller.py", line 2, in <module>
[2024-12-14T18:50:24.535+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.534+0530] {subprocess.py:106} INFO -   File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/controller.py", line 2, in <module>
[2024-12-14T18:50:24.535+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,535] {subprocess.py:106} INFO -     import extract
[2024-12-14T18:50:24.535+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.535+0530] {subprocess.py:106} INFO -     import extract
[2024-12-14T18:50:24.536+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,536] {subprocess.py:106} INFO -   File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/extract.py", line 11, in <module>
[2024-12-14T18:50:24.536+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.536+0530] {subprocess.py:106} INFO -   File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/extract.py", line 11, in <module>
[2024-12-14T18:50:24.536+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,536] {subprocess.py:106} INFO -     driver=webdriver.Chrome(service=service)
[2024-12-14T18:50:24.537+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.536+0530] {subprocess.py:106} INFO -     driver=webdriver.Chrome(service=service)
[2024-12-14T18:50:24.537+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,537] {subprocess.py:106} INFO -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2024-12-14T18:50:24.537+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.537+0530] {subprocess.py:106} INFO -            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[2024-12-14T18:50:24.538+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,538] {subprocess.py:106} INFO -   File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/selenium/webdriver/chrome/webdriver.py", line 45, in __init__
[2024-12-14T18:50:24.538+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.538+0530] {subprocess.py:106} INFO -   File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/selenium/webdriver/chrome/webdriver.py", line 45, in __init__
[2024-12-14T18:50:24.538+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,538] {subprocess.py:106} INFO -     super().__init__(
[2024-12-14T18:50:24.539+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.538+0530] {subprocess.py:106} INFO -     super().__init__(
[2024-12-14T18:50:24.539+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,539] {subprocess.py:106} INFO -   File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/selenium/webdriver/chromium/webdriver.py", line 50, in __init__
[2024-12-14T18:50:24.541+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.539+0530] {subprocess.py:106} INFO -   File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/selenium/webdriver/chromium/webdriver.py", line 50, in __init__
[2024-12-14T18:50:24.541+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,541] {subprocess.py:106} INFO -     if finder.get_browser_path():
[2024-12-14T18:50:24.542+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.541+0530] {subprocess.py:106} INFO -     if finder.get_browser_path():
[2024-12-14T18:50:24.542+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,542] {subprocess.py:106} INFO -        ^^^^^^^^^^^^^^^^^^^^^^^^^
[2024-12-14T18:50:24.544+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.542+0530] {subprocess.py:106} INFO -        ^^^^^^^^^^^^^^^^^^^^^^^^^
[2024-12-14T18:50:24.545+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,544] {subprocess.py:106} INFO -   File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/selenium/webdriver/common/driver_finder.py", line 47, in get_browser_path
[2024-12-14T18:50:24.545+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.544+0530] {subprocess.py:106} INFO -   File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/selenium/webdriver/common/driver_finder.py", line 47, in get_browser_path
[2024-12-14T18:50:24.546+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,546] {subprocess.py:106} INFO -     return self._binary_paths()["browser_path"]
[2024-12-14T18:50:24.546+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.546+0530] {subprocess.py:106} INFO -     return self._binary_paths()["browser_path"]
[2024-12-14T18:50:24.547+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,547] {subprocess.py:106} INFO -            ^^^^^^^^^^^^^^^^^^^^
[2024-12-14T18:50:24.547+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.547+0530] {subprocess.py:106} INFO -            ^^^^^^^^^^^^^^^^^^^^
[2024-12-14T18:50:24.548+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,548] {subprocess.py:106} INFO -   File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/selenium/webdriver/common/driver_finder.py", line 78, in _binary_paths
[2024-12-14T18:50:24.549+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.548+0530] {subprocess.py:106} INFO -   File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/selenium/webdriver/common/driver_finder.py", line 78, in _binary_paths
[2024-12-14T18:50:24.550+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,549] {subprocess.py:106} INFO -     raise NoSuchDriverException(msg) from err
[2024-12-14T18:50:24.550+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.549+0530] {subprocess.py:106} INFO -     raise NoSuchDriverException(msg) from err
[2024-12-14T18:50:24.550+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,550] {subprocess.py:106} INFO - selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2024-12-14T18:50:24.551+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.550+0530] {subprocess.py:106} INFO - selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location
[2024-12-14T18:50:24.551+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,551] {subprocess.py:106} INFO -
[2024-12-14T18:50:24.551+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.551+0530] {subprocess.py:106} INFO -
[2024-12-14T18:50:24.583+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,583] {subprocess.py:110} INFO - Command exited with return code 1
[2024-12-14T18:50:24.583+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.583+0530] {subprocess.py:110} INFO - Command exited with return code 1
[2024-12-14T18:50:24.592+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:50:24,590] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-12-14T18:50:24.593+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.590+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-12-14T18:50:24.595+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T18:50:24.595+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 13:20:24.594906+00:00 duration:None
[2024-12-14T18:50:24.596+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 13:20:18.757263+00:00: manual__2024-12-14T13:20:18.757263+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T18:50:24.596+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 1.
[2024-12-14T18:50:24.596+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.596+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T13:20:18.757263+00:00, execution_date=20241214T132018, start_date=, end_date=20241214T132024
[2024-12-14T18:50:24.607+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.606+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T18:50:24.609+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.607+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T13:20:18.757263+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2024-12-14T18:50:24.614+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.614+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 13:20:18.757263+00:00: manual__2024-12-14T13:20:18.757263+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T18:50:24.614+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T18:50:24.615+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T13:20:18.757263+00:00 external trigger: False
[2024-12-14T18:50:24.615+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T18:50:24.615+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.615+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 13:20:18.757263+00:00, run_id=manual__2024-12-14T13:20:18.757263+00:00, run_start_date=2024-12-14 13:20:18.757263+00:00, run_end_date=2024-12-14 13:20:24.614816+00:00, run_duration=5.857553, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 13:20:18.757263+00:00, data_interval_end=2024-12-14 13:20:18.757263+00:00, dag_hash=None
[2024-12-14T18:50:24.628+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T18:50:24.769+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.769+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T18:50:24.791+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:50:24.791+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T18:50:24.814+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 6.187 seconds
[2024-12-14T18:53:56.215+0530] {processor.py:186} INFO - Started process (PID=3251) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T18:53:56.219+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T18:53:56.223+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:53:56.222+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T18:53:56.230+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:53:56.225+0530] {dagbag.py:387} ERROR - Failed to import: /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 991, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1129, in get_code
  File "<frozen importlib._bootstrap_external>", line 1059, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py", line 20
    bash_command='cd /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src"
                 ^
SyntaxError: unterminated string literal (detected at line 20)
[2024-12-14T18:53:56.231+0530] {processor.py:927} WARNING - No viable dags retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T18:53:56.596+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:53:56.595+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T18:53:56.656+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.447 seconds
[2024-12-14T18:57:18.491+0530] {processor.py:186} INFO - Started process (PID=3619) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T18:57:18.493+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T18:57:18.495+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:18.495+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T18:57:18.648+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:18.647+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T18:57:18.663+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:18.662+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 13:27:18.618204+00:00: manual__2024-12-14T13:27:18.618204+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T18:57:18.694+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:18.694+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T18:57:18.695+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:18.695+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T13:27:18.618204+00:00 [scheduled]>
[2024-12-14T18:57:23.723+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:23.722+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T18:57:23.862+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:57:23,862] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:27:18.618204+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:27:18.618204+00:00'
[2024-12-14T18:57:23.863+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:23.862+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:27:18.618204+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:27:18.618204+00:00'
[2024-12-14T18:57:23.870+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T18:57:23.871+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T18:57:23.871+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T18:57:23.871+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T18:57:23.871+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:23.871+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T18:57:23.902+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:57:23,902] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T18:57:23.902+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:23.902+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T18:57:23.903+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:57:23,903] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "cd '/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src'"]
[2024-12-14T18:57:23.903+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:23.903+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "cd '/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src'"]
[2024-12-14T18:57:23.911+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:57:23,910] {subprocess.py:99} INFO - Output:
[2024-12-14T18:57:23.912+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:23.910+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T18:57:23.913+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:57:23,913] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T18:57:23.913+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:23.913+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T18:57:23.932+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:23.932+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T18:57:23.933+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:23.933+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T13:27:18.618204+00:00, execution_date=20241214T132718, start_date=, end_date=20241214T132723
[2024-12-14T18:57:23.944+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T18:57:23.944+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T18:57:23.944+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T18:57:23.944+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T18:57:23.945+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:23.945+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T18:57:23.962+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:23.962+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T18:57:23.963+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:23.962+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T13:27:18.618204+00:00 [scheduled]>
[2024-12-14T18:57:23.992+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:57:23,992] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:27:18.618204+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:27:18.618204+00:00'
[2024-12-14T18:57:23.992+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:23.992+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:27:18.618204+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:27:18.618204+00:00'
[2024-12-14T18:57:23.993+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T18:57:23.993+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T18:57:23.993+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T18:57:23.993+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T18:57:23.994+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:23.993+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T18:57:23.994+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:57:23,994] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T18:57:23.995+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:23.994+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T18:57:23.995+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:57:23,995] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py 2024-12-14']
[2024-12-14T18:57:23.996+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:23.995+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py 2024-12-14']
[2024-12-14T18:57:24.005+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:57:24,004] {subprocess.py:99} INFO - Output:
[2024-12-14T18:57:24.006+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:24.004+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T18:57:24.049+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:57:24,049] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpjhhy2sm4/controller.py': [Errno 2] No such file or directory
[2024-12-14T18:57:24.050+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:24.049+0530] {subprocess.py:106} INFO - /usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/Resources/Python.app/Contents/MacOS/Python: can't open file '/private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpjhhy2sm4/controller.py': [Errno 2] No such file or directory
[2024-12-14T18:57:24.055+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:57:24,055] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T18:57:24.055+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:24.055+0530] {subprocess.py:110} INFO - Command exited with return code 2
[2024-12-14T18:57:24.069+0530] {logging_mixin.py:190} INFO - [2024-12-14 18:57:24,062] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T18:57:24.069+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:24.062+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T18:57:24.071+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T18:57:24.071+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 13:27:24.071077+00:00 duration:None
[2024-12-14T18:57:24.072+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): scrape> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 13:27:18.618204+00:00: manual__2024-12-14T13:27:18.618204+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T18:57:24.072+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T18:57:24.072+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:24.072+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T13:27:18.618204+00:00, execution_date=20241214T132718, start_date=, end_date=20241214T132724
[2024-12-14T18:57:24.083+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:24.083+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T18:57:24.089+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:24.083+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.scrape manual__2024-12-14T13:27:18.618204+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 2.
[2024-12-14T18:57:24.094+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:24.094+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 13:27:18.618204+00:00: manual__2024-12-14T13:27:18.618204+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T18:57:24.094+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T18:57:24.095+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T13:27:18.618204+00:00 external trigger: False
[2024-12-14T18:57:24.095+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T18:57:24.095+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:24.095+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 13:27:18.618204+00:00, run_id=manual__2024-12-14T13:27:18.618204+00:00, run_start_date=2024-12-14 13:27:18.618204+00:00, run_end_date=2024-12-14 13:27:24.094692+00:00, run_duration=5.476488, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 13:27:18.618204+00:00, data_interval_end=2024-12-14 13:27:18.618204+00:00, dag_hash=None
[2024-12-14T18:57:24.105+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T18:57:24.225+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:24.225+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T18:57:24.245+0530] {logging_mixin.py:190} INFO - [2024-12-14T18:57:24.245+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T18:57:24.272+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.784 seconds
[2024-12-14T19:00:29.977+0530] {processor.py:186} INFO - Started process (PID=3976) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:00:29.979+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T19:00:29.981+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:29.981+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:00:30.141+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:30.141+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T19:00:30.160+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:30.159+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 13:30:29.988102+00:00: manual__2024-12-14T13:30:29.988102+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T19:00:30.198+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:30.198+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T19:00:30.199+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:30.199+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T13:30:29.988102+00:00 [scheduled]>
[2024-12-14T19:00:35.232+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:35.232+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T19:00:35.376+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:00:35,376] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:30:29.988102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:30:29.988102+00:00'
[2024-12-14T19:00:35.376+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:35.376+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:30:29.988102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:30:29.988102+00:00'
[2024-12-14T19:00:35.389+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T19:00:35.389+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T19:00:35.389+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T19:00:35.390+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T19:00:35.390+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:35.390+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T19:00:35.427+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:00:35,426] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:00:35.427+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:35.426+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:00:35.428+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:00:35,428] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "cd '/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src'"]
[2024-12-14T19:00:35.428+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:35.428+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "cd '/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src'"]
[2024-12-14T19:00:35.438+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:00:35,436] {subprocess.py:99} INFO - Output:
[2024-12-14T19:00:35.440+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:35.436+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T19:00:35.441+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:00:35,440] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:00:35.441+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:35.440+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:00:35.465+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:35.464+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T19:00:35.465+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:35.465+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T13:30:29.988102+00:00, execution_date=20241214T133029, start_date=, end_date=20241214T133035
[2024-12-14T19:00:35.475+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T19:00:35.476+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T19:00:35.477+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T19:00:35.478+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T19:00:35.478+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:35.478+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T19:00:35.505+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:35.505+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T19:00:35.506+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:35.505+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T13:30:29.988102+00:00 [scheduled]>
[2024-12-14T19:00:35.539+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:00:35,539] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:30:29.988102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:30:29.988102+00:00'
[2024-12-14T19:00:35.540+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:35.539+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:30:29.988102+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:30:29.988102+00:00'
[2024-12-14T19:00:35.540+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T19:00:35.540+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T19:00:35.540+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T19:00:35.541+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T19:00:35.542+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:35.541+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T19:00:35.543+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:00:35,543] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:00:35.544+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:35.543+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:00:35.545+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:00:35,545] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'pwd']
[2024-12-14T19:00:35.545+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:35.545+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'pwd']
[2024-12-14T19:00:35.554+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:00:35,553] {subprocess.py:99} INFO - Output:
[2024-12-14T19:00:35.555+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:35.553+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T19:00:35.556+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:00:35,556] {subprocess.py:106} INFO - /private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmppk3yf18j
[2024-12-14T19:00:35.556+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:35.556+0530] {subprocess.py:106} INFO - /private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmppk3yf18j
[2024-12-14T19:00:35.556+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:00:35,556] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:00:35.559+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:35.556+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:00:35.705+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:35.704+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T19:00:35.713+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:35.708+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T13:30:29.988102+00:00, execution_date=20241214T133029, start_date=, end_date=20241214T133035
[2024-12-14T19:00:35.758+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T19:00:35.759+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T19:00:35.760+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T19:00:35.761+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T19:00:35.761+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:35.761+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=scrape map_index=-1
[2024-12-14T19:00:35.768+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:35.768+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 13:30:29.988102+00:00: manual__2024-12-14T13:30:29.988102+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T19:00:35.769+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T19:00:35.769+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 13:30:29.988102+00:00 end:2024-12-14 13:30:35.769369+00:00
[2024-12-14T19:00:35.771+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:35.770+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 13:30:29.988102+00:00, run_id=manual__2024-12-14T13:30:29.988102+00:00, run_start_date=2024-12-14 13:30:29.988102+00:00, run_end_date=2024-12-14 13:30:35.769369+00:00, run_duration=5.781267, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 13:30:29.988102+00:00, data_interval_end=2024-12-14 13:30:29.988102+00:00, dag_hash=None
[2024-12-14T19:00:35.784+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:00:36.124+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:36.124+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T19:00:36.164+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:00:36.164+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T19:00:36.201+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 6.228 seconds
[2024-12-14T19:03:48.625+0530] {processor.py:186} INFO - Started process (PID=4319) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:03:48.628+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T19:03:48.629+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:48.629+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:03:48.782+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:48.781+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T19:03:48.796+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:48.796+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 13:33:48.636178+00:00: manual__2024-12-14T13:33:48.636178+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T19:03:48.831+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:48.831+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T19:03:48.832+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:48.831+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T13:33:48.636178+00:00 [scheduled]>
[2024-12-14T19:03:53.858+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:53.857+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T19:03:54.008+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:03:54,008] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:33:48.636178+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:33:48.636178+00:00'
[2024-12-14T19:03:54.008+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:54.008+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:33:48.636178+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:33:48.636178+00:00'
[2024-12-14T19:03:54.022+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T19:03:54.023+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T19:03:54.023+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T19:03:54.024+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T19:03:54.025+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:54.025+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T19:03:54.064+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:03:54,064] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:03:54.065+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:54.064+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:03:54.066+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:03:54,065] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "cd '/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src'"]
[2024-12-14T19:03:54.066+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:54.065+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "cd '/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src'"]
[2024-12-14T19:03:54.077+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:03:54,075] {subprocess.py:99} INFO - Output:
[2024-12-14T19:03:54.078+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:54.075+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T19:03:54.080+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:03:54,080] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:03:54.081+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:54.080+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:03:54.106+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:54.105+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T19:03:54.107+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:54.106+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T13:33:48.636178+00:00, execution_date=20241214T133348, start_date=, end_date=20241214T133354
[2024-12-14T19:03:54.119+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T19:03:54.119+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T19:03:54.120+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T19:03:54.120+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T19:03:54.120+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:54.120+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T19:03:54.143+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:54.142+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T19:03:54.144+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:54.143+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T13:33:48.636178+00:00 [scheduled]>
[2024-12-14T19:03:54.174+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:03:54,173] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:33:48.636178+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:33:48.636178+00:00'
[2024-12-14T19:03:54.174+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:54.173+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:33:48.636178+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:33:48.636178+00:00'
[2024-12-14T19:03:54.175+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T19:03:54.175+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T19:03:54.175+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T19:03:54.175+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T19:03:54.176+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:54.176+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T19:03:54.177+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:03:54,177] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:03:54.177+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:54.177+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:03:54.178+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:03:54,178] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'pwd']
[2024-12-14T19:03:54.179+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:54.178+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'pwd']
[2024-12-14T19:03:54.189+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:03:54,187] {subprocess.py:99} INFO - Output:
[2024-12-14T19:03:54.191+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:54.187+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T19:03:54.192+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:03:54,192] {subprocess.py:106} INFO - /private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpj7xdu7as
[2024-12-14T19:03:54.193+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:54.192+0530] {subprocess.py:106} INFO - /private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpj7xdu7as
[2024-12-14T19:03:54.193+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:03:54,193] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:03:54.193+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:54.193+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:03:54.209+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:54.209+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T19:03:54.210+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:54.209+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T13:33:48.636178+00:00, execution_date=20241214T133348, start_date=, end_date=20241214T133354
[2024-12-14T19:03:54.218+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T19:03:54.218+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T19:03:54.218+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T19:03:54.218+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T19:03:54.219+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:54.219+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=scrape map_index=-1
[2024-12-14T19:03:54.223+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:54.222+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 13:33:48.636178+00:00: manual__2024-12-14T13:33:48.636178+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T19:03:54.223+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T19:03:54.223+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 13:33:48.636178+00:00 end:2024-12-14 13:33:54.223334+00:00
[2024-12-14T19:03:54.224+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:54.223+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 13:33:48.636178+00:00, run_id=manual__2024-12-14T13:33:48.636178+00:00, run_start_date=2024-12-14 13:33:48.636178+00:00, run_end_date=2024-12-14 13:33:54.223334+00:00, run_duration=5.587156, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 13:33:48.636178+00:00, data_interval_end=2024-12-14 13:33:48.636178+00:00, dag_hash=None
[2024-12-14T19:03:54.234+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:03:54.246+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:54.246+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T19:03:54.266+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:03:54.266+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T19:03:54.288+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.666 seconds
[2024-12-14T19:06:56.766+0530] {processor.py:186} INFO - Started process (PID=4536) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:06:56.768+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T19:06:56.771+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:06:56.770+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:06:56.943+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:06:56.942+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T19:06:56.957+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:06:56.957+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 13:36:56.779539+00:00: manual__2024-12-14T13:36:56.779539+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T19:06:56.992+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:06:56.992+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T19:06:56.993+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:06:56.993+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T13:36:56.779539+00:00 [scheduled]>
[2024-12-14T19:07:02.026+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:07:02.026+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T19:07:02.189+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:07:02,189] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:36:56.779539+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:36:56.779539+00:00'
[2024-12-14T19:07:02.190+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:07:02.189+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:36:56.779539+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:36:56.779539+00:00'
[2024-12-14T19:07:02.202+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T19:07:02.203+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T19:07:02.203+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T19:07:02.204+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T19:07:02.204+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:07:02.204+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T19:07:02.239+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:07:02,239] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:07:02.240+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:07:02.239+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:07:02.241+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:07:02,240] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "cd '/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src'"]
[2024-12-14T19:07:02.241+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:07:02.240+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "cd '/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src'"]
[2024-12-14T19:07:02.250+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:07:02,248] {subprocess.py:99} INFO - Output:
[2024-12-14T19:07:02.251+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:07:02.248+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T19:07:02.253+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:07:02,253] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:07:02.254+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:07:02.253+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:07:02.280+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:07:02.279+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T19:07:02.280+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:07:02.280+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T13:36:56.779539+00:00, execution_date=20241214T133656, start_date=, end_date=20241214T133702
[2024-12-14T19:07:02.292+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T19:07:02.293+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T19:07:02.293+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T19:07:02.294+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T19:07:02.295+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:07:02.295+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T19:07:02.314+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:07:02.313+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T19:07:02.314+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:07:02.314+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T13:36:56.779539+00:00 [scheduled]>
[2024-12-14T19:07:02.350+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:07:02,350] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:36:56.779539+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:36:56.779539+00:00'
[2024-12-14T19:07:02.350+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:07:02.350+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:36:56.779539+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:36:56.779539+00:00'
[2024-12-14T19:07:02.350+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T19:07:02.350+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T19:07:02.351+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T19:07:02.351+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T19:07:02.351+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:07:02.351+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T19:07:02.352+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:07:02,352] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:07:02.352+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:07:02.352+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:07:02.353+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:07:02,353] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'pwd']
[2024-12-14T19:07:02.353+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:07:02.353+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'pwd']
[2024-12-14T19:07:02.373+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:07:02,360] {subprocess.py:99} INFO - Output:
[2024-12-14T19:07:02.380+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:07:02.360+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T19:07:02.381+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:07:02,381] {subprocess.py:106} INFO - /private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpyrobuyfn
[2024-12-14T19:07:02.441+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:07:02.381+0530] {subprocess.py:106} INFO - /private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpyrobuyfn
[2024-12-14T19:07:02.443+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:07:02,442] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:07:02.444+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:07:02.442+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:07:02.470+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:07:02.470+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T19:07:02.471+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:07:02.471+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T13:36:56.779539+00:00, execution_date=20241214T133656, start_date=, end_date=20241214T133702
[2024-12-14T19:07:02.481+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T19:07:02.481+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T19:07:02.481+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T19:07:02.481+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T19:07:02.482+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:07:02.482+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=scrape map_index=-1
[2024-12-14T19:07:02.487+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:07:02.487+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 13:36:56.779539+00:00: manual__2024-12-14T13:36:56.779539+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T19:07:02.488+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T19:07:02.488+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 13:36:56.779539+00:00 end:2024-12-14 13:37:02.488060+00:00
[2024-12-14T19:07:02.489+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:07:02.488+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 13:36:56.779539+00:00, run_id=manual__2024-12-14T13:36:56.779539+00:00, run_start_date=2024-12-14 13:36:56.779539+00:00, run_end_date=2024-12-14 13:37:02.488060+00:00, run_duration=5.708521, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 13:36:56.779539+00:00, data_interval_end=2024-12-14 13:36:56.779539+00:00, dag_hash=None
[2024-12-14T19:07:02.504+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:07:02.541+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:07:02.541+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T19:07:02.600+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:07:02.600+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T19:07:02.642+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.879 seconds
[2024-12-14T19:10:00.052+0530] {processor.py:186} INFO - Started process (PID=4755) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:10:00.054+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T19:10:00.056+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:00.056+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:10:00.212+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:00.211+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T19:10:00.228+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:00.228+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 13:40:00.064553+00:00: manual__2024-12-14T13:40:00.064553+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T19:10:00.263+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:00.263+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T19:10:00.263+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:00.263+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T13:40:00.064553+00:00 [scheduled]>
[2024-12-14T19:10:05.295+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:05.295+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T19:10:05.441+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:10:05,441] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:40:00.064553+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:40:00.064553+00:00'
[2024-12-14T19:10:05.441+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:05.441+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:40:00.064553+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:40:00.064553+00:00'
[2024-12-14T19:10:05.450+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T19:10:05.450+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T19:10:05.451+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T19:10:05.451+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T19:10:05.451+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:05.451+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T19:10:05.487+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:10:05,486] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:10:05.487+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:05.486+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:10:05.488+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:10:05,487] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "cd '/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src'"]
[2024-12-14T19:10:05.488+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:05.487+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "cd '/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src'"]
[2024-12-14T19:10:05.497+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:10:05,495] {subprocess.py:99} INFO - Output:
[2024-12-14T19:10:05.498+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:05.495+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T19:10:05.500+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:10:05,500] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:10:05.501+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:05.500+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:10:05.520+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:05.520+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T19:10:05.521+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:05.521+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T13:40:00.064553+00:00, execution_date=20241214T134000, start_date=, end_date=20241214T134005
[2024-12-14T19:10:05.534+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T19:10:05.534+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T19:10:05.534+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T19:10:05.535+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T19:10:05.535+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:05.535+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T19:10:05.553+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:05.553+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T19:10:05.553+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:05.553+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T13:40:00.064553+00:00 [scheduled]>
[2024-12-14T19:10:05.583+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:10:05,583] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:40:00.064553+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:40:00.064553+00:00'
[2024-12-14T19:10:05.584+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:05.583+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:40:00.064553+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:40:00.064553+00:00'
[2024-12-14T19:10:05.584+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T19:10:05.584+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T19:10:05.584+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T19:10:05.584+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T19:10:05.585+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:05.585+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T19:10:05.585+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:10:05,585] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:10:05.586+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:05.585+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:10:05.586+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:10:05,586] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'pwd']
[2024-12-14T19:10:05.587+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:05.586+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'pwd']
[2024-12-14T19:10:05.595+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:10:05,594] {subprocess.py:99} INFO - Output:
[2024-12-14T19:10:05.596+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:05.594+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T19:10:05.597+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:10:05,597] {subprocess.py:106} INFO - /private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpzfi3zc58
[2024-12-14T19:10:05.597+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:05.597+0530] {subprocess.py:106} INFO - /private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpzfi3zc58
[2024-12-14T19:10:05.598+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:10:05,598] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:10:05.599+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:05.598+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:10:05.615+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:05.614+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T19:10:05.615+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:05.615+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T13:40:00.064553+00:00, execution_date=20241214T134000, start_date=, end_date=20241214T134005
[2024-12-14T19:10:05.624+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T19:10:05.624+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T19:10:05.625+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T19:10:05.625+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T19:10:05.626+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:05.626+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=scrape map_index=-1
[2024-12-14T19:10:05.632+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:05.632+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 13:40:00.064553+00:00: manual__2024-12-14T13:40:00.064553+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T19:10:05.632+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T19:10:05.633+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 13:40:00.064553+00:00 end:2024-12-14 13:40:05.632872+00:00
[2024-12-14T19:10:05.633+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:05.633+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 13:40:00.064553+00:00, run_id=manual__2024-12-14T13:40:00.064553+00:00, run_start_date=2024-12-14 13:40:00.064553+00:00, run_end_date=2024-12-14 13:40:05.632872+00:00, run_duration=5.568319, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 13:40:00.064553+00:00, data_interval_end=2024-12-14 13:40:00.064553+00:00, dag_hash=None
[2024-12-14T19:10:05.644+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:10:05.657+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:05.657+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T19:10:05.676+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:10:05.675+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T19:10:05.698+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.649 seconds
[2024-12-14T19:13:09.392+0530] {processor.py:186} INFO - Started process (PID=4983) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:13:09.394+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T19:13:09.396+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:09.395+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:13:09.541+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:09.541+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T19:13:09.557+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:09.556+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 13:43:09.402781+00:00: manual__2024-12-14T13:43:09.402781+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T19:13:09.588+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:09.588+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T19:13:09.589+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:09.589+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T13:43:09.402781+00:00 [scheduled]>
[2024-12-14T19:13:14.616+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:14.616+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T19:13:14.773+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:13:14,773] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:43:09.402781+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:43:09.402781+00:00'
[2024-12-14T19:13:14.773+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:14.773+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:43:09.402781+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:43:09.402781+00:00'
[2024-12-14T19:13:14.785+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T19:13:14.785+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T19:13:14.785+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T19:13:14.785+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T19:13:14.786+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:14.786+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T19:13:14.817+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:13:14,816] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:13:14.817+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:14.816+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:13:14.818+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:13:14,817] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "cd '/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src'"]
[2024-12-14T19:13:14.818+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:14.817+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "cd '/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src'"]
[2024-12-14T19:13:14.826+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:13:14,825] {subprocess.py:99} INFO - Output:
[2024-12-14T19:13:14.827+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:14.825+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T19:13:14.830+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:13:14,830] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:13:14.831+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:14.830+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:13:14.852+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:14.852+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T19:13:14.853+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:14.853+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T13:43:09.402781+00:00, execution_date=20241214T134309, start_date=, end_date=20241214T134314
[2024-12-14T19:13:14.864+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T19:13:14.864+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T19:13:14.864+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T19:13:14.864+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T19:13:14.865+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:14.865+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T19:13:14.882+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:14.882+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T19:13:14.883+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:14.882+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T13:43:09.402781+00:00 [scheduled]>
[2024-12-14T19:13:14.916+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:13:14,916] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:43:09.402781+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:43:09.402781+00:00'
[2024-12-14T19:13:14.917+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:14.916+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:43:09.402781+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:43:09.402781+00:00'
[2024-12-14T19:13:14.917+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T19:13:14.918+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T19:13:14.918+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T19:13:14.918+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T19:13:14.919+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:14.919+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T19:13:14.919+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:13:14,919] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:13:14.920+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:14.919+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:13:14.920+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:13:14,920] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'pwd']
[2024-12-14T19:13:14.921+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:14.920+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'pwd']
[2024-12-14T19:13:14.929+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:13:14,928] {subprocess.py:99} INFO - Output:
[2024-12-14T19:13:14.931+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:14.928+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T19:13:14.932+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:13:14,932] {subprocess.py:106} INFO - /private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpbuhyrp2l
[2024-12-14T19:13:14.933+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:14.932+0530] {subprocess.py:106} INFO - /private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpbuhyrp2l
[2024-12-14T19:13:14.933+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:13:14,933] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:13:14.934+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:14.933+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:13:14.950+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:14.950+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T19:13:14.951+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:14.951+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T13:43:09.402781+00:00, execution_date=20241214T134309, start_date=, end_date=20241214T134314
[2024-12-14T19:13:14.958+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T19:13:14.959+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T19:13:14.959+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T19:13:14.959+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T19:13:14.960+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:14.960+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=scrape map_index=-1
[2024-12-14T19:13:14.964+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:14.964+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 13:43:09.402781+00:00: manual__2024-12-14T13:43:09.402781+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T19:13:14.965+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T19:13:14.965+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 13:43:09.402781+00:00 end:2024-12-14 13:43:14.964999+00:00
[2024-12-14T19:13:14.965+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:14.965+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 13:43:09.402781+00:00, run_id=manual__2024-12-14T13:43:09.402781+00:00, run_start_date=2024-12-14 13:43:09.402781+00:00, run_end_date=2024-12-14 13:43:14.964999+00:00, run_duration=5.562218, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 13:43:09.402781+00:00, data_interval_end=2024-12-14 13:43:09.402781+00:00, dag_hash=None
[2024-12-14T19:13:14.975+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:13:14.987+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:14.987+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T19:13:15.007+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:13:15.007+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T19:13:15.026+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.638 seconds
[2024-12-14T19:16:12.235+0530] {processor.py:186} INFO - Started process (PID=5189) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:16:12.239+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T19:16:12.240+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:12.240+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:16:12.389+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:12.388+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T19:16:12.404+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:12.404+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 13:46:12.246146+00:00: manual__2024-12-14T13:46:12.246146+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T19:16:12.437+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:12.437+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T19:16:12.438+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:12.437+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T13:46:12.246146+00:00 [scheduled]>
[2024-12-14T19:16:17.463+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:17.463+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T19:16:17.608+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:16:17,608] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:46:12.246146+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:46:12.246146+00:00'
[2024-12-14T19:16:17.609+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:17.608+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:46:12.246146+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:46:12.246146+00:00'
[2024-12-14T19:16:17.621+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T19:16:17.621+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T19:16:17.622+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T19:16:17.622+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T19:16:17.622+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:17.622+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T19:16:17.654+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:16:17,654] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:16:17.654+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:17.654+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:16:17.655+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:16:17,655] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "cd '/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src'"]
[2024-12-14T19:16:17.655+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:17.655+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "cd '/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src'"]
[2024-12-14T19:16:17.664+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:16:17,662] {subprocess.py:99} INFO - Output:
[2024-12-14T19:16:17.665+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:17.662+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T19:16:17.667+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:16:17,667] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:16:17.667+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:17.667+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:16:17.687+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:17.687+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T19:16:17.688+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:17.687+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T13:46:12.246146+00:00, execution_date=20241214T134612, start_date=, end_date=20241214T134617
[2024-12-14T19:16:17.699+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T19:16:17.700+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T19:16:17.700+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T19:16:17.700+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T19:16:17.701+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:17.701+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T19:16:17.719+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:17.719+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T19:16:17.719+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:17.719+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T13:46:12.246146+00:00 [scheduled]>
[2024-12-14T19:16:17.747+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:16:17,747] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:46:12.246146+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:46:12.246146+00:00'
[2024-12-14T19:16:17.748+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:17.747+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:46:12.246146+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:46:12.246146+00:00'
[2024-12-14T19:16:17.748+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T19:16:17.748+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T19:16:17.748+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T19:16:17.748+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T19:16:17.749+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:17.749+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T19:16:17.749+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:16:17,749] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:16:17.750+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:17.749+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:16:17.750+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:16:17,750] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'pwd']
[2024-12-14T19:16:17.751+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:17.750+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'pwd']
[2024-12-14T19:16:17.759+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:16:17,758] {subprocess.py:99} INFO - Output:
[2024-12-14T19:16:17.760+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:17.758+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T19:16:17.761+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:16:17,761] {subprocess.py:106} INFO - /private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpifv8_b__
[2024-12-14T19:16:17.761+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:17.761+0530] {subprocess.py:106} INFO - /private/var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T/airflowtmpifv8_b__
[2024-12-14T19:16:17.762+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:16:17,762] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:16:17.762+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:17.762+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:16:17.780+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:17.780+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T19:16:17.781+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:17.781+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T13:46:12.246146+00:00, execution_date=20241214T134612, start_date=, end_date=20241214T134617
[2024-12-14T19:16:17.790+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T19:16:17.791+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T19:16:17.791+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T19:16:17.791+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T19:16:17.792+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:17.792+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=scrape map_index=-1
[2024-12-14T19:16:17.796+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:17.796+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 13:46:12.246146+00:00: manual__2024-12-14T13:46:12.246146+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T19:16:17.797+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T19:16:17.797+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 13:46:12.246146+00:00 end:2024-12-14 13:46:17.797268+00:00
[2024-12-14T19:16:17.798+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:17.798+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 13:46:12.246146+00:00, run_id=manual__2024-12-14T13:46:12.246146+00:00, run_start_date=2024-12-14 13:46:12.246146+00:00, run_end_date=2024-12-14 13:46:17.797268+00:00, run_duration=5.551122, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 13:46:12.246146+00:00, data_interval_end=2024-12-14 13:46:12.246146+00:00, dag_hash=None
[2024-12-14T19:16:17.808+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:16:17.820+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:17.820+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T19:16:17.838+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:16:17.837+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T19:16:17.860+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.629 seconds
[2024-12-14T19:19:40.960+0530] {processor.py:186} INFO - Started process (PID=5589) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:19:40.962+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T19:19:40.964+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:19:40.963+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:19:41.135+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:19:41.135+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T19:19:41.148+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:19:41.148+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 13:49:41.106170+00:00: manual__2024-12-14T13:49:41.106170+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T19:19:41.179+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:19:41.179+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T19:19:41.180+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:19:41.180+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T13:49:41.106170+00:00 [scheduled]>
[2024-12-14T19:19:46.207+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:19:46.207+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T19:19:46.348+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:19:46,348] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:49:41.106170+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:49:41.106170+00:00'
[2024-12-14T19:19:46.348+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:19:46.348+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:49:41.106170+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:49:41.106170+00:00'
[2024-12-14T19:19:46.352+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T19:19:46.352+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T19:19:46.353+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T19:19:46.353+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T19:19:46.353+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:19:46.353+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T19:19:46.382+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:19:46,382] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:19:46.383+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:19:46.382+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:19:46.384+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:19:46,383] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'Scraping start']
[2024-12-14T19:19:46.384+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:19:46.383+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'Scraping start']
[2024-12-14T19:19:46.395+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:19:46,393] {subprocess.py:99} INFO - Output:
[2024-12-14T19:19:46.396+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:19:46.393+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T19:19:46.397+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:19:46,397] {subprocess.py:106} INFO - /bin/bash: Scraping: command not found
[2024-12-14T19:19:46.398+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:19:46.397+0530] {subprocess.py:106} INFO - /bin/bash: Scraping: command not found
[2024-12-14T19:19:46.398+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:19:46,398] {subprocess.py:110} INFO - Command exited with return code 127
[2024-12-14T19:19:46.398+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:19:46.398+0530] {subprocess.py:110} INFO - Command exited with return code 127
[2024-12-14T19:19:46.410+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:19:46,408] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 127.
[2024-12-14T19:19:46.411+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:19:46.408+0530] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 127.
[2024-12-14T19:19:46.413+0530] {logging_mixin.py:190} INFO - Task instance in failure state
[2024-12-14T19:19:46.413+0530] {logging_mixin.py:190} INFO - Task start:None end:2024-12-14 13:49:46.412866+00:00 duration:None
[2024-12-14T19:19:46.413+0530] {logging_mixin.py:190} INFO - Task:<Task(BashOperator): info_mssg> dag:<DAG: movie_pipeline> dagrun:<DagRun movie_pipeline @ 2024-12-14 13:49:41.106170+00:00: manual__2024-12-14T13:49:41.106170+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T19:19:46.414+0530] {logging_mixin.py:190} INFO - Failure caused by Bash command failed. The command returned a non-zero exit code 127.
[2024-12-14T19:19:46.414+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:19:46.414+0530] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T13:49:41.106170+00:00, execution_date=20241214T134941, start_date=, end_date=20241214T134946
[2024-12-14T19:19:46.426+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:19:46.426+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T19:19:46.429+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:19:46.427+0530] {dag.py:3090} ERROR - Task failed; ti=<TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T13:49:41.106170+00:00 [failed]>
Traceback (most recent call last):
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 3083, in test
    _run_task(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/dag.py", line 4400, in _run_task
    ti._run_raw_task(session=session, raise_on_defer=inline_trigger, mark_success=mark_success)
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3005, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3159, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3183, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 417, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/.venv/lib/python3.12/site-packages/airflow/operators/bash.py", line 276, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 127.
[2024-12-14T19:19:46.451+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:19:46.450+0530] {dagrun.py:823} ERROR - Marking run <DagRun movie_pipeline @ 2024-12-14 13:49:41.106170+00:00: manual__2024-12-14T13:49:41.106170+00:00, state:running, queued_at: None. externally triggered: False> failed
[2024-12-14T19:19:46.451+0530] {logging_mixin.py:190} INFO - Dag run  in failure state
[2024-12-14T19:19:46.451+0530] {logging_mixin.py:190} INFO - Dag information:movie_pipeline Run id: manual__2024-12-14T13:49:41.106170+00:00 external trigger: False
[2024-12-14T19:19:46.452+0530] {logging_mixin.py:190} INFO - Failed with message: task_failure
[2024-12-14T19:19:46.452+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:19:46.452+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 13:49:41.106170+00:00, run_id=manual__2024-12-14T13:49:41.106170+00:00, run_start_date=2024-12-14 13:49:41.106170+00:00, run_end_date=2024-12-14 13:49:46.451467+00:00, run_duration=5.345297, state=failed, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 13:49:41.106170+00:00, data_interval_end=2024-12-14 13:49:41.106170+00:00, dag_hash=None
[2024-12-14T19:19:46.462+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:19:46.812+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:19:46.812+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T19:19:46.829+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:19:46.829+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T19:19:46.863+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 5.907 seconds
[2024-12-14T19:24:08.758+0530] {processor.py:186} INFO - Started process (PID=6168) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:24:08.760+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T19:24:08.763+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:08.762+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:24:08.931+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:08.930+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T19:24:08.947+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:08.946+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 13:54:08.894744+00:00: manual__2024-12-14T13:54:08.894744+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T19:24:08.984+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:08.983+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T19:24:08.985+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:08.984+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T13:54:08.894744+00:00 [scheduled]>
[2024-12-14T19:24:14.014+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:14.014+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T19:24:14.172+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:24:14,172] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:54:08.894744+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:54:08.894744+00:00'
[2024-12-14T19:24:14.172+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:14.172+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:54:08.894744+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:54:08.894744+00:00'
[2024-12-14T19:24:14.186+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T19:24:14.186+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T19:24:14.186+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T19:24:14.186+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T19:24:14.187+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:14.187+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T19:24:14.221+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:24:14,220] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:24:14.221+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:14.220+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:24:14.222+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:24:14,222] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "echo 'scraping start'"]
[2024-12-14T19:24:14.224+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:14.222+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "echo 'scraping start'"]
[2024-12-14T19:24:14.232+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:24:14,231] {subprocess.py:99} INFO - Output:
[2024-12-14T19:24:14.233+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:14.231+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T19:24:14.234+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:24:14,234] {subprocess.py:106} INFO - scraping start
[2024-12-14T19:24:14.234+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:14.234+0530] {subprocess.py:106} INFO - scraping start
[2024-12-14T19:24:14.235+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:24:14,235] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:24:14.235+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:14.235+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:24:14.255+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:14.255+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T19:24:14.255+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:14.255+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T13:54:08.894744+00:00, execution_date=20241214T135408, start_date=, end_date=20241214T135414
[2024-12-14T19:24:14.266+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T19:24:14.267+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T19:24:14.268+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T19:24:14.268+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T19:24:14.269+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:14.268+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T19:24:14.293+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:14.293+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T19:24:14.294+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:14.294+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T13:54:08.894744+00:00 [scheduled]>
[2024-12-14T19:24:14.329+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:24:14,328] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:54:08.894744+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:54:08.894744+00:00'
[2024-12-14T19:24:14.329+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:14.328+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:54:08.894744+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:54:08.894744+00:00'
[2024-12-14T19:24:14.329+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T19:24:14.329+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T19:24:14.330+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T19:24:14.330+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T19:24:14.331+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:14.330+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T19:24:14.332+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:24:14,332] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:24:14.334+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:14.332+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:24:14.334+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:24:14,334] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py --run_date 2024-12-14']
[2024-12-14T19:24:14.335+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:14.334+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py --run_date 2024-12-14']
[2024-12-14T19:24:14.345+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:24:14,343] {subprocess.py:99} INFO - Output:
[2024-12-14T19:24:14.346+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:14.343+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T19:24:16.925+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:24:16,925] {subprocess.py:106} INFO - 2024-12-14
[2024-12-14T19:24:16.930+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:16.925+0530] {subprocess.py:106} INFO - 2024-12-14
[2024-12-14T19:24:17.229+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:24:17,229] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:24:17.230+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:17.229+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:24:17.252+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:17.251+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T19:24:17.252+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:17.252+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T13:54:08.894744+00:00, execution_date=20241214T135408, start_date=, end_date=20241214T135417
[2024-12-14T19:24:17.264+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T19:24:17.265+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T19:24:17.265+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T19:24:17.265+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T19:24:17.266+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:17.266+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=scrape map_index=-1
[2024-12-14T19:24:17.271+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:17.270+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 13:54:08.894744+00:00: manual__2024-12-14T13:54:08.894744+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T19:24:17.272+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T19:24:17.272+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 13:54:08.894744+00:00 end:2024-12-14 13:54:17.272014+00:00
[2024-12-14T19:24:17.273+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:17.273+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 13:54:08.894744+00:00, run_id=manual__2024-12-14T13:54:08.894744+00:00, run_start_date=2024-12-14 13:54:08.894744+00:00, run_end_date=2024-12-14 13:54:17.272014+00:00, run_duration=8.37727, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 13:54:08.894744+00:00, data_interval_end=2024-12-14 13:54:08.894744+00:00, dag_hash=None
[2024-12-14T19:24:17.292+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:24:17.645+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:17.644+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T19:24:17.667+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:24:17.666+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T19:24:17.693+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 8.940 seconds
[2024-12-14T19:27:41.016+0530] {processor.py:186} INFO - Started process (PID=6536) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:27:41.017+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T19:27:41.022+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:41.021+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:27:41.216+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:41.216+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T19:27:41.232+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:41.232+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 13:57:41.184018+00:00: manual__2024-12-14T13:57:41.184018+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T19:27:41.266+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:41.265+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T19:27:41.266+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:41.266+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T13:57:41.184018+00:00 [scheduled]>
[2024-12-14T19:27:46.292+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:46.291+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T19:27:46.451+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:27:46,451] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:57:41.184018+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:57:41.184018+00:00'
[2024-12-14T19:27:46.451+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:46.451+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:57:41.184018+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:57:41.184018+00:00'
[2024-12-14T19:27:46.465+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T19:27:46.466+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T19:27:46.466+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T19:27:46.466+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T19:27:46.466+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:46.466+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T19:27:46.504+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:27:46,504] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:27:46.505+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:46.504+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:27:46.507+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:27:46,507] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "echo 'scraping start'"]
[2024-12-14T19:27:46.507+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:46.507+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "echo 'scraping start'"]
[2024-12-14T19:27:46.518+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:27:46,516] {subprocess.py:99} INFO - Output:
[2024-12-14T19:27:46.520+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:46.516+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T19:27:46.524+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:27:46,524] {subprocess.py:106} INFO - scraping start
[2024-12-14T19:27:46.525+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:46.524+0530] {subprocess.py:106} INFO - scraping start
[2024-12-14T19:27:46.525+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:27:46,525] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:27:46.526+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:46.525+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:27:46.552+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:46.552+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T19:27:46.553+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:46.553+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T13:57:41.184018+00:00, execution_date=20241214T135741, start_date=, end_date=20241214T135746
[2024-12-14T19:27:46.566+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T19:27:46.566+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T19:27:46.566+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T19:27:46.566+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T19:27:46.567+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:46.567+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T19:27:46.590+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:46.587+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T19:27:46.591+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:46.591+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T13:57:41.184018+00:00 [scheduled]>
[2024-12-14T19:27:46.625+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:27:46,625] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:57:41.184018+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:57:41.184018+00:00'
[2024-12-14T19:27:46.626+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:46.625+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T13:57:41.184018+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T13:57:41.184018+00:00'
[2024-12-14T19:27:46.626+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T19:27:46.626+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T19:27:46.627+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T19:27:46.627+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T19:27:46.628+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:46.627+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T19:27:46.628+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:27:46,628] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:27:46.629+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:46.628+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:27:46.629+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:27:46,629] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py --run_date 2024-12-14']
[2024-12-14T19:27:46.629+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:46.629+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py --run_date 2024-12-14']
[2024-12-14T19:27:46.640+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:27:46,638] {subprocess.py:99} INFO - Output:
[2024-12-14T19:27:46.641+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:46.638+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T19:27:49.740+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:27:49,740] {subprocess.py:106} INFO - 2024-12-14
[2024-12-14T19:27:49.754+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:49.740+0530] {subprocess.py:106} INFO - 2024-12-14
[2024-12-14T19:27:50.000+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:27:50,000] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:27:50.001+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:50.000+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:27:50.018+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:50.017+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T19:27:50.018+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:50.018+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T13:57:41.184018+00:00, execution_date=20241214T135741, start_date=, end_date=20241214T135750
[2024-12-14T19:27:50.028+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T19:27:50.028+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T19:27:50.029+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T19:27:50.030+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T19:27:50.031+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:50.030+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=scrape map_index=-1
[2024-12-14T19:27:50.035+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:50.035+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 13:57:41.184018+00:00: manual__2024-12-14T13:57:41.184018+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T19:27:50.036+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T19:27:50.036+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 13:57:41.184018+00:00 end:2024-12-14 13:57:50.035906+00:00
[2024-12-14T19:27:50.037+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:50.036+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 13:57:41.184018+00:00, run_id=manual__2024-12-14T13:57:41.184018+00:00, run_start_date=2024-12-14 13:57:41.184018+00:00, run_end_date=2024-12-14 13:57:50.035906+00:00, run_duration=8.851888, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 13:57:41.184018+00:00, data_interval_end=2024-12-14 13:57:41.184018+00:00, dag_hash=None
[2024-12-14T19:27:50.049+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:27:50.067+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:50.067+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T19:27:50.088+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:27:50.088+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T19:27:50.112+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 9.102 seconds
[2024-12-14T19:31:01.065+0530] {processor.py:186} INFO - Started process (PID=6766) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:31:01.068+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T19:31:01.071+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:01.070+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:31:01.229+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:01.229+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T19:31:01.246+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:01.245+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 14:01:01.198899+00:00: manual__2024-12-14T14:01:01.198899+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T19:31:01.280+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:01.280+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T19:31:01.281+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:01.281+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T14:01:01.198899+00:00 [scheduled]>
[2024-12-14T19:31:06.305+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:06.305+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T19:31:06.452+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:31:06,452] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T14:01:01.198899+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T14:01:01.198899+00:00'
[2024-12-14T19:31:06.453+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:06.452+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T14:01:01.198899+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T14:01:01.198899+00:00'
[2024-12-14T19:31:06.465+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T19:31:06.465+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T19:31:06.465+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T19:31:06.466+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T19:31:06.467+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:06.466+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T19:31:06.498+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:31:06,498] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:31:06.498+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:06.498+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:31:06.499+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:31:06,499] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "echo 'scraping start'"]
[2024-12-14T19:31:06.499+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:06.499+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "echo 'scraping start'"]
[2024-12-14T19:31:06.510+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:31:06,507] {subprocess.py:99} INFO - Output:
[2024-12-14T19:31:06.511+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:06.507+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T19:31:06.513+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:31:06,513] {subprocess.py:106} INFO - scraping start
[2024-12-14T19:31:06.514+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:06.513+0530] {subprocess.py:106} INFO - scraping start
[2024-12-14T19:31:06.514+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:31:06,514] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:31:06.514+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:06.514+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:31:06.539+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:06.539+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T19:31:06.540+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:06.540+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T14:01:01.198899+00:00, execution_date=20241214T140101, start_date=, end_date=20241214T140106
[2024-12-14T19:31:06.551+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T19:31:06.551+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T19:31:06.551+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T19:31:06.551+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T19:31:06.552+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:06.552+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T19:31:06.568+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:06.568+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T19:31:06.568+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:06.568+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T14:01:01.198899+00:00 [scheduled]>
[2024-12-14T19:31:06.600+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:31:06,600] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T14:01:01.198899+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T14:01:01.198899+00:00'
[2024-12-14T19:31:06.601+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:06.600+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T14:01:01.198899+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T14:01:01.198899+00:00'
[2024-12-14T19:31:06.602+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T19:31:06.602+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T19:31:06.602+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T19:31:06.602+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T19:31:06.603+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:06.603+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T19:31:06.603+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:31:06,603] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:31:06.604+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:06.603+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:31:06.604+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:31:06,604] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py --run_date 2024-12-14']
[2024-12-14T19:31:06.604+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:06.604+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py --run_date 2024-12-14']
[2024-12-14T19:31:06.614+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:31:06,612] {subprocess.py:99} INFO - Output:
[2024-12-14T19:31:06.615+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:06.612+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T19:31:09.891+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:31:09,891] {subprocess.py:106} INFO - 2024-12-14
[2024-12-14T19:31:09.898+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:09.891+0530] {subprocess.py:106} INFO - 2024-12-14
[2024-12-14T19:31:10.257+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:31:10,257] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:31:10.258+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:10.257+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:31:10.282+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:10.282+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T19:31:10.283+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:10.282+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T14:01:01.198899+00:00, execution_date=20241214T140101, start_date=, end_date=20241214T140110
[2024-12-14T19:31:10.296+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T19:31:10.297+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T19:31:10.297+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T19:31:10.298+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T19:31:10.298+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:10.298+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=scrape map_index=-1
[2024-12-14T19:31:10.305+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:10.305+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 14:01:01.198899+00:00: manual__2024-12-14T14:01:01.198899+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T19:31:10.305+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T19:31:10.305+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 14:01:01.198899+00:00 end:2024-12-14 14:01:10.305647+00:00
[2024-12-14T19:31:10.306+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:10.306+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 14:01:01.198899+00:00, run_id=manual__2024-12-14T14:01:01.198899+00:00, run_start_date=2024-12-14 14:01:01.198899+00:00, run_end_date=2024-12-14 14:01:10.305647+00:00, run_duration=9.106748, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 14:01:01.198899+00:00, data_interval_end=2024-12-14 14:01:01.198899+00:00, dag_hash=None
[2024-12-14T19:31:10.322+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:31:10.345+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:10.345+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T19:31:10.381+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:31:10.381+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T19:31:10.412+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 9.351 seconds
[2024-12-14T19:34:26.107+0530] {processor.py:186} INFO - Started process (PID=7017) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:34:26.110+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T19:34:26.112+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:26.112+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:34:26.323+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:26.323+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T19:34:26.338+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:26.338+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 14:04:26.287574+00:00: manual__2024-12-14T14:04:26.287574+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T19:34:26.379+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:26.378+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T19:34:26.379+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:26.379+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T14:04:26.287574+00:00 [scheduled]>
[2024-12-14T19:34:31.403+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:31.403+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T19:34:31.542+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:34:31,542] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T14:04:26.287574+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T14:04:26.287574+00:00'
[2024-12-14T19:34:31.542+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:31.542+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T14:04:26.287574+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T14:04:26.287574+00:00'
[2024-12-14T19:34:31.546+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T19:34:31.546+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T19:34:31.546+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T19:34:31.546+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T19:34:31.547+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:31.547+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T19:34:31.576+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:34:31,576] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:34:31.576+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:31.576+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:34:31.577+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:34:31,577] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "echo 'scraping start'"]
[2024-12-14T19:34:31.577+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:31.577+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "echo 'scraping start'"]
[2024-12-14T19:34:31.586+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:34:31,584] {subprocess.py:99} INFO - Output:
[2024-12-14T19:34:31.588+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:31.584+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T19:34:31.588+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:34:31,588] {subprocess.py:106} INFO - scraping start
[2024-12-14T19:34:31.589+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:31.588+0530] {subprocess.py:106} INFO - scraping start
[2024-12-14T19:34:31.589+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:34:31,589] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:34:31.590+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:31.589+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:34:31.613+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:31.613+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T19:34:31.614+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:31.614+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T14:04:26.287574+00:00, execution_date=20241214T140426, start_date=, end_date=20241214T140431
[2024-12-14T19:34:31.625+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T19:34:31.625+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T19:34:31.625+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T19:34:31.626+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T19:34:31.626+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:31.626+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T19:34:31.643+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:31.643+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T19:34:31.643+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:31.643+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T14:04:26.287574+00:00 [scheduled]>
[2024-12-14T19:34:31.672+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:34:31,672] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T14:04:26.287574+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T14:04:26.287574+00:00'
[2024-12-14T19:34:31.673+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:31.672+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T14:04:26.287574+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T14:04:26.287574+00:00'
[2024-12-14T19:34:31.673+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T19:34:31.673+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T19:34:31.674+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T19:34:31.674+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T19:34:31.674+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:31.674+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T19:34:31.675+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:34:31,675] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:34:31.676+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:31.675+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:34:31.676+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:34:31,676] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py --run_date 2024-12-14']
[2024-12-14T19:34:31.676+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:31.676+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py --run_date 2024-12-14']
[2024-12-14T19:34:31.687+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:34:31,686] {subprocess.py:99} INFO - Output:
[2024-12-14T19:34:31.688+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:31.686+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T19:34:33.885+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:34:33,884] {subprocess.py:106} INFO - 2024-12-14
[2024-12-14T19:34:33.903+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:33.884+0530] {subprocess.py:106} INFO - 2024-12-14
[2024-12-14T19:34:34.166+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:34:34,166] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:34:34.166+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:34.166+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:34:34.182+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:34.182+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T19:34:34.183+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:34.183+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T14:04:26.287574+00:00, execution_date=20241214T140426, start_date=, end_date=20241214T140434
[2024-12-14T19:34:34.192+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T19:34:34.193+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T19:34:34.193+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T19:34:34.193+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T19:34:34.194+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:34.194+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=scrape map_index=-1
[2024-12-14T19:34:34.202+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:34.201+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 14:04:26.287574+00:00: manual__2024-12-14T14:04:26.287574+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T19:34:34.202+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T19:34:34.203+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 14:04:26.287574+00:00 end:2024-12-14 14:04:34.202618+00:00
[2024-12-14T19:34:34.203+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:34.203+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 14:04:26.287574+00:00, run_id=manual__2024-12-14T14:04:26.287574+00:00, run_start_date=2024-12-14 14:04:26.287574+00:00, run_end_date=2024-12-14 14:04:34.202618+00:00, run_duration=7.915044, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 14:04:26.287574+00:00, data_interval_end=2024-12-14 14:04:26.287574+00:00, dag_hash=None
[2024-12-14T19:34:34.216+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:34:34.236+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:34.236+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T19:34:34.263+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:34:34.263+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T19:34:34.286+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 8.187 seconds
[2024-12-14T19:37:44.963+0530] {processor.py:186} INFO - Started process (PID=7264) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:37:44.965+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T19:37:44.967+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:44.966+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:37:45.212+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:45.211+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T19:37:45.240+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:45.236+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 14:07:45.162071+00:00: manual__2024-12-14T14:07:45.162071+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T19:37:45.286+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:45.285+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T19:37:45.289+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:45.289+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T14:07:45.162071+00:00 [scheduled]>
[2024-12-14T19:37:50.316+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:50.316+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T19:37:50.451+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:37:50,451] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T14:07:45.162071+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T14:07:45.162071+00:00'
[2024-12-14T19:37:50.451+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:50.451+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T14:07:45.162071+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T14:07:45.162071+00:00'
[2024-12-14T19:37:50.454+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T19:37:50.454+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T19:37:50.455+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T19:37:50.455+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T19:37:50.455+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:50.455+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T19:37:50.484+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:37:50,484] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:37:50.485+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:50.484+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:37:50.486+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:37:50,485] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "echo 'scraping start'"]
[2024-12-14T19:37:50.486+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:50.485+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "echo 'scraping start'"]
[2024-12-14T19:37:50.495+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:37:50,493] {subprocess.py:99} INFO - Output:
[2024-12-14T19:37:50.496+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:50.493+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T19:37:50.497+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:37:50,497] {subprocess.py:106} INFO - scraping start
[2024-12-14T19:37:50.498+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:50.497+0530] {subprocess.py:106} INFO - scraping start
[2024-12-14T19:37:50.498+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:37:50,498] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:37:50.498+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:50.498+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:37:50.520+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:50.519+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T19:37:50.520+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:50.520+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T14:07:45.162071+00:00, execution_date=20241214T140745, start_date=, end_date=20241214T140750
[2024-12-14T19:37:50.532+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T19:37:50.532+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T19:37:50.532+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T19:37:50.532+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T19:37:50.533+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:50.533+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T19:37:50.550+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:50.550+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T19:37:50.550+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:50.550+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T14:07:45.162071+00:00 [scheduled]>
[2024-12-14T19:37:50.579+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:37:50,579] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T14:07:45.162071+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T14:07:45.162071+00:00'
[2024-12-14T19:37:50.580+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:50.579+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T14:07:45.162071+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T14:07:45.162071+00:00'
[2024-12-14T19:37:50.580+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T19:37:50.580+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T19:37:50.580+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T19:37:50.581+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T19:37:50.581+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:50.581+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T19:37:50.582+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:37:50,582] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:37:50.583+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:50.582+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T19:37:50.583+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:37:50,583] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py --run_date 2024-12-14']
[2024-12-14T19:37:50.583+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:50.583+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py --run_date 2024-12-14']
[2024-12-14T19:37:50.593+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:37:50,591] {subprocess.py:99} INFO - Output:
[2024-12-14T19:37:50.595+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:50.591+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T19:37:52.950+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:37:52,950] {subprocess.py:106} INFO - 2024-12-14
[2024-12-14T19:37:52.957+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:52.950+0530] {subprocess.py:106} INFO - 2024-12-14
[2024-12-14T19:37:53.322+0530] {logging_mixin.py:190} INFO - [2024-12-14 19:37:53,321] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:37:53.322+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:53.321+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T19:37:53.342+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:53.342+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T19:37:53.344+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:53.343+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T14:07:45.162071+00:00, execution_date=20241214T140745, start_date=, end_date=20241214T140753
[2024-12-14T19:37:53.355+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T19:37:53.356+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T19:37:53.356+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T19:37:53.356+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T19:37:53.357+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:53.356+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=scrape map_index=-1
[2024-12-14T19:37:53.361+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:53.360+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 14:07:45.162071+00:00: manual__2024-12-14T14:07:45.162071+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T19:37:53.361+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T19:37:53.362+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 14:07:45.162071+00:00 end:2024-12-14 14:07:53.361603+00:00
[2024-12-14T19:37:53.365+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:53.365+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 14:07:45.162071+00:00, run_id=manual__2024-12-14T14:07:45.162071+00:00, run_start_date=2024-12-14 14:07:45.162071+00:00, run_end_date=2024-12-14 14:07:53.361603+00:00, run_duration=8.199532, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 14:07:45.162071+00:00, data_interval_end=2024-12-14 14:07:45.162071+00:00, dag_hash=None
[2024-12-14T19:37:53.375+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:37:53.399+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:53.399+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T19:37:53.418+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:37:53.418+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T19:37:53.448+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 8.491 seconds
[2024-12-14T19:41:24.250+0530] {processor.py:186} INFO - Started process (PID=7565) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:41:24.253+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T19:41:24.254+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:41:24.254+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:41:24.378+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:41:24.396+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:41:24.395+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T19:41:24.419+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:41:24.418+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T19:41:24.446+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.199 seconds
[2024-12-14T19:44:18.465+0530] {processor.py:186} INFO - Started process (PID=7768) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:44:18.467+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T19:44:18.468+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:44:18.468+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:44:18.591+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:44:18.608+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:44:18.608+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T19:44:18.629+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:44:18.629+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T19:44:18.651+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.189 seconds
[2024-12-14T19:47:08.500+0530] {processor.py:186} INFO - Started process (PID=7960) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:47:08.501+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T19:47:08.502+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:47:08.502+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:47:08.625+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:47:08.641+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:47:08.641+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T19:47:08.663+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:47:08.662+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T19:47:08.687+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.190 seconds
[2024-12-14T19:49:58.115+0530] {processor.py:186} INFO - Started process (PID=8163) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:49:58.117+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T19:49:58.118+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:49:58.117+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:49:58.268+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:49:58.289+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:49:58.288+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T19:49:58.322+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:49:58.322+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T19:49:58.351+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.239 seconds
[2024-12-14T19:52:47.573+0530] {processor.py:186} INFO - Started process (PID=8364) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:52:47.574+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T19:52:47.575+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:52:47.575+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:52:47.699+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:52:47.716+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:52:47.715+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T19:52:47.736+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:52:47.735+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T19:52:47.759+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.190 seconds
[2024-12-14T19:55:36.529+0530] {processor.py:186} INFO - Started process (PID=8567) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:55:36.531+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T19:55:36.532+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:55:36.532+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:55:36.653+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:55:36.671+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:55:36.671+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T19:55:36.694+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:55:36.694+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T19:55:36.716+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.190 seconds
[2024-12-14T19:58:25.176+0530] {processor.py:186} INFO - Started process (PID=8765) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:58:25.178+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T19:58:25.180+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:58:25.179+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:58:25.303+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T19:58:25.321+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:58:25.320+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T19:58:25.342+0530] {logging_mixin.py:190} INFO - [2024-12-14T19:58:25.342+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T19:58:25.364+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.191 seconds
[2024-12-14T20:01:15.332+0530] {processor.py:186} INFO - Started process (PID=8970) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:01:15.333+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T20:01:15.334+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:01:15.334+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:01:15.457+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:01:15.475+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:01:15.474+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T20:01:15.496+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:01:15.495+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T20:01:15.517+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.189 seconds
[2024-12-14T20:04:03.339+0530] {processor.py:186} INFO - Started process (PID=9163) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:04:03.340+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T20:04:03.341+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:04:03.341+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:04:03.464+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:04:03.481+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:04:03.480+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T20:04:03.502+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:04:03.502+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T20:04:03.524+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.189 seconds
[2024-12-14T20:06:53.277+0530] {processor.py:186} INFO - Started process (PID=9355) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:06:53.278+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T20:06:53.279+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:06:53.279+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:06:53.408+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:06:53.425+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:06:53.425+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T20:06:53.445+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:06:53.445+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T20:06:53.469+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.196 seconds
[2024-12-14T20:10:09.252+0530] {processor.py:186} INFO - Started process (PID=9638) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:10:09.254+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T20:10:09.257+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:10:09.256+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:10:09.390+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:10:09.414+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:10:09.414+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T20:10:09.448+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:10:09.447+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T20:10:09.479+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.232 seconds
[2024-12-14T20:13:19.538+0530] {processor.py:186} INFO - Started process (PID=9860) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:13:19.540+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T20:13:19.541+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:13:19.541+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:13:19.671+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:13:19.688+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:13:19.688+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T20:13:19.711+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:13:19.711+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T20:13:19.736+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.203 seconds
[2024-12-14T20:16:15.983+0530] {processor.py:186} INFO - Started process (PID=10072) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:16:15.986+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T20:16:15.987+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:16:15.987+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:16:16.140+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:16:16.158+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:16:16.157+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T20:16:16.183+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:16:16.182+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T20:16:16.204+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.224 seconds
[2024-12-14T20:19:18.187+0530] {processor.py:186} INFO - Started process (PID=10300) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:19:18.188+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T20:19:18.189+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:19:18.189+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:19:18.316+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:19:18.334+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:19:18.334+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T20:19:18.356+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:19:18.356+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T20:19:18.378+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.196 seconds
[2024-12-14T20:22:08.532+0530] {processor.py:186} INFO - Started process (PID=10514) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:22:08.533+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T20:22:08.534+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:22:08.534+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:22:08.671+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:22:08.691+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:22:08.691+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T20:22:08.712+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:22:08.712+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T20:22:08.735+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.208 seconds
[2024-12-14T20:25:00.234+0530] {processor.py:186} INFO - Started process (PID=10710) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:25:00.235+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T20:25:00.236+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:25:00.236+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:25:00.364+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:25:00.381+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:25:00.380+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T20:25:00.401+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:25:00.401+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T20:25:00.424+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.193 seconds
[2024-12-14T20:28:30.040+0530] {processor.py:186} INFO - Started process (PID=11155) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:28:30.043+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T20:28:30.045+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:30.044+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:28:30.050+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T20:28:30.197+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:30.196+0530] {dag.py:4435} INFO - dagrun id: movie_pipeline
[2024-12-14T20:28:30.212+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:30.212+0530] {dag.py:4451} INFO - created dagrun <DagRun movie_pipeline @ 2024-12-14 14:58:30.167051+00:00: manual__2024-12-14T14:58:30.167051+00:00, state:running, queued_at: None. externally triggered: False>
[2024-12-14T20:28:30.243+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:30.242+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=info_mssg map_index=-1
[2024-12-14T20:28:30.243+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:30.243+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.info_mssg manual__2024-12-14T14:58:30.167051+00:00 [scheduled]>
[2024-12-14T20:28:35.266+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:35.265+0530] {workday.py:41} WARNING - Could not import pandas. Holidays will not be considered.
[2024-12-14T20:28:35.404+0530] {logging_mixin.py:190} INFO - [2024-12-14 20:28:35,404] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T14:58:30.167051+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T14:58:30.167051+00:00'
[2024-12-14T20:28:35.404+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:35.404+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='info_mssg' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T14:58:30.167051+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T14:58:30.167051+00:00'
[2024-12-14T20:28:35.408+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T20:28:35.408+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T20:28:35.408+0530] {logging_mixin.py:190} INFO - Current task name:info_mssg state:scheduled start_date:None
[2024-12-14T20:28:35.408+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T20:28:35.409+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:35.409+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T20:28:35.440+0530] {logging_mixin.py:190} INFO - [2024-12-14 20:28:35,440] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T20:28:35.441+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:35.440+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T20:28:35.441+0530] {logging_mixin.py:190} INFO - [2024-12-14 20:28:35,441] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "echo 'scraping start'"]
[2024-12-14T20:28:35.442+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:35.441+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', "echo 'scraping start'"]
[2024-12-14T20:28:35.450+0530] {logging_mixin.py:190} INFO - [2024-12-14 20:28:35,449] {subprocess.py:99} INFO - Output:
[2024-12-14T20:28:35.451+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:35.449+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T20:28:35.452+0530] {logging_mixin.py:190} INFO - [2024-12-14 20:28:35,452] {subprocess.py:106} INFO - scraping start
[2024-12-14T20:28:35.453+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:35.452+0530] {subprocess.py:106} INFO - scraping start
[2024-12-14T20:28:35.453+0530] {logging_mixin.py:190} INFO - [2024-12-14 20:28:35,453] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T20:28:35.454+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:35.453+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T20:28:35.473+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:35.473+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T20:28:35.474+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:35.473+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=info_mssg, run_id=manual__2024-12-14T14:58:30.167051+00:00, execution_date=20241214T145830, start_date=, end_date=20241214T145835
[2024-12-14T20:28:35.484+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T20:28:35.484+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T20:28:35.485+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T20:28:35.485+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T20:28:35.485+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:35.485+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=info_mssg map_index=-1
[2024-12-14T20:28:35.504+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:35.503+0530] {dag.py:4396} INFO - [DAG TEST] starting task_id=scrape map_index=-1
[2024-12-14T20:28:35.504+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:35.504+0530] {dag.py:4399} INFO - [DAG TEST] running task <TaskInstance: movie_pipeline.scrape manual__2024-12-14T14:58:30.167051+00:00 [scheduled]>
[2024-12-14T20:28:35.534+0530] {logging_mixin.py:190} INFO - [2024-12-14 20:28:35,534] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T14:58:30.167051+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T14:58:30.167051+00:00'
[2024-12-14T20:28:35.535+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:35.534+0530] {taskinstance.py:3132} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='movie_pipeline' AIRFLOW_CTX_TASK_ID='scrape' AIRFLOW_CTX_EXECUTION_DATE='2024-12-14T14:58:30.167051+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-12-14T14:58:30.167051+00:00'
[2024-12-14T20:28:35.535+0530] {logging_mixin.py:190} INFO - Task instance is in running state
[2024-12-14T20:28:35.535+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2024-12-14T20:28:35.536+0530] {logging_mixin.py:190} INFO - Current task name:scrape state:scheduled start_date:None
[2024-12-14T20:28:35.536+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline and current dag run status:running
[2024-12-14T20:28:35.536+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:35.536+0530] {taskinstance.py:731} INFO - ::endgroup::
[2024-12-14T20:28:35.537+0530] {logging_mixin.py:190} INFO - [2024-12-14 20:28:35,537] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T20:28:35.537+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:35.537+0530] {subprocess.py:78} INFO - Tmp dir root location: /var/folders/h6/l2cjrfls77b6_h6zs5w5vn4r0000gn/T
[2024-12-14T20:28:35.537+0530] {logging_mixin.py:190} INFO - [2024-12-14 20:28:35,537] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py --run_date 2024-12-14']
[2024-12-14T20:28:35.538+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:35.537+0530] {subprocess.py:88} INFO - Running command: ['/bin/bash', '-c', 'python controller.py --run_date 2024-12-14']
[2024-12-14T20:28:35.548+0530] {logging_mixin.py:190} INFO - [2024-12-14 20:28:35,546] {subprocess.py:99} INFO - Output:
[2024-12-14T20:28:35.549+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:35.546+0530] {subprocess.py:99} INFO - Output:
[2024-12-14T20:28:37.887+0530] {logging_mixin.py:190} INFO - [2024-12-14 20:28:37,885] {subprocess.py:106} INFO - 2024-12-14
[2024-12-14T20:28:37.889+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:37.885+0530] {subprocess.py:106} INFO - 2024-12-14
[2024-12-14T20:28:38.253+0530] {logging_mixin.py:190} INFO - [2024-12-14 20:28:38,252] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T20:28:38.254+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:38.252+0530] {subprocess.py:110} INFO - Command exited with return code 0
[2024-12-14T20:28:38.276+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:38.275+0530] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2024-12-14T20:28:38.276+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:38.276+0530] {taskinstance.py:352} INFO - Marking task as SUCCESS. dag_id=movie_pipeline, task_id=scrape, run_id=manual__2024-12-14T14:58:30.167051+00:00, execution_date=20241214T145830, start_date=, end_date=20241214T145838
[2024-12-14T20:28:38.287+0530] {logging_mixin.py:190} INFO - Task instance in success state
[2024-12-14T20:28:38.287+0530] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2024-12-14T20:28:38.287+0530] {logging_mixin.py:190} INFO - Dag name:movie_pipeline queued_at:None
[2024-12-14T20:28:38.287+0530] {logging_mixin.py:190} INFO - Task hostname:Jayeshs-MacBook-Air.local operator:BashOperator
[2024-12-14T20:28:38.288+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:38.288+0530] {dag.py:4410} INFO - [DAG TEST] end task task_id=scrape map_index=-1
[2024-12-14T20:28:38.297+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:38.297+0530] {dagrun.py:854} INFO - Marking run <DagRun movie_pipeline @ 2024-12-14 14:58:30.167051+00:00: manual__2024-12-14T14:58:30.167051+00:00, state:running, queued_at: None. externally triggered: False> successful
[2024-12-14T20:28:38.298+0530] {logging_mixin.py:190} INFO - Dag run in success state
[2024-12-14T20:28:38.298+0530] {logging_mixin.py:190} INFO - Dag run start:2024-12-14 14:58:30.167051+00:00 end:2024-12-14 14:58:38.297910+00:00
[2024-12-14T20:28:38.299+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:38.299+0530] {dagrun.py:905} INFO - DagRun Finished: dag_id=movie_pipeline, execution_date=2024-12-14 14:58:30.167051+00:00, run_id=manual__2024-12-14T14:58:30.167051+00:00, run_start_date=2024-12-14 14:58:30.167051+00:00, run_end_date=2024-12-14 14:58:38.297910+00:00, run_duration=8.130859, state=success, external_trigger=False, run_type=manual, data_interval_start=2024-12-13 14:58:30.167051+00:00, data_interval_end=2024-12-14 14:58:30.167051+00:00, dag_hash=None
[2024-12-14T20:28:38.326+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:28:38.355+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:38.354+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T20:28:38.386+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:28:38.386+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T20:28:38.418+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 8.381 seconds
[2024-12-14T20:31:37.304+0530] {processor.py:186} INFO - Started process (PID=11574) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:31:37.306+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T20:31:37.309+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:31:37.308+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:31:37.316+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T20:31:37.443+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:31:37.462+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:31:37.462+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T20:31:37.483+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:31:37.482+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T20:31:37.506+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.209 seconds
[2024-12-14T20:34:31.047+0530] {processor.py:186} INFO - Started process (PID=11799) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:34:31.049+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T20:34:31.054+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:34:31.054+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:34:31.061+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T20:34:31.182+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:34:31.198+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:34:31.198+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T20:34:31.221+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:34:31.221+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T20:34:31.244+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.203 seconds
[2024-12-14T20:37:20.311+0530] {processor.py:186} INFO - Started process (PID=12000) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:37:20.313+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T20:37:20.315+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:37:20.315+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:37:20.322+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T20:37:20.448+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:37:20.466+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:37:20.466+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T20:37:20.487+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:37:20.487+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T20:37:20.509+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.203 seconds
[2024-12-14T20:40:09.031+0530] {processor.py:186} INFO - Started process (PID=12191) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:40:09.032+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T20:40:09.034+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:40:09.033+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:40:09.037+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T20:40:09.170+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:40:09.187+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:40:09.187+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T20:40:09.207+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:40:09.207+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T20:40:09.231+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.203 seconds
[2024-12-14T20:42:59.231+0530] {processor.py:186} INFO - Started process (PID=12383) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:42:59.232+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T20:42:59.233+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:42:59.233+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:42:59.237+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T20:42:59.361+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:42:59.381+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:42:59.381+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T20:42:59.405+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:42:59.405+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T20:42:59.426+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.200 seconds
[2024-12-14T20:45:48.489+0530] {processor.py:186} INFO - Started process (PID=12588) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:45:48.490+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T20:45:48.491+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:45:48.491+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:45:48.495+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T20:45:48.617+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:45:48.634+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:45:48.633+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T20:45:48.655+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:45:48.654+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T20:45:48.677+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.191 seconds
[2024-12-14T20:48:40.638+0530] {processor.py:186} INFO - Started process (PID=12788) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:48:40.643+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T20:48:40.653+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:48:40.653+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:48:40.682+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T20:48:40.967+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:48:40.992+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:48:40.992+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T20:48:41.042+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:48:41.042+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T20:48:41.084+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.455 seconds
[2024-12-14T20:53:03.739+0530] {processor.py:186} INFO - Started process (PID=13060) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:53:03.743+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T20:53:03.746+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:53:03.745+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:53:03.755+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T20:53:04.433+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:53:04.495+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:53:04.494+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T20:53:04.527+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:53:04.526+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T20:53:04.553+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.832 seconds
[2024-12-14T20:57:14.643+0530] {processor.py:186} INFO - Started process (PID=13329) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:57:14.645+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T20:57:14.646+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:57:14.646+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:57:14.654+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T20:57:14.823+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T20:57:14.845+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:57:14.845+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T20:57:14.875+0530] {logging_mixin.py:190} INFO - [2024-12-14T20:57:14.875+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T20:57:14.904+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.266 seconds
[2024-12-14T21:02:04.269+0530] {processor.py:186} INFO - Started process (PID=13614) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:02:04.272+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T21:02:04.273+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:02:04.273+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:02:04.280+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T21:02:04.440+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:02:04.462+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:02:04.461+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T21:02:04.495+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:02:04.495+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T21:02:04.522+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.258 seconds
[2024-12-14T21:05:23.221+0530] {processor.py:186} INFO - Started process (PID=13850) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:05:23.223+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T21:05:23.225+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:05:23.225+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:05:23.230+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T21:05:23.362+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:05:23.380+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:05:23.380+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T21:05:23.404+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:05:23.404+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T21:05:23.427+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.211 seconds
[2024-12-14T21:08:46.447+0530] {processor.py:186} INFO - Started process (PID=14067) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:08:46.450+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T21:08:46.452+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:08:46.451+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:08:46.459+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T21:08:46.582+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:08:46.601+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:08:46.601+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T21:08:46.626+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:08:46.626+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T21:08:46.648+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.206 seconds
[2024-12-14T21:12:42.321+0530] {processor.py:186} INFO - Started process (PID=14303) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:12:42.323+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T21:12:42.325+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:12:42.324+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:12:42.337+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T21:12:42.647+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:12:42.722+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:12:42.721+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T21:12:42.791+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:12:42.791+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T21:12:42.855+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.542 seconds
[2024-12-14T21:16:46.213+0530] {processor.py:186} INFO - Started process (PID=14559) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:16:46.215+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T21:16:46.217+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:16:46.217+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:16:46.225+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T21:16:46.351+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:16:46.369+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:16:46.369+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T21:16:46.394+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:16:46.393+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T21:16:46.417+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.207 seconds
[2024-12-14T21:20:33.246+0530] {processor.py:186} INFO - Started process (PID=14816) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:20:33.251+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T21:20:33.253+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:20:33.252+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:20:33.258+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T21:20:33.421+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:20:33.451+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:20:33.450+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T21:20:33.487+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:20:33.486+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T21:20:33.519+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.278 seconds
[2024-12-14T21:24:41.095+0530] {processor.py:186} INFO - Started process (PID=15061) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:24:41.098+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T21:24:41.100+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:24:41.099+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:24:41.110+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T21:24:41.273+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:24:41.298+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:24:41.298+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T21:24:41.326+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:24:41.326+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T21:24:41.361+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.274 seconds
[2024-12-14T21:29:40.345+0530] {processor.py:186} INFO - Started process (PID=15357) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:29:40.351+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T21:29:40.354+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:29:40.353+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:29:40.369+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T21:29:40.710+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:29:40.744+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:29:40.744+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T21:29:40.796+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:29:40.795+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T21:29:40.852+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.520 seconds
[2024-12-14T21:33:41.541+0530] {processor.py:186} INFO - Started process (PID=15596) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:33:41.545+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T21:33:41.546+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:33:41.546+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:33:41.550+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T21:33:41.803+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:33:41.826+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:33:41.825+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T21:33:41.853+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:33:41.853+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T21:33:41.882+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.347 seconds
[2024-12-14T21:37:49.878+0530] {processor.py:186} INFO - Started process (PID=15839) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:37:49.881+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T21:37:49.885+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:37:49.883+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:37:49.892+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T21:37:50.178+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:37:50.197+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:37:50.196+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T21:37:50.228+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:37:50.228+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T21:37:50.259+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.386 seconds
[2024-12-14T21:41:55.626+0530] {processor.py:186} INFO - Started process (PID=16082) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:41:55.628+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T21:41:55.631+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:41:55.631+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:41:55.637+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T21:41:55.799+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:41:55.820+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:41:55.820+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T21:41:55.853+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:41:55.853+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T21:41:55.883+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.265 seconds
[2024-12-14T21:46:17.540+0530] {processor.py:186} INFO - Started process (PID=16329) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:46:17.543+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T21:46:17.547+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:46:17.546+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:46:17.567+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T21:46:17.789+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:46:17.831+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:46:17.831+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T21:46:17.861+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:46:17.860+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T21:46:17.904+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.368 seconds
[2024-12-14T21:50:58.419+0530] {processor.py:186} INFO - Started process (PID=16606) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:50:58.421+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T21:50:58.423+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:50:58.422+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:50:58.429+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T21:50:58.595+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:50:58.618+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:50:58.617+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T21:50:58.645+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:50:58.644+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T21:50:58.673+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.259 seconds
[2024-12-14T21:55:19.968+0530] {processor.py:186} INFO - Started process (PID=16874) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:55:19.971+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T21:55:19.977+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:55:19.977+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:55:19.988+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T21:55:20.318+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:55:20.385+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:55:20.385+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T21:55:20.455+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:55:20.454+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T21:55:20.500+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.541 seconds
[2024-12-14T21:59:50.461+0530] {processor.py:186} INFO - Started process (PID=17149) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:59:50.463+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T21:59:50.466+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:59:50.465+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:59:50.476+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T21:59:50.652+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T21:59:50.682+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:59:50.681+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T21:59:50.731+0530] {logging_mixin.py:190} INFO - [2024-12-14T21:59:50.731+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T21:59:50.771+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.314 seconds
[2024-12-14T22:03:44.586+0530] {processor.py:186} INFO - Started process (PID=17391) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:03:44.594+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T22:03:44.597+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:03:44.597+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:03:44.602+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T22:03:44.778+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:03:44.802+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:03:44.802+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T22:03:44.833+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:03:44.833+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T22:03:44.857+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.277 seconds
[2024-12-14T22:08:04.945+0530] {processor.py:186} INFO - Started process (PID=17644) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:08:04.948+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T22:08:04.950+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:08:04.950+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:08:04.955+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T22:08:05.125+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:08:05.151+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:08:05.151+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T22:08:05.176+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:08:05.176+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T22:08:05.204+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.262 seconds
[2024-12-14T22:14:09.086+0530] {processor.py:186} INFO - Started process (PID=17973) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:14:09.088+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T22:14:09.091+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:14:09.091+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:14:09.097+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T22:14:09.226+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:14:09.248+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:14:09.247+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T22:14:09.274+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:14:09.273+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T22:14:09.296+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.214 seconds
[2024-12-14T22:17:01.873+0530] {processor.py:186} INFO - Started process (PID=18163) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:17:01.874+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T22:17:01.876+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:17:01.875+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:17:01.880+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T22:17:02.022+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:17:02.039+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:17:02.039+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T22:17:02.062+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:17:02.061+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T22:17:02.084+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.214 seconds
[2024-12-14T22:20:00.988+0530] {processor.py:186} INFO - Started process (PID=18393) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:20:00.990+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T22:20:00.991+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:20:00.991+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:20:00.998+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T22:20:01.114+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:20:01.130+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:20:01.130+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T22:20:01.153+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:20:01.152+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T22:20:01.173+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.189 seconds
[2024-12-14T22:22:48.987+0530] {processor.py:186} INFO - Started process (PID=18593) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:22:48.988+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T22:22:48.990+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:22:48.990+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:22:48.993+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T22:22:49.105+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:22:49.121+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:22:49.121+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T22:22:49.141+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:22:49.140+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T22:22:49.162+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.178 seconds
[2024-12-14T22:25:24.175+0530] {processor.py:186} INFO - Started process (PID=18789) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:25:24.176+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T22:25:24.177+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:25:24.177+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:25:24.181+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T22:25:24.293+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:25:24.309+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:25:24.309+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T22:25:24.330+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:25:24.330+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T22:25:24.352+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.181 seconds
[2024-12-14T22:28:00.963+0530] {processor.py:186} INFO - Started process (PID=18983) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:28:00.964+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T22:28:00.965+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:28:00.965+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:28:00.969+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T22:28:01.079+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:28:01.095+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:28:01.095+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T22:28:01.115+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:28:01.115+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T22:28:01.135+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.176 seconds
[2024-12-14T22:30:39.154+0530] {processor.py:186} INFO - Started process (PID=19175) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:30:39.155+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T22:30:39.156+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:30:39.156+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:30:39.160+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T22:30:39.272+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:30:39.288+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:30:39.288+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T22:30:39.309+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:30:39.309+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T22:30:39.341+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.191 seconds
[2024-12-14T22:33:08.991+0530] {processor.py:186} INFO - Started process (PID=19358) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:33:08.992+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T22:33:08.993+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:33:08.993+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:33:08.997+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T22:33:09.108+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:33:09.124+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:33:09.124+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T22:33:09.144+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:33:09.144+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T22:33:09.164+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.177 seconds
[2024-12-14T22:35:46.757+0530] {processor.py:186} INFO - Started process (PID=19555) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:35:46.758+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T22:35:46.759+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:35:46.759+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:35:46.763+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T22:35:46.876+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:35:46.892+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:35:46.892+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T22:35:46.913+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:35:46.912+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T22:35:46.933+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.180 seconds
[2024-12-14T22:38:19.220+0530] {processor.py:186} INFO - Started process (PID=19739) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:38:19.221+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T22:38:19.222+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:38:19.222+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:38:19.226+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T22:38:19.396+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:38:19.412+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:38:19.412+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T22:38:19.432+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:38:19.432+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T22:38:19.453+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.237 seconds
[2024-12-14T22:40:52.283+0530] {processor.py:186} INFO - Started process (PID=19921) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:40:52.284+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T22:40:52.285+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:40:52.285+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:40:52.289+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T22:40:52.398+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:40:52.415+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:40:52.415+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T22:40:52.435+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:40:52.435+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T22:40:52.457+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.177 seconds
[2024-12-14T22:43:27.237+0530] {processor.py:186} INFO - Started process (PID=20115) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:43:27.239+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T22:43:27.240+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:43:27.239+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:43:27.243+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T22:43:27.356+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:43:27.373+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:43:27.373+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T22:43:27.393+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:43:27.393+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T22:43:27.414+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.180 seconds
[2024-12-14T22:46:00.046+0530] {processor.py:186} INFO - Started process (PID=20299) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:46:00.047+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T22:46:00.048+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:46:00.048+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:46:00.052+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T22:46:00.163+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:46:00.179+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:46:00.179+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T22:46:00.200+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:46:00.200+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T22:46:00.221+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.179 seconds
[2024-12-14T22:48:32.021+0530] {processor.py:186} INFO - Started process (PID=20483) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:48:32.022+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T22:48:32.023+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:48:32.023+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:48:32.027+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T22:48:32.143+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:48:32.159+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:48:32.159+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T22:48:32.179+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:48:32.179+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T22:48:32.200+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.183 seconds
[2024-12-14T22:51:05.517+0530] {processor.py:186} INFO - Started process (PID=20670) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:51:05.519+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T22:51:05.520+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:51:05.520+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:51:05.524+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T22:51:05.635+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:51:05.651+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:51:05.651+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T22:51:05.671+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:51:05.671+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T22:51:05.693+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.179 seconds
[2024-12-14T22:53:38.630+0530] {processor.py:186} INFO - Started process (PID=20866) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:53:38.631+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T22:53:38.632+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:53:38.632+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:53:38.636+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T22:53:38.753+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:53:38.769+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:53:38.769+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T22:53:38.791+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:53:38.790+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T22:53:38.811+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.185 seconds
[2024-12-14T22:56:16.263+0530] {processor.py:186} INFO - Started process (PID=21059) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:56:16.264+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T22:56:16.265+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:56:16.265+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:56:16.268+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T22:56:16.384+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:56:16.400+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:56:16.400+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T22:56:16.420+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:56:16.420+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T22:56:16.441+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.182 seconds
[2024-12-14T22:58:49.356+0530] {processor.py:186} INFO - Started process (PID=21241) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:58:49.357+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T22:58:49.358+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:58:49.358+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:58:49.362+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T22:58:49.472+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T22:58:49.488+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:58:49.488+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T22:58:49.509+0530] {logging_mixin.py:190} INFO - [2024-12-14T22:58:49.508+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T22:58:49.530+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.178 seconds
[2024-12-14T23:01:24.908+0530] {processor.py:186} INFO - Started process (PID=21437) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:01:24.910+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T23:01:24.911+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:01:24.911+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:01:24.916+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T23:01:25.035+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:01:25.051+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:01:25.050+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T23:01:25.071+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:01:25.071+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T23:01:25.092+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.188 seconds
[2024-12-14T23:04:03.044+0530] {processor.py:186} INFO - Started process (PID=21623) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:04:03.045+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T23:04:03.047+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:04:03.046+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:04:03.050+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T23:04:03.163+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:04:03.178+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:04:03.178+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T23:04:03.198+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:04:03.198+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T23:04:03.219+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.178 seconds
[2024-12-14T23:06:41.770+0530] {processor.py:186} INFO - Started process (PID=21810) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:06:41.771+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T23:06:41.772+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:06:41.772+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:06:41.776+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T23:06:41.894+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:06:41.910+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:06:41.910+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T23:06:41.930+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:06:41.930+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T23:06:41.952+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.185 seconds
[2024-12-14T23:09:16.335+0530] {processor.py:186} INFO - Started process (PID=22008) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:09:16.336+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T23:09:16.337+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:09:16.337+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:09:16.341+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T23:09:16.453+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:09:16.469+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:09:16.469+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T23:09:16.489+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:09:16.489+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T23:09:16.510+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.179 seconds
[2024-12-14T23:11:56.244+0530] {processor.py:186} INFO - Started process (PID=22196) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:11:56.245+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T23:11:56.246+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:11:56.246+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:11:56.250+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T23:11:56.360+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:11:56.377+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:11:56.376+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T23:11:56.397+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:11:56.396+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T23:11:56.417+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.177 seconds
[2024-12-14T23:14:31.731+0530] {processor.py:186} INFO - Started process (PID=22381) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:14:31.732+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T23:14:31.734+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:14:31.733+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:14:31.737+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T23:14:31.854+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:14:31.872+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:14:31.872+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T23:14:31.896+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:14:31.896+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T23:14:31.917+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.189 seconds
[2024-12-14T23:17:09.725+0530] {processor.py:186} INFO - Started process (PID=22567) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:17:09.730+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T23:17:09.732+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:17:09.732+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:17:09.736+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T23:17:09.846+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:17:09.862+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:17:09.862+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T23:17:09.888+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:17:09.887+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T23:17:09.909+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.187 seconds
[2024-12-14T23:19:46.880+0530] {processor.py:186} INFO - Started process (PID=22764) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:19:46.881+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T23:19:46.883+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:19:46.882+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:19:46.888+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T23:19:46.999+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:19:47.015+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:19:47.015+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T23:19:47.036+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:19:47.035+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T23:19:47.057+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.182 seconds
[2024-12-14T23:22:22.471+0530] {processor.py:186} INFO - Started process (PID=22964) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:22:22.473+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T23:22:22.474+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:22:22.474+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:22:22.477+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T23:22:22.585+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:22:22.601+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:22:22.601+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T23:22:22.623+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:22:22.623+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T23:22:22.644+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.176 seconds
[2024-12-14T23:24:59.292+0530] {processor.py:186} INFO - Started process (PID=23151) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:24:59.293+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T23:24:59.295+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:24:59.294+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:24:59.299+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T23:24:59.412+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:24:59.428+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:24:59.427+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T23:24:59.448+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:24:59.447+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T23:24:59.469+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.181 seconds
[2024-12-14T23:27:34.993+0530] {processor.py:186} INFO - Started process (PID=23363) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:27:34.994+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T23:27:34.995+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:27:34.995+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:27:34.999+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T23:27:35.110+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:27:35.126+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:27:35.126+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T23:27:35.147+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:27:35.147+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T23:27:35.168+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.179 seconds
[2024-12-14T23:30:08.807+0530] {processor.py:186} INFO - Started process (PID=23551) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:30:08.808+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T23:30:08.809+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:30:08.809+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:30:08.813+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T23:30:08.929+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:30:08.945+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:30:08.945+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T23:30:08.966+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:30:08.966+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T23:30:08.990+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.187 seconds
[2024-12-14T23:32:41.043+0530] {processor.py:186} INFO - Started process (PID=23733) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:32:41.044+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T23:32:41.045+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:32:41.045+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:32:41.049+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T23:32:41.163+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:32:41.180+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:32:41.179+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T23:32:41.200+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:32:41.200+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T23:32:41.222+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.183 seconds
[2024-12-14T23:35:21.232+0530] {processor.py:186} INFO - Started process (PID=23931) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:35:21.233+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T23:35:21.234+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:35:21.234+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:35:21.238+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T23:35:21.350+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:35:21.366+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:35:21.366+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T23:35:21.387+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:35:21.387+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T23:35:21.408+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.180 seconds
[2024-12-14T23:37:59.441+0530] {processor.py:186} INFO - Started process (PID=24120) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:37:59.442+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T23:37:59.443+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:37:59.443+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:37:59.447+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T23:37:59.558+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:37:59.574+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:37:59.573+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T23:37:59.594+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:37:59.593+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T23:37:59.616+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.178 seconds
[2024-12-14T23:40:36.156+0530] {processor.py:186} INFO - Started process (PID=24304) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:40:36.157+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T23:40:36.158+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:40:36.158+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:40:36.162+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T23:40:36.275+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:40:36.292+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:40:36.291+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T23:40:36.312+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:40:36.312+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T23:40:36.333+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.181 seconds
[2024-12-14T23:43:08.955+0530] {processor.py:186} INFO - Started process (PID=24486) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:43:08.956+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T23:43:08.957+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:43:08.957+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:43:08.961+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T23:43:09.082+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:43:09.099+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:43:09.099+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T23:43:09.120+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:43:09.120+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T23:43:09.141+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.190 seconds
[2024-12-14T23:45:46.485+0530] {processor.py:186} INFO - Started process (PID=24685) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:45:46.486+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T23:45:46.488+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:45:46.487+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:45:46.491+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T23:45:46.602+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:45:46.618+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:45:46.618+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T23:45:46.638+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:45:46.638+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T23:45:46.660+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.178 seconds
[2024-12-14T23:48:24.607+0530] {processor.py:186} INFO - Started process (PID=24872) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:48:24.608+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T23:48:24.609+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:48:24.609+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:48:24.613+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T23:48:24.725+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:48:24.741+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:48:24.741+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T23:48:24.763+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:48:24.763+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T23:48:24.783+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.180 seconds
[2024-12-14T23:51:35.071+0530] {processor.py:186} INFO - Started process (PID=25126) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:51:35.076+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T23:51:35.077+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:51:35.077+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:51:35.090+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T23:51:35.327+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:51:35.353+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:51:35.352+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T23:51:35.392+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:51:35.391+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T23:51:35.429+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.364 seconds
[2024-12-14T23:54:44.856+0530] {processor.py:186} INFO - Started process (PID=25344) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:54:44.859+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T23:54:44.860+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:54:44.860+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:54:44.867+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T23:54:44.979+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:54:44.995+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:54:44.994+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T23:54:45.015+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:54:45.015+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T23:54:45.036+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.184 seconds
[2024-12-14T23:57:18.412+0530] {processor.py:186} INFO - Started process (PID=25545) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:57:18.413+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T23:57:18.415+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:57:18.414+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:57:18.418+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T23:57:18.530+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:57:18.546+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:57:18.546+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T23:57:18.566+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:57:18.566+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T23:57:18.588+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.179 seconds
[2024-12-14T23:59:53.687+0530] {processor.py:186} INFO - Started process (PID=25731) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:59:53.689+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-14T23:59:53.691+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:59:53.691+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:59:53.697+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-14T23:59:53.813+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-14T23:59:53.830+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:59:53.829+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-14T23:59:53.850+0530] {logging_mixin.py:190} INFO - [2024-12-14T23:59:53.850+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-14T23:59:53.870+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.187 seconds
[2024-12-15T00:02:39.150+0530] {processor.py:186} INFO - Started process (PID=25938) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:02:39.152+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T00:02:39.154+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:02:39.153+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:02:39.158+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T00:02:39.269+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:02:39.285+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:02:39.285+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T00:02:39.305+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:02:39.305+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T00:02:39.326+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.180 seconds
[2024-12-15T00:05:18.157+0530] {processor.py:186} INFO - Started process (PID=26135) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:05:18.158+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T00:05:18.159+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:05:18.159+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:05:18.163+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T00:05:18.276+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:05:18.292+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:05:18.292+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T00:05:18.313+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:05:18.313+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T00:05:18.334+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.181 seconds
[2024-12-15T00:07:53.756+0530] {processor.py:186} INFO - Started process (PID=26321) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:07:53.757+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T00:07:53.758+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:07:53.758+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:07:53.762+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T00:07:53.932+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:07:53.948+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:07:53.947+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T00:07:53.968+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:07:53.968+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T00:07:53.994+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.242 seconds
[2024-12-15T00:10:27.142+0530] {processor.py:186} INFO - Started process (PID=26502) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:10:27.143+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T00:10:27.144+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:10:27.144+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:10:27.148+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T00:10:27.261+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:10:27.277+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:10:27.277+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T00:10:27.297+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:10:27.297+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T00:10:27.318+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.180 seconds
[2024-12-15T00:13:02.800+0530] {processor.py:186} INFO - Started process (PID=26688) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:13:02.801+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T00:13:02.802+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:13:02.802+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:13:02.806+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T00:13:02.923+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:13:02.939+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:13:02.939+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T00:13:02.960+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:13:02.960+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T00:13:02.981+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.184 seconds
[2024-12-15T00:15:40.819+0530] {processor.py:186} INFO - Started process (PID=26886) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:15:40.820+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T00:15:40.821+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:15:40.821+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:15:40.825+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T00:15:40.946+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:15:40.962+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:15:40.961+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T00:15:40.982+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:15:40.982+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T00:15:41.002+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.187 seconds
[2024-12-15T00:18:14.894+0530] {processor.py:186} INFO - Started process (PID=27070) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:18:14.896+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T00:18:14.897+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:18:14.897+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:18:14.901+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T00:18:15.013+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:18:15.029+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:18:15.029+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T00:18:15.049+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:18:15.049+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T00:18:15.069+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.179 seconds
[2024-12-15T00:20:50.006+0530] {processor.py:186} INFO - Started process (PID=27271) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:20:50.007+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T00:20:50.008+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:20:50.008+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:20:50.012+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T00:20:50.126+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:20:50.143+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:20:50.142+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T00:20:50.163+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:20:50.163+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T00:20:50.184+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.181 seconds
[2024-12-15T00:23:26.553+0530] {processor.py:186} INFO - Started process (PID=27471) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:23:26.554+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T00:23:26.555+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:23:26.555+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:23:26.559+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T00:23:26.696+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:23:26.713+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:23:26.712+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T00:23:26.733+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:23:26.732+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T00:23:26.755+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.205 seconds
[2024-12-15T00:25:58.792+0530] {processor.py:186} INFO - Started process (PID=27664) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:25:58.794+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T00:25:58.795+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:25:58.795+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:25:58.799+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T00:25:58.912+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:25:58.928+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:25:58.928+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T00:25:58.949+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:25:58.948+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T00:25:58.970+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.181 seconds
[2024-12-15T00:28:34.474+0530] {processor.py:186} INFO - Started process (PID=27849) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:28:34.475+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T00:28:34.476+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:28:34.476+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:28:34.480+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T00:28:34.592+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:28:34.608+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:28:34.608+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T00:28:34.628+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:28:34.628+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T00:28:34.648+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.177 seconds
[2024-12-15T00:31:09.145+0530] {processor.py:186} INFO - Started process (PID=28036) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:31:09.146+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T00:31:09.147+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:31:09.147+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:31:09.151+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T00:31:09.263+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:31:09.279+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:31:09.279+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T00:31:09.300+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:31:09.299+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T00:31:09.320+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.178 seconds
[2024-12-15T00:33:44.507+0530] {processor.py:186} INFO - Started process (PID=28232) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:33:44.508+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T00:33:44.509+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:33:44.509+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:33:44.513+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T00:33:44.625+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:33:44.641+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:33:44.641+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T00:33:44.661+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:33:44.661+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T00:33:44.683+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.180 seconds
[2024-12-15T00:36:17.426+0530] {processor.py:186} INFO - Started process (PID=28415) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:36:17.427+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T00:36:17.428+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:36:17.428+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:36:17.432+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T00:36:17.543+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:36:17.559+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:36:17.558+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T00:36:17.579+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:36:17.578+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T00:36:17.599+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.177 seconds
[2024-12-15T00:38:52.657+0530] {processor.py:186} INFO - Started process (PID=28597) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:38:52.658+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T00:38:52.659+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:38:52.659+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:38:52.662+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T00:38:52.774+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:38:52.790+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:38:52.790+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T00:38:52.810+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:38:52.810+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T00:38:52.833+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.180 seconds
[2024-12-15T00:41:30.463+0530] {processor.py:186} INFO - Started process (PID=28800) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:41:30.465+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T00:41:30.467+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:41:30.467+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:41:30.471+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T00:41:30.585+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:41:30.601+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:41:30.601+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T00:41:30.623+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:41:30.623+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T00:41:30.649+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.190 seconds
[2024-12-15T00:44:16.318+0530] {processor.py:186} INFO - Started process (PID=28999) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:44:16.320+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T00:44:16.321+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:44:16.321+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:44:16.326+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T00:44:16.445+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:44:16.462+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:44:16.462+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T00:44:16.485+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:44:16.485+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T00:44:16.506+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.192 seconds
[2024-12-15T00:47:05.281+0530] {processor.py:186} INFO - Started process (PID=29204) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:47:05.283+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T00:47:05.284+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:47:05.284+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:47:05.288+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T00:47:05.398+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:47:05.414+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:47:05.414+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T00:47:05.434+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:47:05.434+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T00:47:05.454+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.176 seconds
[2024-12-15T00:49:40.193+0530] {processor.py:186} INFO - Started process (PID=29402) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:49:40.194+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T00:49:40.196+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:49:40.195+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:49:40.199+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T00:49:40.313+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:49:40.328+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:49:40.328+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T00:49:40.348+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:49:40.348+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T00:49:40.369+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.180 seconds
[2024-12-15T00:52:14.684+0530] {processor.py:186} INFO - Started process (PID=29587) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:52:14.685+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T00:52:14.686+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:52:14.686+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:52:14.690+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T00:52:14.804+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:52:14.819+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:52:14.819+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T00:52:14.839+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:52:14.839+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T00:52:14.860+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.180 seconds
[2024-12-15T00:54:51.165+0530] {processor.py:186} INFO - Started process (PID=29775) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:54:51.166+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T00:54:51.167+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:54:51.167+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:54:51.171+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T00:54:51.289+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:54:51.305+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:54:51.305+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T00:54:51.325+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:54:51.325+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T00:54:51.346+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.187 seconds
[2024-12-15T00:57:22.571+0530] {processor.py:186} INFO - Started process (PID=29974) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:57:22.572+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T00:57:22.573+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:57:22.573+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:57:22.578+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T00:57:22.828+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:57:22.843+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:57:22.843+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T00:57:22.864+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:57:22.864+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T00:57:22.884+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.317 seconds
[2024-12-15T00:59:53.641+0530] {processor.py:186} INFO - Started process (PID=30157) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:59:53.642+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T00:59:53.643+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:59:53.643+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:59:53.647+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T00:59:53.757+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T00:59:53.773+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:59:53.773+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T00:59:53.794+0530] {logging_mixin.py:190} INFO - [2024-12-15T00:59:53.793+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T00:59:53.815+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.177 seconds
[2024-12-15T01:02:24.330+0530] {processor.py:186} INFO - Started process (PID=30338) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:02:24.331+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T01:02:24.333+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:02:24.332+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:02:24.338+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T01:02:24.449+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:02:24.466+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:02:24.465+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T01:02:24.486+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:02:24.485+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T01:02:24.506+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.181 seconds
[2024-12-15T01:04:55.297+0530] {processor.py:186} INFO - Started process (PID=30520) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:04:55.298+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T01:04:55.299+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:04:55.299+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:04:55.304+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T01:04:55.415+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:04:55.431+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:04:55.431+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T01:04:55.451+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:04:55.451+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T01:04:55.473+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.182 seconds
[2024-12-15T01:07:31.627+0530] {processor.py:186} INFO - Started process (PID=30717) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:07:31.628+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T01:07:31.630+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:07:31.629+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:07:31.633+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T01:07:31.743+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:07:31.759+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:07:31.759+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T01:07:31.780+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:07:31.779+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T01:07:31.800+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.177 seconds
[2024-12-15T01:10:06.684+0530] {processor.py:186} INFO - Started process (PID=30902) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:10:06.685+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T01:10:06.687+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:10:06.686+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:10:06.690+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T01:10:06.802+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:10:06.819+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:10:06.818+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T01:10:06.838+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:10:06.838+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T01:10:06.858+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.178 seconds
[2024-12-15T01:12:40.379+0530] {processor.py:186} INFO - Started process (PID=31084) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:12:40.380+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T01:12:40.381+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:12:40.381+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:12:40.385+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T01:12:40.497+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:12:40.513+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:12:40.513+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T01:12:40.534+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:12:40.533+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T01:12:40.554+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.179 seconds
[2024-12-15T01:15:13.041+0530] {processor.py:186} INFO - Started process (PID=31280) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:15:13.042+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T01:15:13.043+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:15:13.043+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:15:13.047+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T01:15:13.160+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:15:13.176+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:15:13.175+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T01:15:13.196+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:15:13.196+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T01:15:13.217+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.180 seconds
[2024-12-15T01:17:46.160+0530] {processor.py:186} INFO - Started process (PID=31461) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:17:46.161+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T01:17:46.163+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:17:46.162+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:17:46.166+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T01:17:46.282+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:17:46.300+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:17:46.299+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T01:17:46.320+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:17:46.320+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T01:17:46.341+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.184 seconds
[2024-12-15T01:20:17.392+0530] {processor.py:186} INFO - Started process (PID=31645) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:20:17.393+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T01:20:17.394+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:20:17.394+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:20:17.398+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T01:20:17.511+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:20:17.527+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:20:17.526+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T01:20:17.547+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:20:17.547+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T01:20:17.567+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.179 seconds
[2024-12-15T01:22:51.583+0530] {processor.py:186} INFO - Started process (PID=31845) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:22:51.584+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T01:22:51.585+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:22:51.585+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:22:51.589+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T01:22:51.699+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:22:51.715+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:22:51.715+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T01:22:51.735+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:22:51.735+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T01:22:51.757+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.178 seconds
[2024-12-15T01:25:27.536+0530] {processor.py:186} INFO - Started process (PID=32040) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:25:27.537+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T01:25:27.538+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:25:27.538+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:25:27.542+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T01:25:27.655+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:25:27.671+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:25:27.670+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T01:25:27.690+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:25:27.690+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T01:25:27.711+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.179 seconds
[2024-12-15T01:28:01.257+0530] {processor.py:186} INFO - Started process (PID=32226) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:28:01.259+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T01:28:01.260+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:28:01.260+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:28:01.265+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T01:28:01.386+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:28:01.402+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:28:01.401+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T01:28:01.425+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:28:01.425+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T01:28:01.446+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.193 seconds
[2024-12-15T01:30:34.195+0530] {processor.py:186} INFO - Started process (PID=32414) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:30:34.196+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T01:30:34.198+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:30:34.198+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:30:34.202+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T01:30:34.321+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:30:34.339+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:30:34.339+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T01:30:34.363+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:30:34.363+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T01:30:34.383+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.192 seconds
[2024-12-15T01:33:10.779+0530] {processor.py:186} INFO - Started process (PID=32600) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:33:10.780+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T01:33:10.781+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:33:10.781+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:33:10.785+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T01:33:10.895+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:33:10.911+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:33:10.911+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T01:33:10.931+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:33:10.931+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T01:33:10.952+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.176 seconds
[2024-12-15T01:35:43.641+0530] {processor.py:186} INFO - Started process (PID=32795) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:35:43.642+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T01:35:43.643+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:35:43.643+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:35:43.647+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T01:35:43.761+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:35:43.776+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:35:43.776+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T01:35:43.798+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:35:43.798+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T01:35:43.825+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.188 seconds
[2024-12-15T01:38:16.985+0530] {processor.py:186} INFO - Started process (PID=32977) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:38:16.987+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T01:38:16.988+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:38:16.988+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:38:16.994+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T01:38:17.117+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:38:17.134+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:38:17.134+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T01:38:17.155+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:38:17.155+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T01:38:17.180+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.199 seconds
[2024-12-15T01:40:52.552+0530] {processor.py:186} INFO - Started process (PID=33162) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:40:52.553+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T01:40:52.555+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:40:52.554+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:40:52.558+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T01:40:52.670+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:40:52.686+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:40:52.686+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T01:40:52.706+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:40:52.706+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T01:40:52.727+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.179 seconds
[2024-12-15T01:43:30.878+0530] {processor.py:186} INFO - Started process (PID=33361) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:43:30.879+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T01:43:30.880+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:43:30.880+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:43:30.884+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T01:43:30.995+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:43:31.011+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:43:31.011+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T01:43:31.031+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:43:31.030+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T01:43:31.052+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.178 seconds
[2024-12-15T01:46:06.518+0530] {processor.py:186} INFO - Started process (PID=33546) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:46:06.519+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T01:46:06.520+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:46:06.520+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:46:06.524+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T01:46:06.635+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:46:06.650+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:46:06.650+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T01:46:06.671+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:46:06.670+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T01:46:06.691+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.177 seconds
[2024-12-15T01:48:42.943+0530] {processor.py:186} INFO - Started process (PID=33730) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:48:42.944+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T01:48:42.945+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:48:42.945+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:48:42.949+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T01:48:43.058+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:48:43.074+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:48:43.074+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T01:48:43.095+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:48:43.095+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T01:48:43.116+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.177 seconds
[2024-12-15T01:51:22.473+0530] {processor.py:186} INFO - Started process (PID=33936) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:51:22.475+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T01:51:22.476+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:51:22.475+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:51:22.480+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T01:51:22.591+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:51:22.607+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:51:22.606+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T01:51:22.627+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:51:22.627+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T01:51:22.649+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.179 seconds
[2024-12-15T01:53:56.494+0530] {processor.py:186} INFO - Started process (PID=34121) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:53:56.496+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T01:53:56.497+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:53:56.497+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:53:56.501+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T01:53:56.611+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:53:56.627+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:53:56.627+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T01:53:56.649+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:53:56.649+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T01:53:56.670+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.179 seconds
[2024-12-15T01:56:28.660+0530] {processor.py:186} INFO - Started process (PID=34310) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:56:28.661+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T01:56:28.663+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:56:28.662+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:56:28.666+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T01:56:28.777+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:56:28.793+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:56:28.793+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T01:56:28.814+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:56:28.814+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T01:56:28.835+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.178 seconds
[2024-12-15T01:59:06.050+0530] {processor.py:186} INFO - Started process (PID=34496) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:59:06.051+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T01:59:06.052+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:59:06.052+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:59:06.056+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T01:59:06.168+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T01:59:06.184+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:59:06.184+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T01:59:06.204+0530] {logging_mixin.py:190} INFO - [2024-12-15T01:59:06.204+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T01:59:06.225+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.178 seconds
[2024-12-15T02:01:41.565+0530] {processor.py:186} INFO - Started process (PID=34693) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:01:41.567+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T02:01:41.568+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:01:41.568+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:01:41.572+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T02:01:41.683+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:01:41.700+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:01:41.699+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T02:01:41.721+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:01:41.721+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T02:01:41.742+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.180 seconds
[2024-12-15T02:04:13.141+0530] {processor.py:186} INFO - Started process (PID=34874) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:04:13.142+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T02:04:13.143+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:04:13.143+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:04:13.147+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T02:04:13.264+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:04:13.280+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:04:13.280+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T02:04:13.300+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:04:13.300+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T02:04:13.321+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.184 seconds
[2024-12-15T02:06:46.237+0530] {processor.py:186} INFO - Started process (PID=35058) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:06:46.238+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T02:06:46.239+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:06:46.239+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:06:46.243+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T02:06:46.356+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:06:46.372+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:06:46.371+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T02:06:46.394+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:06:46.392+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T02:06:46.418+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.184 seconds
[2024-12-15T02:09:23.597+0530] {processor.py:186} INFO - Started process (PID=35254) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:09:23.598+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T02:09:23.600+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:09:23.600+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:09:23.604+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T02:09:23.715+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:09:23.730+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:09:23.730+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T02:09:23.751+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:09:23.750+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T02:09:23.771+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.177 seconds
[2024-12-15T02:11:58.205+0530] {processor.py:186} INFO - Started process (PID=35440) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:11:58.206+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T02:11:58.207+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:11:58.207+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:11:58.211+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T02:11:58.323+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:11:58.339+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:11:58.339+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T02:11:58.360+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:11:58.360+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T02:11:58.382+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.180 seconds
[2024-12-15T02:14:33.571+0530] {processor.py:186} INFO - Started process (PID=35622) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:14:33.572+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T02:14:33.573+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:14:33.573+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:14:33.577+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T02:14:33.689+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:14:33.705+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:14:33.704+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T02:14:33.726+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:14:33.726+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T02:14:33.746+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.179 seconds
[2024-12-15T02:17:09.176+0530] {processor.py:186} INFO - Started process (PID=35805) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:17:09.178+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T02:17:09.179+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:17:09.179+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:17:09.182+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T02:17:09.296+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:17:09.312+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:17:09.312+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T02:17:09.332+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:17:09.332+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T02:17:09.353+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.180 seconds
[2024-12-15T02:19:45.858+0530] {processor.py:186} INFO - Started process (PID=36002) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:19:45.859+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T02:19:45.860+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:19:45.860+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:19:45.864+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T02:19:45.975+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:19:45.991+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:19:45.991+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T02:19:46.011+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:19:46.011+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T02:19:46.032+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.177 seconds
[2024-12-15T02:22:20.479+0530] {processor.py:186} INFO - Started process (PID=36203) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:22:20.480+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T02:22:20.481+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:22:20.481+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:22:20.485+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T02:22:20.597+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:22:20.613+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:22:20.613+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T02:22:20.633+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:22:20.633+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T02:22:20.654+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.179 seconds
[2024-12-15T02:24:53.147+0530] {processor.py:186} INFO - Started process (PID=36389) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:24:53.149+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T02:24:53.150+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:24:53.150+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:24:53.154+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T02:24:53.267+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:24:53.283+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:24:53.282+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T02:24:53.304+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:24:53.303+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T02:24:53.324+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.180 seconds
[2024-12-15T02:27:29.233+0530] {processor.py:186} INFO - Started process (PID=36589) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:27:29.234+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T02:27:29.236+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:27:29.235+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:27:29.239+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T02:27:29.354+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:27:29.370+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:27:29.370+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T02:27:29.390+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:27:29.390+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T02:27:29.411+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.182 seconds
[2024-12-15T02:30:04.550+0530] {processor.py:186} INFO - Started process (PID=36775) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:30:04.552+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T02:30:04.553+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:30:04.552+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:30:04.557+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T02:30:04.667+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:30:04.683+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:30:04.683+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T02:30:04.703+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:30:04.703+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T02:30:04.724+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.177 seconds
[2024-12-15T02:32:40.513+0530] {processor.py:186} INFO - Started process (PID=36962) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:32:40.515+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T02:32:40.516+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:32:40.515+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:32:40.520+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T02:32:40.634+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:32:40.650+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:32:40.650+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T02:32:40.670+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:32:40.670+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T02:32:40.691+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.183 seconds
[2024-12-15T02:35:15.921+0530] {processor.py:186} INFO - Started process (PID=37156) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:35:15.922+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T02:35:15.923+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:35:15.923+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:35:15.927+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T02:35:16.036+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:35:16.052+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:35:16.051+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T02:35:16.073+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:35:16.073+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T02:35:16.094+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.177 seconds
[2024-12-15T02:37:51.558+0530] {processor.py:186} INFO - Started process (PID=37340) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:37:51.559+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T02:37:51.561+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:37:51.560+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:37:51.564+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T02:37:51.680+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:37:51.696+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:37:51.696+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T02:37:51.717+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:37:51.717+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T02:37:51.738+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.183 seconds
[2024-12-15T02:40:30.568+0530] {processor.py:186} INFO - Started process (PID=37530) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:40:30.570+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T02:40:30.571+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:40:30.571+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:40:30.575+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T02:40:30.685+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:40:30.701+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:40:30.700+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T02:40:30.721+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:40:30.721+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T02:40:30.741+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.176 seconds
[2024-12-15T02:43:16.138+0530] {processor.py:186} INFO - Started process (PID=37757) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:43:16.139+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T02:43:16.141+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:43:16.140+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:43:16.145+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T02:43:16.262+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:43:16.278+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:43:16.278+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T02:43:16.301+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:43:16.301+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T02:43:16.323+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.190 seconds
[2024-12-15T02:45:52.610+0530] {processor.py:186} INFO - Started process (PID=37949) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:45:52.611+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T02:45:52.612+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:45:52.612+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:45:52.616+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T02:45:52.729+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:45:52.745+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:45:52.745+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T02:45:52.765+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:45:52.765+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T02:45:52.785+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.179 seconds
[2024-12-15T02:48:24.467+0530] {processor.py:186} INFO - Started process (PID=38134) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:48:24.468+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T02:48:24.469+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:48:24.469+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:48:24.473+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T02:48:24.595+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:48:24.611+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:48:24.611+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T02:48:24.631+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:48:24.631+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T02:48:24.651+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.188 seconds
[2024-12-15T02:50:56.694+0530] {processor.py:186} INFO - Started process (PID=38314) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:50:56.695+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T02:50:56.696+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:50:56.696+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:50:56.700+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T02:50:56.811+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:50:56.826+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:50:56.826+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T02:50:56.848+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:50:56.847+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T02:50:56.868+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.178 seconds
[2024-12-15T02:53:31.308+0530] {processor.py:186} INFO - Started process (PID=38507) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:53:31.309+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T02:53:31.310+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:53:31.310+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:53:31.314+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T02:53:31.428+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:53:31.444+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:53:31.444+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T02:53:31.464+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:53:31.464+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T02:53:31.485+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.181 seconds
[2024-12-15T02:56:04.442+0530] {processor.py:186} INFO - Started process (PID=38696) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:56:04.443+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T02:56:04.444+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:56:04.444+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:56:04.448+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T02:56:04.559+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:56:04.575+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:56:04.574+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T02:56:04.599+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:56:04.599+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T02:56:04.620+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.182 seconds
[2024-12-15T02:58:34.758+0530] {processor.py:186} INFO - Started process (PID=38882) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:58:34.760+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T02:58:34.761+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:58:34.761+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:58:34.764+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T02:58:34.876+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T02:58:34.892+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:58:34.892+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T02:58:34.912+0530] {logging_mixin.py:190} INFO - [2024-12-15T02:58:34.911+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T02:58:34.932+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.177 seconds
[2024-12-15T03:01:10.119+0530] {processor.py:186} INFO - Started process (PID=39071) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:01:10.120+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T03:01:10.121+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:01:10.121+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:01:10.125+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T03:01:10.237+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:01:10.253+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:01:10.253+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T03:01:10.273+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:01:10.273+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T03:01:10.295+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.179 seconds
[2024-12-15T03:03:42.725+0530] {processor.py:186} INFO - Started process (PID=39264) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:03:42.727+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T03:03:42.728+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:03:42.728+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:03:42.732+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T03:03:42.843+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:03:42.859+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:03:42.859+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T03:03:42.880+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:03:42.879+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T03:03:42.901+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.179 seconds
[2024-12-15T03:06:15.886+0530] {processor.py:186} INFO - Started process (PID=39445) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:06:15.888+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T03:06:15.889+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:06:15.889+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:06:15.892+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T03:06:16.005+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:06:16.021+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:06:16.020+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T03:06:16.041+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:06:16.040+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T03:06:16.061+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.178 seconds
[2024-12-15T03:08:48.404+0530] {processor.py:186} INFO - Started process (PID=39625) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:08:48.405+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T03:08:48.407+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:08:48.406+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:08:48.410+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T03:08:48.525+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:08:48.541+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:08:48.541+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T03:08:48.561+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:08:48.561+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T03:08:48.582+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.182 seconds
[2024-12-15T03:11:20.418+0530] {processor.py:186} INFO - Started process (PID=39816) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:11:20.419+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T03:11:20.420+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:11:20.420+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:11:20.424+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T03:11:20.537+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:11:20.553+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:11:20.552+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T03:11:20.573+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:11:20.572+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T03:11:20.594+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.179 seconds
[2024-12-15T03:13:53.412+0530] {processor.py:186} INFO - Started process (PID=39998) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:13:53.413+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T03:13:53.414+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:13:53.414+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:13:53.418+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T03:13:53.533+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:13:53.549+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:13:53.549+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T03:13:53.569+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:13:53.569+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T03:13:53.590+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.182 seconds
[2024-12-15T03:16:26.244+0530] {processor.py:186} INFO - Started process (PID=40180) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:16:26.245+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T03:16:26.246+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:16:26.246+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:16:26.250+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T03:16:26.361+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:16:26.376+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:16:26.376+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T03:16:26.396+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:16:26.396+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T03:16:26.424+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.183 seconds
[2024-12-15T03:18:59.140+0530] {processor.py:186} INFO - Started process (PID=40366) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:18:59.141+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T03:18:59.143+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:18:59.142+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:18:59.147+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T03:18:59.258+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:18:59.273+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:18:59.273+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T03:18:59.293+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:18:59.293+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T03:18:59.314+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.177 seconds
[2024-12-15T03:21:31.398+0530] {processor.py:186} INFO - Started process (PID=40575) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:21:31.400+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T03:21:31.401+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:21:31.401+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:21:31.405+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T03:21:31.521+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:21:31.537+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:21:31.537+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T03:21:31.559+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:21:31.558+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T03:21:31.579+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.185 seconds
[2024-12-15T03:24:04.204+0530] {processor.py:186} INFO - Started process (PID=40761) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:24:04.205+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T03:24:04.206+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:24:04.206+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:24:04.210+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T03:24:04.320+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:24:04.336+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:24:04.336+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T03:24:04.356+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:24:04.356+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T03:24:04.377+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.176 seconds
[2024-12-15T03:26:39.215+0530] {processor.py:186} INFO - Started process (PID=40949) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:26:39.216+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T03:26:39.218+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:26:39.217+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:26:39.221+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T03:26:39.335+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:26:39.351+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:26:39.351+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T03:26:39.372+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:26:39.371+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T03:26:39.392+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.180 seconds
[2024-12-15T03:29:16.227+0530] {processor.py:186} INFO - Started process (PID=41144) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:29:16.228+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T03:29:16.230+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:29:16.229+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:29:16.233+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T03:29:16.343+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:29:16.358+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:29:16.358+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T03:29:16.379+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:29:16.379+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T03:29:16.401+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.177 seconds
[2024-12-15T03:31:51.132+0530] {processor.py:186} INFO - Started process (PID=41330) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:31:51.134+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T03:31:51.135+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:31:51.135+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:31:51.139+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T03:31:51.250+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:31:51.266+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:31:51.265+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T03:31:51.286+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:31:51.286+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T03:31:51.306+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.178 seconds
[2024-12-15T03:34:23.576+0530] {processor.py:186} INFO - Started process (PID=41515) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:34:23.577+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T03:34:23.578+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:34:23.578+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:34:23.582+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T03:34:23.702+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T03:34:23.719+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:34:23.718+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T03:34:23.745+0530] {logging_mixin.py:190} INFO - [2024-12-15T03:34:23.744+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T03:34:23.765+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.193 seconds
[2024-12-15T04:23:29.039+0530] {processor.py:186} INFO - Started process (PID=41798) to work on /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T04:23:29.040+0530] {processor.py:914} INFO - Processing file /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py for tasks to queue
[2024-12-15T04:23:29.041+0530] {logging_mixin.py:190} INFO - [2024-12-15T04:23:29.041+0530] {dagbag.py:588} INFO - Filling up the DagBag from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T04:23:29.045+0530] {logging_mixin.py:190} INFO - The dag start data: 2024-12-14 01:30:00+00:00
[2024-12-15T04:23:29.153+0530] {processor.py:925} INFO - DAG(s) 'movie_pipeline' retrieved from /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py
[2024-12-15T04:23:29.168+0530] {logging_mixin.py:190} INFO - [2024-12-15T04:23:29.168+0530] {dag.py:3239} INFO - Sync 1 DAGs
[2024-12-15T04:23:29.188+0530] {logging_mixin.py:190} INFO - [2024-12-15T04:23:29.188+0530] {dag.py:4180} INFO - Setting next_dagrun for movie_pipeline to 2024-12-14 01:30:00+00:00, run_after=2024-12-15 01:30:00+00:00
[2024-12-15T04:23:29.209+0530] {processor.py:208} INFO - Processing /Users/jayesh/Desktop/Personal Work/Movie_data_pipeline/src/Airflow/dags/pipeline_dag.py took 0.174 seconds
