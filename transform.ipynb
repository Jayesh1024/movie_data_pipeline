{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/25 22:45:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Creating spark session\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import explode\n",
    "import os\n",
    "spark=(\n",
    "    SparkSession.builder\n",
    "    .master('local[3]')\n",
    "    .appName('transformApp')\n",
    "    .config('spark.jars','postgresql-42.7.4.jar')\n",
    "    .config('spark.driver.extraClassPath','postgresql-42.6.2.jar')\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Loading the data into spark DataFrames\n",
    "df_boxoffice=spark.read.json('collection_parsed_2024116.json',multiLine=True)\n",
    "df_movie_raw=spark.read.json('movies_parsed_2024116.json',multiLine=True)\n",
    "df_filmmaker_raw=spark.read.json('filmmaker_parsed_2024116.json',multiLine=True)\n",
    "df_genre_raw=spark.read.json('genre_parsed_2024116.json',multiLine=True)\n",
    "df_distributor_raw=spark.read.json('distributor_parsed_2024116.json',multiLine=True)\n",
    "\n",
    "\n",
    "\n",
    "# Shaping the data in desired format from raw DataFrames\n",
    "df_movie=(\n",
    "    df_movie_raw.select(explode(df_movie_raw.content).alias('movies'),'extracted_at','run_date')\n",
    "        .select('movies.*','extracted_at','run_date')       \n",
    ")\n",
    "\n",
    "df_genre=(\n",
    "    df_genre_raw.select(explode(df_genre_raw.content).alias('genre'),'extracted_at','run_date')\n",
    "        .select('genre.*','extracted_at','run_date')      \n",
    ")\n",
    "\n",
    "df_filmmaker=(\n",
    "    df_filmmaker_raw.select(explode(df_filmmaker_raw.content).alias('filmmaker'),'extracted_at','run_date')\n",
    "        .select('filmmaker.*','extracted_at','run_date')       \n",
    ")\n",
    "\n",
    "df_distributor=(\n",
    "    df_distributor_raw.select(explode(df_distributor_raw.content).alias('distributor'),'extracted_at','run_date')\n",
    "        .select('distributor.*','extracted_at','run_date')       \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Bridge table b/w movies and genre dimension\n",
    "bridge_movie_genre=df_genre.select('genre_id','movie_id')\n",
    "\n",
    "# Bridge table b/w movies and filmmaker dimension\n",
    "bridge_filmmaker_movie=(\n",
    "    df_movie.withColumn('filmmaker',explode(df_movie['filmmakers']))\n",
    "        .select('filmmaker','movie_id')\n",
    "        .select('filmmaker.filmmaker_id','filmmaker.role','movie_id')     \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Removing the duplicate values from dim_genre and dim_filmmaker which got created due to the many to many relationship b/w (genre,filmmaker) and movies\n",
    "# Also dropping the movie_id as it does not match the dimension model schema for the corresponding dims\n",
    "df_genre=(\n",
    "    df_genre.dropDuplicates(['genre_id'])\n",
    "            .drop('movie_id')\n",
    ")\n",
    "df_filmmaker=(\n",
    "    df_filmmaker.dropDuplicates(['filmmaker_id'])\n",
    "                .drop('movie_id')\n",
    ")\n",
    "\n",
    "\n",
    "# Adding the movie_id field in the df_boxoffice DataFrame using the df_movie DataFrame\n",
    "df_boxoffice=df_boxoffice.join(other=df_movie.select(['release_id','movie_id']),on='release_id',how='left')\n",
    "\n",
    "\n",
    "# Cleaning fields to remove \"$\" and \",\" charachters from the fields\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "df_boxoffice=(\n",
    "    df_boxoffice.withColumns({\n",
    "        \"collection_domestic\":regexp_replace('collection_domestic',r'[\\$\\,]',''),\n",
    "        \"days_post_release\":regexp_replace('days_post_release',r'[\\,]',''),\n",
    "        \"num_theatres\":regexp_replace('num_theatres',r'[\\,]','')\n",
    "    })\n",
    ")\n",
    "\n",
    "df_distributor=(\n",
    "    df_distributor.withColumn(\"total_movies\",regexp_replace(\"total_movies\",r'\\,',''))\n",
    ")\n",
    "\n",
    "\n",
    "# Adding calculated field \"post_release_days\" to the df_movie DataFrame\n",
    "from pyspark.sql.functions import to_date,date_diff,current_date\n",
    "df_movie=df_movie.withColumn('post_release_days',\n",
    "                    date_diff(\n",
    "                        start=to_date('release_date_id',\n",
    "                        format=\"yyyyMMdd\"),\n",
    "                        end=current_date()\n",
    "                    )\n",
    ")\n",
    "\n",
    "# Casting fields of all DataFrames to appropriate data types\n",
    "df_movie=(\n",
    "    df_movie.withColumns({\n",
    "    \"release_date_id\":df_movie.release_date_id.cast(IntegerType()),\n",
    "    \"duration\":df_movie.duration.cast(IntegerType()),\n",
    "    \"widest_release\":df_movie.widest_release.cast(IntegerType()),\n",
    "    \"imdb_rating\":df_movie.imdb_rating.cast(FloatType()),\n",
    "    \"num_of_rating\":df_movie.num_of_rating.cast(IntegerType()),\n",
    "    \"extracted_at\":df_movie.extracted_at.cast(IntegerType()),\n",
    "    \"run_date\":df_movie.run_date.cast(IntegerType())\n",
    "    })\n",
    ")\n",
    "\n",
    "df_genre=(\n",
    "    df_genre.withColumns({\n",
    "        \"total_movies\":df_genre.total_movies.cast(IntegerType()),\n",
    "        \"extracted_at\":df_genre.extracted_at.cast(IntegerType()),\n",
    "        \"run_date\":df_genre.run_date.cast(IntegerType())\n",
    "    })\n",
    ")\n",
    "\n",
    "df_filmmaker=(\n",
    "    df_filmmaker.withColumns({\n",
    "        \"dob\":df_filmmaker.dob.cast(DateType()),\n",
    "        \"total_movies\":df_filmmaker.total_movies.cast(IntegerType()),\n",
    "        \"extracted_at\":df_filmmaker.extracted_at.cast(IntegerType()),\n",
    "        \"run_date\":df_filmmaker.run_date.cast(IntegerType())\n",
    "    })\n",
    ")\n",
    "\n",
    "df_distributor=(\n",
    "    df_distributor.withColumns({\n",
    "        \"total_movies\":df_distributor.total_movies.cast(IntegerType()),\n",
    "        \"extracted_at\":df_distributor.extracted_at.cast(IntegerType()),\n",
    "        \"run_date\":df_distributor.run_date.cast(IntegerType())\n",
    "    })\n",
    ")\n",
    "\n",
    "df_boxoffice=(\n",
    "    df_boxoffice.withColumns({\n",
    "        \"run_date\":df_boxoffice.run_date.cast(IntegerType()),\n",
    "        \"collection_domestic\":df_boxoffice.collection_domestic.cast(FloatType()),\n",
    "        \"days_post_release\":df_boxoffice.days_post_release.cast(IntegerType()),\n",
    "        \"num_of_releases\":df_boxoffice.num_of_releases.cast(IntegerType()),\n",
    "        \"rank\":df_boxoffice.rank.cast(IntegerType()),\n",
    "        \"num_theatres\":df_boxoffice.num_theatres.cast(IntegerType()),\n",
    "        \"extracted_at\":df_boxoffice.extracted_at.cast(IntegerType())\n",
    "    })\n",
    ")\n",
    "\n",
    "\n",
    "# Adding the field \"age\" to DataFrame \"df_filmmaker\"\n",
    "df_filmmaker=df_filmmaker.withColumn('age',(date_diff(end=current_date(),start='dob')/365).cast(IntegerType()))\n",
    "\n",
    "# Dropping the \"filmmakers\" and \"genres\" fields as the bridge table are created.\n",
    "df_movie=df_movie.drop('filmmakers','genres')\n",
    "\n",
    "# Similar to the above step, dropping the movie_id field from df_distributor\n",
    "df_distributor=df_distributor.drop('movie_id')\n",
    "\n",
    "df_boxoffice=df_boxoffice.drop('movie_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data to postgres\n",
    "url='jdbc:postgresql://localhost:5432/movie_data?user=jayesh'\n",
    "\n",
    "query='''\n",
    "    SELECT * FROM dim_movies\n",
    "'''\n",
    "(\n",
    "    spark.read\n",
    "            .format('jdbc')\n",
    "            .option('url',url)\n",
    "            .option('query',query)\n",
    "            .load()\n",
    ").show()\n",
    "# df_movie.write.jdbc(url=url,table='dim_movies',mode='append')\n",
    "# df_genre.write.jdbc(url=url,table='dim_genre',mode='append')\n",
    "# df_filmmaker.write.jdbc(url=url,table='dim_filmmakers',mode='append')\n",
    "# df_distributor.write.jdbc(url=url,table='dim_distributor',mode='append')\n",
    "# bridge_filmmaker_movie.write.jdbc(url=url,table='bridge_movie_filmmaker',mode='append')\n",
    "# bridge_movie_genre.write.jdbc(url=url,table='bridge_movie_genre',mode='append')\n",
    "# df_boxoffice.write.jdbc(url=url,table='fact_domestic_collection',mode='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "    # 1. Add fields listed in the data model to the corresponding DataFrames\n",
    "    # 2. Check for possible undesired values in every DataFrames' fields and fix it by replacing it with the desired value so everything can be casted properly.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-kernel",
   "language": "python",
   "name": "my-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
